I1101 13:43:41.392980  4164 caffe.cpp:218] Using GPUs 0
I1101 13:43:41.416420  4164 caffe.cpp:223] GPU 0: GeForce GTX 1060 6GB
I1101 13:43:41.628187  4164 solver.cpp:44] Initializing solver from parameters: 
train_net: "/home/ljf/caffe-master/examples/ljftest_alphabet_ResNet/train.prototxt"
test_net: "/home/ljf/caffe-master/examples/ljftest_alphabet_ResNet/test.prototxt"
test_iter: 100
test_interval: 100
base_lr: 0.1
display: 20
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 5000
snapshot_prefix: "/home/ljf/caffe-master/examples/ljftest_alphabet_ResNet/caffe_ljftest_train"
solver_mode: GPU
device_id: 0
train_state {
  level: 0
  stage: ""
}
test_initialization: false
average_loss: 100
stepvalue: 5000
stepvalue: 20000
stepvalue: 80000
stepvalue: 150000
iter_size: 1
I1101 13:43:41.628414  4164 solver.cpp:77] Creating training net from train_net file: /home/ljf/caffe-master/examples/ljftest_alphabet_ResNet/train.prototxt
I1101 13:43:41.629210  4164 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/ljf/caffe-master/examples/ljftest_alphabet_ResNet/train.prototxt
I1101 13:43:41.629220  4164 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1101 13:43:41.629978  4164 net.cpp:51] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  data_param {
    source: "/home/ljf/caffe-master/examples/ljftest_alphabet_ResNet/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution3"
  bottom: "Convolution1"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Convolution5"
  bottom: "Eltwise1"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Convolution7"
  bottom: "Eltwise2"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution9"
  bottom: "Eltwise3"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution12"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Convolution11"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution14"
  bottom: "Eltwise5"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution15"
  top: "Convolution15"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution16"
  bottom: "Eltwise6"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution17"
  top: "Convolution17"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Convolution18"
  bottom: "Eltwise7"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution19"
  top: "Convolution19"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Eltwise8"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution23"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution22"
  bottom: "Convolution23"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution25"
  bottom: "Eltwise10"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution26"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Convolution27"
  bottom: "Eltwise11"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution28"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Convolution29"
  bottom: "Eltwise12"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution30"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution30"
  top: "Convolution30"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Convolution31"
  bottom: "Eltwise13"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution32"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm32"
  type: "BatchNorm"
  bottom: "Convolution32"
  top: "Convolution32"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale32"
  type: "Scale"
  bottom: "Convolution32"
  top: "Convolution32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "Convolution32"
  top: "Convolution32"
}
layer {
  name: "Convolution33"
  type: "Convolution"
  bottom: "Convolution32"
  top: "Convolution33"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm33"
  type: "BatchNorm"
  bottom: "Convolution33"
  top: "Convolution33"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale33"
  type: "Scale"
  bottom: "Convolution33"
  top: "Convolution33"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution34"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution34"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_si
I1101 13:43:41.630488  4164 layer_factory.hpp:77] Creating layer Data1
I1101 13:43:41.630565  4164 db_lmdb.cpp:35] Opened lmdb /home/ljf/caffe-master/examples/ljftest_alphabet_ResNet/train_lmdb
I1101 13:43:41.630589  4164 net.cpp:84] Creating Layer Data1
I1101 13:43:41.630595  4164 net.cpp:380] Data1 -> Data1
I1101 13:43:41.630611  4164 net.cpp:380] Data1 -> Data2
I1101 13:43:41.631271  4164 data_layer.cpp:45] output data size: 256,3,32,32
I1101 13:43:41.637087  4164 net.cpp:122] Setting up Data1
I1101 13:43:41.637109  4164 net.cpp:129] Top shape: 256 3 32 32 (786432)
I1101 13:43:41.637112  4164 net.cpp:129] Top shape: 256 (256)
I1101 13:43:41.637115  4164 net.cpp:137] Memory required for data: 3146752
I1101 13:43:41.637122  4164 layer_factory.hpp:77] Creating layer Convolution1
I1101 13:43:41.637142  4164 net.cpp:84] Creating Layer Convolution1
I1101 13:43:41.637147  4164 net.cpp:406] Convolution1 <- Data1
I1101 13:43:41.637157  4164 net.cpp:380] Convolution1 -> Convolution1
I1101 13:43:41.791921  4164 net.cpp:122] Setting up Convolution1
I1101 13:43:41.791956  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.791960  4164 net.cpp:137] Memory required for data: 19923968
I1101 13:43:41.791983  4164 layer_factory.hpp:77] Creating layer BatchNorm1
I1101 13:43:41.791996  4164 net.cpp:84] Creating Layer BatchNorm1
I1101 13:43:41.791998  4164 net.cpp:406] BatchNorm1 <- Convolution1
I1101 13:43:41.792002  4164 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1101 13:43:41.792176  4164 net.cpp:122] Setting up BatchNorm1
I1101 13:43:41.792189  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.792207  4164 net.cpp:137] Memory required for data: 36701184
I1101 13:43:41.792212  4164 layer_factory.hpp:77] Creating layer Scale1
I1101 13:43:41.792217  4164 net.cpp:84] Creating Layer Scale1
I1101 13:43:41.792218  4164 net.cpp:406] Scale1 <- Convolution1
I1101 13:43:41.792222  4164 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1101 13:43:41.792248  4164 layer_factory.hpp:77] Creating layer Scale1
I1101 13:43:41.792340  4164 net.cpp:122] Setting up Scale1
I1101 13:43:41.792343  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.792346  4164 net.cpp:137] Memory required for data: 53478400
I1101 13:43:41.792349  4164 layer_factory.hpp:77] Creating layer ReLU1
I1101 13:43:41.792353  4164 net.cpp:84] Creating Layer ReLU1
I1101 13:43:41.792356  4164 net.cpp:406] ReLU1 <- Convolution1
I1101 13:43:41.792357  4164 net.cpp:367] ReLU1 -> Convolution1 (in-place)
I1101 13:43:41.792464  4164 net.cpp:122] Setting up ReLU1
I1101 13:43:41.792481  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.792484  4164 net.cpp:137] Memory required for data: 70255616
I1101 13:43:41.792485  4164 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I1101 13:43:41.792488  4164 net.cpp:84] Creating Layer Convolution1_ReLU1_0_split
I1101 13:43:41.792505  4164 net.cpp:406] Convolution1_ReLU1_0_split <- Convolution1
I1101 13:43:41.792507  4164 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I1101 13:43:41.792511  4164 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I1101 13:43:41.792533  4164 net.cpp:122] Setting up Convolution1_ReLU1_0_split
I1101 13:43:41.792537  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.792539  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.792541  4164 net.cpp:137] Memory required for data: 103810048
I1101 13:43:41.792543  4164 layer_factory.hpp:77] Creating layer Convolution2
I1101 13:43:41.792548  4164 net.cpp:84] Creating Layer Convolution2
I1101 13:43:41.792551  4164 net.cpp:406] Convolution2 <- Convolution1_ReLU1_0_split_0
I1101 13:43:41.792553  4164 net.cpp:380] Convolution2 -> Convolution2
I1101 13:43:41.793759  4164 net.cpp:122] Setting up Convolution2
I1101 13:43:41.793767  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.793784  4164 net.cpp:137] Memory required for data: 120587264
I1101 13:43:41.793789  4164 layer_factory.hpp:77] Creating layer BatchNorm2
I1101 13:43:41.793793  4164 net.cpp:84] Creating Layer BatchNorm2
I1101 13:43:41.793795  4164 net.cpp:406] BatchNorm2 <- Convolution2
I1101 13:43:41.793798  4164 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1101 13:43:41.793918  4164 net.cpp:122] Setting up BatchNorm2
I1101 13:43:41.793922  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.793925  4164 net.cpp:137] Memory required for data: 137364480
I1101 13:43:41.793942  4164 layer_factory.hpp:77] Creating layer Scale2
I1101 13:43:41.793946  4164 net.cpp:84] Creating Layer Scale2
I1101 13:43:41.793948  4164 net.cpp:406] Scale2 <- Convolution2
I1101 13:43:41.793951  4164 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1101 13:43:41.793969  4164 layer_factory.hpp:77] Creating layer Scale2
I1101 13:43:41.794064  4164 net.cpp:122] Setting up Scale2
I1101 13:43:41.794068  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.794070  4164 net.cpp:137] Memory required for data: 154141696
I1101 13:43:41.794085  4164 layer_factory.hpp:77] Creating layer ReLU2
I1101 13:43:41.794087  4164 net.cpp:84] Creating Layer ReLU2
I1101 13:43:41.794090  4164 net.cpp:406] ReLU2 <- Convolution2
I1101 13:43:41.794106  4164 net.cpp:367] ReLU2 -> Convolution2 (in-place)
I1101 13:43:41.794205  4164 net.cpp:122] Setting up ReLU2
I1101 13:43:41.794210  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.794212  4164 net.cpp:137] Memory required for data: 170918912
I1101 13:43:41.794214  4164 layer_factory.hpp:77] Creating layer Convolution3
I1101 13:43:41.794225  4164 net.cpp:84] Creating Layer Convolution3
I1101 13:43:41.794227  4164 net.cpp:406] Convolution3 <- Convolution2
I1101 13:43:41.794231  4164 net.cpp:380] Convolution3 -> Convolution3
I1101 13:43:41.794898  4164 net.cpp:122] Setting up Convolution3
I1101 13:43:41.794904  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.794906  4164 net.cpp:137] Memory required for data: 187696128
I1101 13:43:41.794925  4164 layer_factory.hpp:77] Creating layer BatchNorm3
I1101 13:43:41.794929  4164 net.cpp:84] Creating Layer BatchNorm3
I1101 13:43:41.794930  4164 net.cpp:406] BatchNorm3 <- Convolution3
I1101 13:43:41.794934  4164 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1101 13:43:41.795053  4164 net.cpp:122] Setting up BatchNorm3
I1101 13:43:41.795056  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.795058  4164 net.cpp:137] Memory required for data: 204473344
I1101 13:43:41.795078  4164 layer_factory.hpp:77] Creating layer Scale3
I1101 13:43:41.795081  4164 net.cpp:84] Creating Layer Scale3
I1101 13:43:41.795083  4164 net.cpp:406] Scale3 <- Convolution3
I1101 13:43:41.795086  4164 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1101 13:43:41.795105  4164 layer_factory.hpp:77] Creating layer Scale3
I1101 13:43:41.795167  4164 net.cpp:122] Setting up Scale3
I1101 13:43:41.795171  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.795172  4164 net.cpp:137] Memory required for data: 221250560
I1101 13:43:41.795176  4164 layer_factory.hpp:77] Creating layer Eltwise1
I1101 13:43:41.795179  4164 net.cpp:84] Creating Layer Eltwise1
I1101 13:43:41.795181  4164 net.cpp:406] Eltwise1 <- Convolution3
I1101 13:43:41.795183  4164 net.cpp:406] Eltwise1 <- Convolution1_ReLU1_0_split_1
I1101 13:43:41.795186  4164 net.cpp:380] Eltwise1 -> Eltwise1
I1101 13:43:41.795202  4164 net.cpp:122] Setting up Eltwise1
I1101 13:43:41.795205  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.795207  4164 net.cpp:137] Memory required for data: 238027776
I1101 13:43:41.795208  4164 layer_factory.hpp:77] Creating layer ReLU3
I1101 13:43:41.795212  4164 net.cpp:84] Creating Layer ReLU3
I1101 13:43:41.795213  4164 net.cpp:406] ReLU3 <- Eltwise1
I1101 13:43:41.795215  4164 net.cpp:367] ReLU3 -> Eltwise1 (in-place)
I1101 13:43:41.795326  4164 net.cpp:122] Setting up ReLU3
I1101 13:43:41.795331  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.795333  4164 net.cpp:137] Memory required for data: 254804992
I1101 13:43:41.795334  4164 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I1101 13:43:41.795353  4164 net.cpp:84] Creating Layer Eltwise1_ReLU3_0_split
I1101 13:43:41.795356  4164 net.cpp:406] Eltwise1_ReLU3_0_split <- Eltwise1
I1101 13:43:41.795358  4164 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I1101 13:43:41.795363  4164 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I1101 13:43:41.795384  4164 net.cpp:122] Setting up Eltwise1_ReLU3_0_split
I1101 13:43:41.795388  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.795390  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.795392  4164 net.cpp:137] Memory required for data: 288359424
I1101 13:43:41.795393  4164 layer_factory.hpp:77] Creating layer Convolution4
I1101 13:43:41.795399  4164 net.cpp:84] Creating Layer Convolution4
I1101 13:43:41.795402  4164 net.cpp:406] Convolution4 <- Eltwise1_ReLU3_0_split_0
I1101 13:43:41.795404  4164 net.cpp:380] Convolution4 -> Convolution4
I1101 13:43:41.796052  4164 net.cpp:122] Setting up Convolution4
I1101 13:43:41.796061  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.796075  4164 net.cpp:137] Memory required for data: 305136640
I1101 13:43:41.796078  4164 layer_factory.hpp:77] Creating layer BatchNorm4
I1101 13:43:41.796082  4164 net.cpp:84] Creating Layer BatchNorm4
I1101 13:43:41.796085  4164 net.cpp:406] BatchNorm4 <- Convolution4
I1101 13:43:41.796089  4164 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1101 13:43:41.796214  4164 net.cpp:122] Setting up BatchNorm4
I1101 13:43:41.796224  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.796238  4164 net.cpp:137] Memory required for data: 321913856
I1101 13:43:41.796243  4164 layer_factory.hpp:77] Creating layer Scale4
I1101 13:43:41.796247  4164 net.cpp:84] Creating Layer Scale4
I1101 13:43:41.796249  4164 net.cpp:406] Scale4 <- Convolution4
I1101 13:43:41.796252  4164 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1101 13:43:41.796273  4164 layer_factory.hpp:77] Creating layer Scale4
I1101 13:43:41.796336  4164 net.cpp:122] Setting up Scale4
I1101 13:43:41.796341  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.796344  4164 net.cpp:137] Memory required for data: 338691072
I1101 13:43:41.796346  4164 layer_factory.hpp:77] Creating layer ReLU4
I1101 13:43:41.796350  4164 net.cpp:84] Creating Layer ReLU4
I1101 13:43:41.796351  4164 net.cpp:406] ReLU4 <- Convolution4
I1101 13:43:41.796353  4164 net.cpp:367] ReLU4 -> Convolution4 (in-place)
I1101 13:43:41.796456  4164 net.cpp:122] Setting up ReLU4
I1101 13:43:41.796461  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.796463  4164 net.cpp:137] Memory required for data: 355468288
I1101 13:43:41.796464  4164 layer_factory.hpp:77] Creating layer Convolution5
I1101 13:43:41.796470  4164 net.cpp:84] Creating Layer Convolution5
I1101 13:43:41.796473  4164 net.cpp:406] Convolution5 <- Convolution4
I1101 13:43:41.796476  4164 net.cpp:380] Convolution5 -> Convolution5
I1101 13:43:41.797119  4164 net.cpp:122] Setting up Convolution5
I1101 13:43:41.797127  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.797130  4164 net.cpp:137] Memory required for data: 372245504
I1101 13:43:41.797133  4164 layer_factory.hpp:77] Creating layer BatchNorm5
I1101 13:43:41.797137  4164 net.cpp:84] Creating Layer BatchNorm5
I1101 13:43:41.797139  4164 net.cpp:406] BatchNorm5 <- Convolution5
I1101 13:43:41.797143  4164 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1101 13:43:41.797296  4164 net.cpp:122] Setting up BatchNorm5
I1101 13:43:41.797299  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.797302  4164 net.cpp:137] Memory required for data: 389022720
I1101 13:43:41.797319  4164 layer_factory.hpp:77] Creating layer Scale5
I1101 13:43:41.797323  4164 net.cpp:84] Creating Layer Scale5
I1101 13:43:41.797327  4164 net.cpp:406] Scale5 <- Convolution5
I1101 13:43:41.797328  4164 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1101 13:43:41.797349  4164 layer_factory.hpp:77] Creating layer Scale5
I1101 13:43:41.797442  4164 net.cpp:122] Setting up Scale5
I1101 13:43:41.797446  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.797448  4164 net.cpp:137] Memory required for data: 405799936
I1101 13:43:41.797471  4164 layer_factory.hpp:77] Creating layer Eltwise2
I1101 13:43:41.797473  4164 net.cpp:84] Creating Layer Eltwise2
I1101 13:43:41.797475  4164 net.cpp:406] Eltwise2 <- Convolution5
I1101 13:43:41.797477  4164 net.cpp:406] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I1101 13:43:41.797482  4164 net.cpp:380] Eltwise2 -> Eltwise2
I1101 13:43:41.797497  4164 net.cpp:122] Setting up Eltwise2
I1101 13:43:41.797499  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.797502  4164 net.cpp:137] Memory required for data: 422577152
I1101 13:43:41.797515  4164 layer_factory.hpp:77] Creating layer ReLU5
I1101 13:43:41.797518  4164 net.cpp:84] Creating Layer ReLU5
I1101 13:43:41.797520  4164 net.cpp:406] ReLU5 <- Eltwise2
I1101 13:43:41.797523  4164 net.cpp:367] ReLU5 -> Eltwise2 (in-place)
I1101 13:43:41.797832  4164 net.cpp:122] Setting up ReLU5
I1101 13:43:41.797838  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.797853  4164 net.cpp:137] Memory required for data: 439354368
I1101 13:43:41.797855  4164 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I1101 13:43:41.797859  4164 net.cpp:84] Creating Layer Eltwise2_ReLU5_0_split
I1101 13:43:41.797863  4164 net.cpp:406] Eltwise2_ReLU5_0_split <- Eltwise2
I1101 13:43:41.797866  4164 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I1101 13:43:41.797876  4164 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I1101 13:43:41.797902  4164 net.cpp:122] Setting up Eltwise2_ReLU5_0_split
I1101 13:43:41.797905  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.797907  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.797909  4164 net.cpp:137] Memory required for data: 472908800
I1101 13:43:41.797911  4164 layer_factory.hpp:77] Creating layer Convolution6
I1101 13:43:41.797916  4164 net.cpp:84] Creating Layer Convolution6
I1101 13:43:41.797919  4164 net.cpp:406] Convolution6 <- Eltwise2_ReLU5_0_split_0
I1101 13:43:41.797924  4164 net.cpp:380] Convolution6 -> Convolution6
I1101 13:43:41.798395  4164 net.cpp:122] Setting up Convolution6
I1101 13:43:41.798403  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.798420  4164 net.cpp:137] Memory required for data: 489686016
I1101 13:43:41.798424  4164 layer_factory.hpp:77] Creating layer BatchNorm6
I1101 13:43:41.798429  4164 net.cpp:84] Creating Layer BatchNorm6
I1101 13:43:41.798444  4164 net.cpp:406] BatchNorm6 <- Convolution6
I1101 13:43:41.798449  4164 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1101 13:43:41.798588  4164 net.cpp:122] Setting up BatchNorm6
I1101 13:43:41.798593  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.798593  4164 net.cpp:137] Memory required for data: 506463232
I1101 13:43:41.798610  4164 layer_factory.hpp:77] Creating layer Scale6
I1101 13:43:41.798612  4164 net.cpp:84] Creating Layer Scale6
I1101 13:43:41.798615  4164 net.cpp:406] Scale6 <- Convolution6
I1101 13:43:41.798619  4164 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1101 13:43:41.798638  4164 layer_factory.hpp:77] Creating layer Scale6
I1101 13:43:41.798744  4164 net.cpp:122] Setting up Scale6
I1101 13:43:41.798761  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.798763  4164 net.cpp:137] Memory required for data: 523240448
I1101 13:43:41.798766  4164 layer_factory.hpp:77] Creating layer ReLU6
I1101 13:43:41.798785  4164 net.cpp:84] Creating Layer ReLU6
I1101 13:43:41.798787  4164 net.cpp:406] ReLU6 <- Convolution6
I1101 13:43:41.798804  4164 net.cpp:367] ReLU6 -> Convolution6 (in-place)
I1101 13:43:41.799118  4164 net.cpp:122] Setting up ReLU6
I1101 13:43:41.799125  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.799140  4164 net.cpp:137] Memory required for data: 540017664
I1101 13:43:41.799142  4164 layer_factory.hpp:77] Creating layer Convolution7
I1101 13:43:41.799147  4164 net.cpp:84] Creating Layer Convolution7
I1101 13:43:41.799150  4164 net.cpp:406] Convolution7 <- Convolution6
I1101 13:43:41.799154  4164 net.cpp:380] Convolution7 -> Convolution7
I1101 13:43:41.799813  4164 net.cpp:122] Setting up Convolution7
I1101 13:43:41.799819  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.799834  4164 net.cpp:137] Memory required for data: 556794880
I1101 13:43:41.799839  4164 layer_factory.hpp:77] Creating layer BatchNorm7
I1101 13:43:41.799842  4164 net.cpp:84] Creating Layer BatchNorm7
I1101 13:43:41.799845  4164 net.cpp:406] BatchNorm7 <- Convolution7
I1101 13:43:41.799847  4164 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1101 13:43:41.799976  4164 net.cpp:122] Setting up BatchNorm7
I1101 13:43:41.799980  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.799981  4164 net.cpp:137] Memory required for data: 573572096
I1101 13:43:41.799998  4164 layer_factory.hpp:77] Creating layer Scale7
I1101 13:43:41.800004  4164 net.cpp:84] Creating Layer Scale7
I1101 13:43:41.800005  4164 net.cpp:406] Scale7 <- Convolution7
I1101 13:43:41.800009  4164 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1101 13:43:41.800029  4164 layer_factory.hpp:77] Creating layer Scale7
I1101 13:43:41.800097  4164 net.cpp:122] Setting up Scale7
I1101 13:43:41.800101  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.800103  4164 net.cpp:137] Memory required for data: 590349312
I1101 13:43:41.800107  4164 layer_factory.hpp:77] Creating layer Eltwise3
I1101 13:43:41.800128  4164 net.cpp:84] Creating Layer Eltwise3
I1101 13:43:41.800130  4164 net.cpp:406] Eltwise3 <- Convolution7
I1101 13:43:41.800133  4164 net.cpp:406] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I1101 13:43:41.800148  4164 net.cpp:380] Eltwise3 -> Eltwise3
I1101 13:43:41.800163  4164 net.cpp:122] Setting up Eltwise3
I1101 13:43:41.800168  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.800168  4164 net.cpp:137] Memory required for data: 607126528
I1101 13:43:41.800170  4164 layer_factory.hpp:77] Creating layer ReLU7
I1101 13:43:41.800173  4164 net.cpp:84] Creating Layer ReLU7
I1101 13:43:41.800174  4164 net.cpp:406] ReLU7 <- Eltwise3
I1101 13:43:41.800177  4164 net.cpp:367] ReLU7 -> Eltwise3 (in-place)
I1101 13:43:41.800287  4164 net.cpp:122] Setting up ReLU7
I1101 13:43:41.800292  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.800294  4164 net.cpp:137] Memory required for data: 623903744
I1101 13:43:41.800297  4164 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I1101 13:43:41.800299  4164 net.cpp:84] Creating Layer Eltwise3_ReLU7_0_split
I1101 13:43:41.800302  4164 net.cpp:406] Eltwise3_ReLU7_0_split <- Eltwise3
I1101 13:43:41.800305  4164 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I1101 13:43:41.800309  4164 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I1101 13:43:41.800348  4164 net.cpp:122] Setting up Eltwise3_ReLU7_0_split
I1101 13:43:41.800353  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.800367  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.800369  4164 net.cpp:137] Memory required for data: 657458176
I1101 13:43:41.800371  4164 layer_factory.hpp:77] Creating layer Convolution8
I1101 13:43:41.800390  4164 net.cpp:84] Creating Layer Convolution8
I1101 13:43:41.800393  4164 net.cpp:406] Convolution8 <- Eltwise3_ReLU7_0_split_0
I1101 13:43:41.800397  4164 net.cpp:380] Convolution8 -> Convolution8
I1101 13:43:41.801076  4164 net.cpp:122] Setting up Convolution8
I1101 13:43:41.801084  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.801087  4164 net.cpp:137] Memory required for data: 674235392
I1101 13:43:41.801105  4164 layer_factory.hpp:77] Creating layer BatchNorm8
I1101 13:43:41.801111  4164 net.cpp:84] Creating Layer BatchNorm8
I1101 13:43:41.801115  4164 net.cpp:406] BatchNorm8 <- Convolution8
I1101 13:43:41.801118  4164 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1101 13:43:41.801275  4164 net.cpp:122] Setting up BatchNorm8
I1101 13:43:41.801280  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.801282  4164 net.cpp:137] Memory required for data: 691012608
I1101 13:43:41.801301  4164 layer_factory.hpp:77] Creating layer Scale8
I1101 13:43:41.801306  4164 net.cpp:84] Creating Layer Scale8
I1101 13:43:41.801308  4164 net.cpp:406] Scale8 <- Convolution8
I1101 13:43:41.801311  4164 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1101 13:43:41.801344  4164 layer_factory.hpp:77] Creating layer Scale8
I1101 13:43:41.801470  4164 net.cpp:122] Setting up Scale8
I1101 13:43:41.801475  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.801477  4164 net.cpp:137] Memory required for data: 707789824
I1101 13:43:41.801494  4164 layer_factory.hpp:77] Creating layer ReLU8
I1101 13:43:41.801498  4164 net.cpp:84] Creating Layer ReLU8
I1101 13:43:41.801501  4164 net.cpp:406] ReLU8 <- Convolution8
I1101 13:43:41.801503  4164 net.cpp:367] ReLU8 -> Convolution8 (in-place)
I1101 13:43:41.801621  4164 net.cpp:122] Setting up ReLU8
I1101 13:43:41.801626  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.801628  4164 net.cpp:137] Memory required for data: 724567040
I1101 13:43:41.801630  4164 layer_factory.hpp:77] Creating layer Convolution9
I1101 13:43:41.801651  4164 net.cpp:84] Creating Layer Convolution9
I1101 13:43:41.801653  4164 net.cpp:406] Convolution9 <- Convolution8
I1101 13:43:41.801656  4164 net.cpp:380] Convolution9 -> Convolution9
I1101 13:43:41.802362  4164 net.cpp:122] Setting up Convolution9
I1101 13:43:41.802376  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.802378  4164 net.cpp:137] Memory required for data: 741344256
I1101 13:43:41.802397  4164 layer_factory.hpp:77] Creating layer BatchNorm9
I1101 13:43:41.802402  4164 net.cpp:84] Creating Layer BatchNorm9
I1101 13:43:41.802405  4164 net.cpp:406] BatchNorm9 <- Convolution9
I1101 13:43:41.802409  4164 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1101 13:43:41.802546  4164 net.cpp:122] Setting up BatchNorm9
I1101 13:43:41.802551  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.802552  4164 net.cpp:137] Memory required for data: 758121472
I1101 13:43:41.802556  4164 layer_factory.hpp:77] Creating layer Scale9
I1101 13:43:41.802559  4164 net.cpp:84] Creating Layer Scale9
I1101 13:43:41.802561  4164 net.cpp:406] Scale9 <- Convolution9
I1101 13:43:41.802564  4164 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1101 13:43:41.802584  4164 layer_factory.hpp:77] Creating layer Scale9
I1101 13:43:41.802706  4164 net.cpp:122] Setting up Scale9
I1101 13:43:41.802711  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.802714  4164 net.cpp:137] Memory required for data: 774898688
I1101 13:43:41.802731  4164 layer_factory.hpp:77] Creating layer Eltwise4
I1101 13:43:41.802736  4164 net.cpp:84] Creating Layer Eltwise4
I1101 13:43:41.802737  4164 net.cpp:406] Eltwise4 <- Convolution9
I1101 13:43:41.802741  4164 net.cpp:406] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I1101 13:43:41.802744  4164 net.cpp:380] Eltwise4 -> Eltwise4
I1101 13:43:41.802758  4164 net.cpp:122] Setting up Eltwise4
I1101 13:43:41.802762  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.802764  4164 net.cpp:137] Memory required for data: 791675904
I1101 13:43:41.802765  4164 layer_factory.hpp:77] Creating layer ReLU9
I1101 13:43:41.802769  4164 net.cpp:84] Creating Layer ReLU9
I1101 13:43:41.802772  4164 net.cpp:406] ReLU9 <- Eltwise4
I1101 13:43:41.802773  4164 net.cpp:367] ReLU9 -> Eltwise4 (in-place)
I1101 13:43:41.802883  4164 net.cpp:122] Setting up ReLU9
I1101 13:43:41.802889  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.802891  4164 net.cpp:137] Memory required for data: 808453120
I1101 13:43:41.802894  4164 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I1101 13:43:41.802897  4164 net.cpp:84] Creating Layer Eltwise4_ReLU9_0_split
I1101 13:43:41.802898  4164 net.cpp:406] Eltwise4_ReLU9_0_split <- Eltwise4
I1101 13:43:41.802901  4164 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I1101 13:43:41.802907  4164 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I1101 13:43:41.802932  4164 net.cpp:122] Setting up Eltwise4_ReLU9_0_split
I1101 13:43:41.802935  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.802937  4164 net.cpp:129] Top shape: 256 16 32 32 (4194304)
I1101 13:43:41.802939  4164 net.cpp:137] Memory required for data: 842007552
I1101 13:43:41.802942  4164 layer_factory.hpp:77] Creating layer Convolution10
I1101 13:43:41.802947  4164 net.cpp:84] Creating Layer Convolution10
I1101 13:43:41.802949  4164 net.cpp:406] Convolution10 <- Eltwise4_ReLU9_0_split_0
I1101 13:43:41.802953  4164 net.cpp:380] Convolution10 -> Convolution10
I1101 13:43:41.804376  4164 net.cpp:122] Setting up Convolution10
I1101 13:43:41.804388  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.804390  4164 net.cpp:137] Memory required for data: 850396160
I1101 13:43:41.804404  4164 layer_factory.hpp:77] Creating layer BatchNorm10
I1101 13:43:41.804409  4164 net.cpp:84] Creating Layer BatchNorm10
I1101 13:43:41.804412  4164 net.cpp:406] BatchNorm10 <- Convolution10
I1101 13:43:41.804419  4164 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1101 13:43:41.804572  4164 net.cpp:122] Setting up BatchNorm10
I1101 13:43:41.804579  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.804581  4164 net.cpp:137] Memory required for data: 858784768
I1101 13:43:41.804585  4164 layer_factory.hpp:77] Creating layer Scale10
I1101 13:43:41.804602  4164 net.cpp:84] Creating Layer Scale10
I1101 13:43:41.804630  4164 net.cpp:406] Scale10 <- Convolution10
I1101 13:43:41.804635  4164 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1101 13:43:41.804662  4164 layer_factory.hpp:77] Creating layer Scale10
I1101 13:43:41.804797  4164 net.cpp:122] Setting up Scale10
I1101 13:43:41.804803  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.804818  4164 net.cpp:137] Memory required for data: 867173376
I1101 13:43:41.804821  4164 layer_factory.hpp:77] Creating layer ReLU10
I1101 13:43:41.804826  4164 net.cpp:84] Creating Layer ReLU10
I1101 13:43:41.804827  4164 net.cpp:406] ReLU10 <- Convolution10
I1101 13:43:41.804831  4164 net.cpp:367] ReLU10 -> Convolution10 (in-place)
I1101 13:43:41.804955  4164 net.cpp:122] Setting up ReLU10
I1101 13:43:41.804960  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.804975  4164 net.cpp:137] Memory required for data: 875561984
I1101 13:43:41.804976  4164 layer_factory.hpp:77] Creating layer Convolution11
I1101 13:43:41.804983  4164 net.cpp:84] Creating Layer Convolution11
I1101 13:43:41.804986  4164 net.cpp:406] Convolution11 <- Convolution10
I1101 13:43:41.804988  4164 net.cpp:380] Convolution11 -> Convolution11
I1101 13:43:41.805725  4164 net.cpp:122] Setting up Convolution11
I1101 13:43:41.805733  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.805748  4164 net.cpp:137] Memory required for data: 883950592
I1101 13:43:41.805752  4164 layer_factory.hpp:77] Creating layer BatchNorm11
I1101 13:43:41.805757  4164 net.cpp:84] Creating Layer BatchNorm11
I1101 13:43:41.805758  4164 net.cpp:406] BatchNorm11 <- Convolution11
I1101 13:43:41.805763  4164 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1101 13:43:41.805905  4164 net.cpp:122] Setting up BatchNorm11
I1101 13:43:41.805912  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.805914  4164 net.cpp:137] Memory required for data: 892339200
I1101 13:43:41.805920  4164 layer_factory.hpp:77] Creating layer Scale11
I1101 13:43:41.805925  4164 net.cpp:84] Creating Layer Scale11
I1101 13:43:41.805928  4164 net.cpp:406] Scale11 <- Convolution11
I1101 13:43:41.805932  4164 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1101 13:43:41.805975  4164 layer_factory.hpp:77] Creating layer Scale11
I1101 13:43:41.806077  4164 net.cpp:122] Setting up Scale11
I1101 13:43:41.806083  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.806087  4164 net.cpp:137] Memory required for data: 900727808
I1101 13:43:41.806093  4164 layer_factory.hpp:77] Creating layer Convolution12
I1101 13:43:41.806102  4164 net.cpp:84] Creating Layer Convolution12
I1101 13:43:41.806105  4164 net.cpp:406] Convolution12 <- Eltwise4_ReLU9_0_split_1
I1101 13:43:41.806110  4164 net.cpp:380] Convolution12 -> Convolution12
I1101 13:43:41.807153  4164 net.cpp:122] Setting up Convolution12
I1101 13:43:41.807163  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.807165  4164 net.cpp:137] Memory required for data: 909116416
I1101 13:43:41.807168  4164 layer_factory.hpp:77] Creating layer BatchNorm12
I1101 13:43:41.807174  4164 net.cpp:84] Creating Layer BatchNorm12
I1101 13:43:41.807176  4164 net.cpp:406] BatchNorm12 <- Convolution12
I1101 13:43:41.807180  4164 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1101 13:43:41.807298  4164 net.cpp:122] Setting up BatchNorm12
I1101 13:43:41.807303  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.807304  4164 net.cpp:137] Memory required for data: 917505024
I1101 13:43:41.807308  4164 layer_factory.hpp:77] Creating layer Scale12
I1101 13:43:41.807312  4164 net.cpp:84] Creating Layer Scale12
I1101 13:43:41.807314  4164 net.cpp:406] Scale12 <- Convolution12
I1101 13:43:41.807317  4164 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1101 13:43:41.807338  4164 layer_factory.hpp:77] Creating layer Scale12
I1101 13:43:41.807406  4164 net.cpp:122] Setting up Scale12
I1101 13:43:41.807411  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.807412  4164 net.cpp:137] Memory required for data: 925893632
I1101 13:43:41.807423  4164 layer_factory.hpp:77] Creating layer Eltwise5
I1101 13:43:41.807428  4164 net.cpp:84] Creating Layer Eltwise5
I1101 13:43:41.807431  4164 net.cpp:406] Eltwise5 <- Convolution11
I1101 13:43:41.807433  4164 net.cpp:406] Eltwise5 <- Convolution12
I1101 13:43:41.807436  4164 net.cpp:380] Eltwise5 -> Eltwise5
I1101 13:43:41.807448  4164 net.cpp:122] Setting up Eltwise5
I1101 13:43:41.807452  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.807453  4164 net.cpp:137] Memory required for data: 934282240
I1101 13:43:41.807456  4164 layer_factory.hpp:77] Creating layer ReLU11
I1101 13:43:41.807458  4164 net.cpp:84] Creating Layer ReLU11
I1101 13:43:41.807461  4164 net.cpp:406] ReLU11 <- Eltwise5
I1101 13:43:41.807463  4164 net.cpp:367] ReLU11 -> Eltwise5 (in-place)
I1101 13:43:41.807571  4164 net.cpp:122] Setting up ReLU11
I1101 13:43:41.807577  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.807579  4164 net.cpp:137] Memory required for data: 942670848
I1101 13:43:41.807581  4164 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I1101 13:43:41.807585  4164 net.cpp:84] Creating Layer Eltwise5_ReLU11_0_split
I1101 13:43:41.807586  4164 net.cpp:406] Eltwise5_ReLU11_0_split <- Eltwise5
I1101 13:43:41.807590  4164 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I1101 13:43:41.807595  4164 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I1101 13:43:41.807618  4164 net.cpp:122] Setting up Eltwise5_ReLU11_0_split
I1101 13:43:41.807622  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.807626  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.807626  4164 net.cpp:137] Memory required for data: 959448064
I1101 13:43:41.807628  4164 layer_factory.hpp:77] Creating layer Convolution13
I1101 13:43:41.807633  4164 net.cpp:84] Creating Layer Convolution13
I1101 13:43:41.807636  4164 net.cpp:406] Convolution13 <- Eltwise5_ReLU11_0_split_0
I1101 13:43:41.807641  4164 net.cpp:380] Convolution13 -> Convolution13
I1101 13:43:41.808357  4164 net.cpp:122] Setting up Convolution13
I1101 13:43:41.808365  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.808368  4164 net.cpp:137] Memory required for data: 967836672
I1101 13:43:41.808372  4164 layer_factory.hpp:77] Creating layer BatchNorm13
I1101 13:43:41.808392  4164 net.cpp:84] Creating Layer BatchNorm13
I1101 13:43:41.808394  4164 net.cpp:406] BatchNorm13 <- Convolution13
I1101 13:43:41.808398  4164 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1101 13:43:41.808529  4164 net.cpp:122] Setting up BatchNorm13
I1101 13:43:41.808533  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.808535  4164 net.cpp:137] Memory required for data: 976225280
I1101 13:43:41.808554  4164 layer_factory.hpp:77] Creating layer Scale13
I1101 13:43:41.808558  4164 net.cpp:84] Creating Layer Scale13
I1101 13:43:41.808559  4164 net.cpp:406] Scale13 <- Convolution13
I1101 13:43:41.808562  4164 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1101 13:43:41.808596  4164 layer_factory.hpp:77] Creating layer Scale13
I1101 13:43:41.808666  4164 net.cpp:122] Setting up Scale13
I1101 13:43:41.808670  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.808672  4164 net.cpp:137] Memory required for data: 984613888
I1101 13:43:41.808676  4164 layer_factory.hpp:77] Creating layer ReLU12
I1101 13:43:41.808678  4164 net.cpp:84] Creating Layer ReLU12
I1101 13:43:41.808679  4164 net.cpp:406] ReLU12 <- Convolution13
I1101 13:43:41.808683  4164 net.cpp:367] ReLU12 -> Convolution13 (in-place)
I1101 13:43:41.808965  4164 net.cpp:122] Setting up ReLU12
I1101 13:43:41.808974  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.808975  4164 net.cpp:137] Memory required for data: 993002496
I1101 13:43:41.808977  4164 layer_factory.hpp:77] Creating layer Convolution14
I1101 13:43:41.808984  4164 net.cpp:84] Creating Layer Convolution14
I1101 13:43:41.808987  4164 net.cpp:406] Convolution14 <- Convolution13
I1101 13:43:41.808997  4164 net.cpp:380] Convolution14 -> Convolution14
I1101 13:43:41.809727  4164 net.cpp:122] Setting up Convolution14
I1101 13:43:41.809736  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.809737  4164 net.cpp:137] Memory required for data: 1001391104
I1101 13:43:41.809741  4164 layer_factory.hpp:77] Creating layer BatchNorm14
I1101 13:43:41.809751  4164 net.cpp:84] Creating Layer BatchNorm14
I1101 13:43:41.809753  4164 net.cpp:406] BatchNorm14 <- Convolution14
I1101 13:43:41.809757  4164 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1101 13:43:41.809873  4164 net.cpp:122] Setting up BatchNorm14
I1101 13:43:41.809877  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.809880  4164 net.cpp:137] Memory required for data: 1009779712
I1101 13:43:41.809885  4164 layer_factory.hpp:77] Creating layer Scale14
I1101 13:43:41.809887  4164 net.cpp:84] Creating Layer Scale14
I1101 13:43:41.809890  4164 net.cpp:406] Scale14 <- Convolution14
I1101 13:43:41.809893  4164 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1101 13:43:41.809914  4164 layer_factory.hpp:77] Creating layer Scale14
I1101 13:43:41.809983  4164 net.cpp:122] Setting up Scale14
I1101 13:43:41.809986  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.809988  4164 net.cpp:137] Memory required for data: 1018168320
I1101 13:43:41.809993  4164 layer_factory.hpp:77] Creating layer Eltwise6
I1101 13:43:41.809995  4164 net.cpp:84] Creating Layer Eltwise6
I1101 13:43:41.809996  4164 net.cpp:406] Eltwise6 <- Convolution14
I1101 13:43:41.809999  4164 net.cpp:406] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I1101 13:43:41.810003  4164 net.cpp:380] Eltwise6 -> Eltwise6
I1101 13:43:41.810014  4164 net.cpp:122] Setting up Eltwise6
I1101 13:43:41.810017  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.810019  4164 net.cpp:137] Memory required for data: 1026556928
I1101 13:43:41.810021  4164 layer_factory.hpp:77] Creating layer ReLU13
I1101 13:43:41.810025  4164 net.cpp:84] Creating Layer ReLU13
I1101 13:43:41.810026  4164 net.cpp:406] ReLU13 <- Eltwise6
I1101 13:43:41.810029  4164 net.cpp:367] ReLU13 -> Eltwise6 (in-place)
I1101 13:43:41.810137  4164 net.cpp:122] Setting up ReLU13
I1101 13:43:41.810142  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.810143  4164 net.cpp:137] Memory required for data: 1034945536
I1101 13:43:41.810145  4164 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I1101 13:43:41.810149  4164 net.cpp:84] Creating Layer Eltwise6_ReLU13_0_split
I1101 13:43:41.810151  4164 net.cpp:406] Eltwise6_ReLU13_0_split <- Eltwise6
I1101 13:43:41.810154  4164 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I1101 13:43:41.810158  4164 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I1101 13:43:41.810184  4164 net.cpp:122] Setting up Eltwise6_ReLU13_0_split
I1101 13:43:41.810187  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.810189  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.810191  4164 net.cpp:137] Memory required for data: 1051722752
I1101 13:43:41.810192  4164 layer_factory.hpp:77] Creating layer Convolution15
I1101 13:43:41.810197  4164 net.cpp:84] Creating Layer Convolution15
I1101 13:43:41.810199  4164 net.cpp:406] Convolution15 <- Eltwise6_ReLU13_0_split_0
I1101 13:43:41.810204  4164 net.cpp:380] Convolution15 -> Convolution15
I1101 13:43:41.810969  4164 net.cpp:122] Setting up Convolution15
I1101 13:43:41.810977  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.810979  4164 net.cpp:137] Memory required for data: 1060111360
I1101 13:43:41.810983  4164 layer_factory.hpp:77] Creating layer BatchNorm15
I1101 13:43:41.810988  4164 net.cpp:84] Creating Layer BatchNorm15
I1101 13:43:41.810992  4164 net.cpp:406] BatchNorm15 <- Convolution15
I1101 13:43:41.811008  4164 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1101 13:43:41.811141  4164 net.cpp:122] Setting up BatchNorm15
I1101 13:43:41.811144  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.811153  4164 net.cpp:137] Memory required for data: 1068499968
I1101 13:43:41.811157  4164 layer_factory.hpp:77] Creating layer Scale15
I1101 13:43:41.811161  4164 net.cpp:84] Creating Layer Scale15
I1101 13:43:41.811163  4164 net.cpp:406] Scale15 <- Convolution15
I1101 13:43:41.811180  4164 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1101 13:43:41.811203  4164 layer_factory.hpp:77] Creating layer Scale15
I1101 13:43:41.811312  4164 net.cpp:122] Setting up Scale15
I1101 13:43:41.811316  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.811318  4164 net.cpp:137] Memory required for data: 1076888576
I1101 13:43:41.811336  4164 layer_factory.hpp:77] Creating layer ReLU14
I1101 13:43:41.811341  4164 net.cpp:84] Creating Layer ReLU14
I1101 13:43:41.811342  4164 net.cpp:406] ReLU14 <- Convolution15
I1101 13:43:41.811344  4164 net.cpp:367] ReLU14 -> Convolution15 (in-place)
I1101 13:43:41.811465  4164 net.cpp:122] Setting up ReLU14
I1101 13:43:41.811472  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.811475  4164 net.cpp:137] Memory required for data: 1085277184
I1101 13:43:41.811475  4164 layer_factory.hpp:77] Creating layer Convolution16
I1101 13:43:41.811480  4164 net.cpp:84] Creating Layer Convolution16
I1101 13:43:41.811483  4164 net.cpp:406] Convolution16 <- Convolution15
I1101 13:43:41.811487  4164 net.cpp:380] Convolution16 -> Convolution16
I1101 13:43:41.812209  4164 net.cpp:122] Setting up Convolution16
I1101 13:43:41.812218  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.812221  4164 net.cpp:137] Memory required for data: 1093665792
I1101 13:43:41.812224  4164 layer_factory.hpp:77] Creating layer BatchNorm16
I1101 13:43:41.812227  4164 net.cpp:84] Creating Layer BatchNorm16
I1101 13:43:41.812230  4164 net.cpp:406] BatchNorm16 <- Convolution16
I1101 13:43:41.812234  4164 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1101 13:43:41.812379  4164 net.cpp:122] Setting up BatchNorm16
I1101 13:43:41.812383  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.812386  4164 net.cpp:137] Memory required for data: 1102054400
I1101 13:43:41.812389  4164 layer_factory.hpp:77] Creating layer Scale16
I1101 13:43:41.812393  4164 net.cpp:84] Creating Layer Scale16
I1101 13:43:41.812396  4164 net.cpp:406] Scale16 <- Convolution16
I1101 13:43:41.812397  4164 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1101 13:43:41.812418  4164 layer_factory.hpp:77] Creating layer Scale16
I1101 13:43:41.812486  4164 net.cpp:122] Setting up Scale16
I1101 13:43:41.812490  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.812492  4164 net.cpp:137] Memory required for data: 1110443008
I1101 13:43:41.812495  4164 layer_factory.hpp:77] Creating layer Eltwise7
I1101 13:43:41.812500  4164 net.cpp:84] Creating Layer Eltwise7
I1101 13:43:41.812501  4164 net.cpp:406] Eltwise7 <- Convolution16
I1101 13:43:41.812517  4164 net.cpp:406] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I1101 13:43:41.812520  4164 net.cpp:380] Eltwise7 -> Eltwise7
I1101 13:43:41.812533  4164 net.cpp:122] Setting up Eltwise7
I1101 13:43:41.812536  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.812538  4164 net.cpp:137] Memory required for data: 1118831616
I1101 13:43:41.812541  4164 layer_factory.hpp:77] Creating layer ReLU15
I1101 13:43:41.812543  4164 net.cpp:84] Creating Layer ReLU15
I1101 13:43:41.812546  4164 net.cpp:406] ReLU15 <- Eltwise7
I1101 13:43:41.812548  4164 net.cpp:367] ReLU15 -> Eltwise7 (in-place)
I1101 13:43:41.812867  4164 net.cpp:122] Setting up ReLU15
I1101 13:43:41.812875  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.812891  4164 net.cpp:137] Memory required for data: 1127220224
I1101 13:43:41.812892  4164 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I1101 13:43:41.812896  4164 net.cpp:84] Creating Layer Eltwise7_ReLU15_0_split
I1101 13:43:41.812898  4164 net.cpp:406] Eltwise7_ReLU15_0_split <- Eltwise7
I1101 13:43:41.812902  4164 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I1101 13:43:41.812913  4164 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I1101 13:43:41.812940  4164 net.cpp:122] Setting up Eltwise7_ReLU15_0_split
I1101 13:43:41.812944  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.812947  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.812948  4164 net.cpp:137] Memory required for data: 1143997440
I1101 13:43:41.812950  4164 layer_factory.hpp:77] Creating layer Convolution17
I1101 13:43:41.812957  4164 net.cpp:84] Creating Layer Convolution17
I1101 13:43:41.812971  4164 net.cpp:406] Convolution17 <- Eltwise7_ReLU15_0_split_0
I1101 13:43:41.812975  4164 net.cpp:380] Convolution17 -> Convolution17
I1101 13:43:41.813699  4164 net.cpp:122] Setting up Convolution17
I1101 13:43:41.813706  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.813709  4164 net.cpp:137] Memory required for data: 1152386048
I1101 13:43:41.813714  4164 layer_factory.hpp:77] Creating layer BatchNorm17
I1101 13:43:41.813731  4164 net.cpp:84] Creating Layer BatchNorm17
I1101 13:43:41.813735  4164 net.cpp:406] BatchNorm17 <- Convolution17
I1101 13:43:41.813737  4164 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1101 13:43:41.813868  4164 net.cpp:122] Setting up BatchNorm17
I1101 13:43:41.813874  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.813875  4164 net.cpp:137] Memory required for data: 1160774656
I1101 13:43:41.813879  4164 layer_factory.hpp:77] Creating layer Scale17
I1101 13:43:41.813882  4164 net.cpp:84] Creating Layer Scale17
I1101 13:43:41.813885  4164 net.cpp:406] Scale17 <- Convolution17
I1101 13:43:41.813887  4164 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1101 13:43:41.813921  4164 layer_factory.hpp:77] Creating layer Scale17
I1101 13:43:41.814029  4164 net.cpp:122] Setting up Scale17
I1101 13:43:41.814034  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.814036  4164 net.cpp:137] Memory required for data: 1169163264
I1101 13:43:41.814052  4164 layer_factory.hpp:77] Creating layer ReLU16
I1101 13:43:41.814055  4164 net.cpp:84] Creating Layer ReLU16
I1101 13:43:41.814057  4164 net.cpp:406] ReLU16 <- Convolution17
I1101 13:43:41.814061  4164 net.cpp:367] ReLU16 -> Convolution17 (in-place)
I1101 13:43:41.814172  4164 net.cpp:122] Setting up ReLU16
I1101 13:43:41.814177  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.814178  4164 net.cpp:137] Memory required for data: 1177551872
I1101 13:43:41.814180  4164 layer_factory.hpp:77] Creating layer Convolution18
I1101 13:43:41.814185  4164 net.cpp:84] Creating Layer Convolution18
I1101 13:43:41.814188  4164 net.cpp:406] Convolution18 <- Convolution17
I1101 13:43:41.814193  4164 net.cpp:380] Convolution18 -> Convolution18
I1101 13:43:41.815100  4164 net.cpp:122] Setting up Convolution18
I1101 13:43:41.815109  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.815112  4164 net.cpp:137] Memory required for data: 1185940480
I1101 13:43:41.815116  4164 layer_factory.hpp:77] Creating layer BatchNorm18
I1101 13:43:41.815120  4164 net.cpp:84] Creating Layer BatchNorm18
I1101 13:43:41.815124  4164 net.cpp:406] BatchNorm18 <- Convolution18
I1101 13:43:41.815126  4164 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1101 13:43:41.815253  4164 net.cpp:122] Setting up BatchNorm18
I1101 13:43:41.815258  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.815259  4164 net.cpp:137] Memory required for data: 1194329088
I1101 13:43:41.815263  4164 layer_factory.hpp:77] Creating layer Scale18
I1101 13:43:41.815268  4164 net.cpp:84] Creating Layer Scale18
I1101 13:43:41.815270  4164 net.cpp:406] Scale18 <- Convolution18
I1101 13:43:41.815274  4164 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1101 13:43:41.815294  4164 layer_factory.hpp:77] Creating layer Scale18
I1101 13:43:41.815392  4164 net.cpp:122] Setting up Scale18
I1101 13:43:41.815397  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.815397  4164 net.cpp:137] Memory required for data: 1202717696
I1101 13:43:41.815400  4164 layer_factory.hpp:77] Creating layer Eltwise8
I1101 13:43:41.815412  4164 net.cpp:84] Creating Layer Eltwise8
I1101 13:43:41.815415  4164 net.cpp:406] Eltwise8 <- Convolution18
I1101 13:43:41.815418  4164 net.cpp:406] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I1101 13:43:41.815420  4164 net.cpp:380] Eltwise8 -> Eltwise8
I1101 13:43:41.815433  4164 net.cpp:122] Setting up Eltwise8
I1101 13:43:41.815438  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.815439  4164 net.cpp:137] Memory required for data: 1211106304
I1101 13:43:41.815441  4164 layer_factory.hpp:77] Creating layer ReLU17
I1101 13:43:41.815444  4164 net.cpp:84] Creating Layer ReLU17
I1101 13:43:41.815446  4164 net.cpp:406] ReLU17 <- Eltwise8
I1101 13:43:41.815448  4164 net.cpp:367] ReLU17 -> Eltwise8 (in-place)
I1101 13:43:41.815558  4164 net.cpp:122] Setting up ReLU17
I1101 13:43:41.815563  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.815567  4164 net.cpp:137] Memory required for data: 1219494912
I1101 13:43:41.815567  4164 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I1101 13:43:41.815572  4164 net.cpp:84] Creating Layer Eltwise8_ReLU17_0_split
I1101 13:43:41.815573  4164 net.cpp:406] Eltwise8_ReLU17_0_split <- Eltwise8
I1101 13:43:41.815577  4164 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I1101 13:43:41.815580  4164 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I1101 13:43:41.815605  4164 net.cpp:122] Setting up Eltwise8_ReLU17_0_split
I1101 13:43:41.815609  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.815613  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.815615  4164 net.cpp:137] Memory required for data: 1236272128
I1101 13:43:41.815618  4164 layer_factory.hpp:77] Creating layer Convolution19
I1101 13:43:41.815621  4164 net.cpp:84] Creating Layer Convolution19
I1101 13:43:41.815624  4164 net.cpp:406] Convolution19 <- Eltwise8_ReLU17_0_split_0
I1101 13:43:41.815629  4164 net.cpp:380] Convolution19 -> Convolution19
I1101 13:43:41.816359  4164 net.cpp:122] Setting up Convolution19
I1101 13:43:41.816366  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.816370  4164 net.cpp:137] Memory required for data: 1244660736
I1101 13:43:41.816373  4164 layer_factory.hpp:77] Creating layer BatchNorm19
I1101 13:43:41.816377  4164 net.cpp:84] Creating Layer BatchNorm19
I1101 13:43:41.816380  4164 net.cpp:406] BatchNorm19 <- Convolution19
I1101 13:43:41.816383  4164 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1101 13:43:41.816509  4164 net.cpp:122] Setting up BatchNorm19
I1101 13:43:41.816512  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.816514  4164 net.cpp:137] Memory required for data: 1253049344
I1101 13:43:41.816527  4164 layer_factory.hpp:77] Creating layer Scale19
I1101 13:43:41.816531  4164 net.cpp:84] Creating Layer Scale19
I1101 13:43:41.816534  4164 net.cpp:406] Scale19 <- Convolution19
I1101 13:43:41.816536  4164 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1101 13:43:41.816560  4164 layer_factory.hpp:77] Creating layer Scale19
I1101 13:43:41.816632  4164 net.cpp:122] Setting up Scale19
I1101 13:43:41.816637  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.816637  4164 net.cpp:137] Memory required for data: 1261437952
I1101 13:43:41.816642  4164 layer_factory.hpp:77] Creating layer ReLU18
I1101 13:43:41.816644  4164 net.cpp:84] Creating Layer ReLU18
I1101 13:43:41.816648  4164 net.cpp:406] ReLU18 <- Convolution19
I1101 13:43:41.816651  4164 net.cpp:367] ReLU18 -> Convolution19 (in-place)
I1101 13:43:41.816941  4164 net.cpp:122] Setting up ReLU18
I1101 13:43:41.816949  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.816951  4164 net.cpp:137] Memory required for data: 1269826560
I1101 13:43:41.816953  4164 layer_factory.hpp:77] Creating layer Convolution20
I1101 13:43:41.816959  4164 net.cpp:84] Creating Layer Convolution20
I1101 13:43:41.816962  4164 net.cpp:406] Convolution20 <- Convolution19
I1101 13:43:41.816965  4164 net.cpp:380] Convolution20 -> Convolution20
I1101 13:43:41.817714  4164 net.cpp:122] Setting up Convolution20
I1101 13:43:41.817723  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.817725  4164 net.cpp:137] Memory required for data: 1278215168
I1101 13:43:41.817728  4164 layer_factory.hpp:77] Creating layer BatchNorm20
I1101 13:43:41.817734  4164 net.cpp:84] Creating Layer BatchNorm20
I1101 13:43:41.817736  4164 net.cpp:406] BatchNorm20 <- Convolution20
I1101 13:43:41.817739  4164 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1101 13:43:41.817865  4164 net.cpp:122] Setting up BatchNorm20
I1101 13:43:41.817869  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.817872  4164 net.cpp:137] Memory required for data: 1286603776
I1101 13:43:41.817875  4164 layer_factory.hpp:77] Creating layer Scale20
I1101 13:43:41.817879  4164 net.cpp:84] Creating Layer Scale20
I1101 13:43:41.817881  4164 net.cpp:406] Scale20 <- Convolution20
I1101 13:43:41.817884  4164 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1101 13:43:41.817905  4164 layer_factory.hpp:77] Creating layer Scale20
I1101 13:43:41.817979  4164 net.cpp:122] Setting up Scale20
I1101 13:43:41.817984  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.817986  4164 net.cpp:137] Memory required for data: 1294992384
I1101 13:43:41.817989  4164 layer_factory.hpp:77] Creating layer Eltwise9
I1101 13:43:41.817992  4164 net.cpp:84] Creating Layer Eltwise9
I1101 13:43:41.817993  4164 net.cpp:406] Eltwise9 <- Convolution20
I1101 13:43:41.817996  4164 net.cpp:406] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I1101 13:43:41.818001  4164 net.cpp:380] Eltwise9 -> Eltwise9
I1101 13:43:41.818013  4164 net.cpp:122] Setting up Eltwise9
I1101 13:43:41.818017  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.818019  4164 net.cpp:137] Memory required for data: 1303380992
I1101 13:43:41.818022  4164 layer_factory.hpp:77] Creating layer ReLU19
I1101 13:43:41.818024  4164 net.cpp:84] Creating Layer ReLU19
I1101 13:43:41.818027  4164 net.cpp:406] ReLU19 <- Eltwise9
I1101 13:43:41.818030  4164 net.cpp:367] ReLU19 -> Eltwise9 (in-place)
I1101 13:43:41.818137  4164 net.cpp:122] Setting up ReLU19
I1101 13:43:41.818142  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.818145  4164 net.cpp:137] Memory required for data: 1311769600
I1101 13:43:41.818146  4164 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I1101 13:43:41.818150  4164 net.cpp:84] Creating Layer Eltwise9_ReLU19_0_split
I1101 13:43:41.818151  4164 net.cpp:406] Eltwise9_ReLU19_0_split <- Eltwise9
I1101 13:43:41.818155  4164 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I1101 13:43:41.818159  4164 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I1101 13:43:41.818186  4164 net.cpp:122] Setting up Eltwise9_ReLU19_0_split
I1101 13:43:41.818188  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.818192  4164 net.cpp:129] Top shape: 256 32 16 16 (2097152)
I1101 13:43:41.818193  4164 net.cpp:137] Memory required for data: 1328546816
I1101 13:43:41.818194  4164 layer_factory.hpp:77] Creating layer Convolution21
I1101 13:43:41.818199  4164 net.cpp:84] Creating Layer Convolution21
I1101 13:43:41.818202  4164 net.cpp:406] Convolution21 <- Eltwise9_ReLU19_0_split_0
I1101 13:43:41.818207  4164 net.cpp:380] Convolution21 -> Convolution21
I1101 13:43:41.819679  4164 net.cpp:122] Setting up Convolution21
I1101 13:43:41.819689  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.819691  4164 net.cpp:137] Memory required for data: 1332741120
I1101 13:43:41.819697  4164 layer_factory.hpp:77] Creating layer BatchNorm21
I1101 13:43:41.819702  4164 net.cpp:84] Creating Layer BatchNorm21
I1101 13:43:41.819705  4164 net.cpp:406] BatchNorm21 <- Convolution21
I1101 13:43:41.819708  4164 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1101 13:43:41.819839  4164 net.cpp:122] Setting up BatchNorm21
I1101 13:43:41.819842  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.819844  4164 net.cpp:137] Memory required for data: 1336935424
I1101 13:43:41.819855  4164 layer_factory.hpp:77] Creating layer Scale21
I1101 13:43:41.819861  4164 net.cpp:84] Creating Layer Scale21
I1101 13:43:41.819864  4164 net.cpp:406] Scale21 <- Convolution21
I1101 13:43:41.819866  4164 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1101 13:43:41.819914  4164 layer_factory.hpp:77] Creating layer Scale21
I1101 13:43:41.820001  4164 net.cpp:122] Setting up Scale21
I1101 13:43:41.820005  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.820008  4164 net.cpp:137] Memory required for data: 1341129728
I1101 13:43:41.820010  4164 layer_factory.hpp:77] Creating layer ReLU20
I1101 13:43:41.820015  4164 net.cpp:84] Creating Layer ReLU20
I1101 13:43:41.820030  4164 net.cpp:406] ReLU20 <- Convolution21
I1101 13:43:41.820034  4164 net.cpp:367] ReLU20 -> Convolution21 (in-place)
I1101 13:43:41.820224  4164 net.cpp:122] Setting up ReLU20
I1101 13:43:41.820231  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.820233  4164 net.cpp:137] Memory required for data: 1345324032
I1101 13:43:41.820235  4164 layer_factory.hpp:77] Creating layer Convolution22
I1101 13:43:41.820240  4164 net.cpp:84] Creating Layer Convolution22
I1101 13:43:41.820243  4164 net.cpp:406] Convolution22 <- Convolution21
I1101 13:43:41.820247  4164 net.cpp:380] Convolution22 -> Convolution22
I1101 13:43:41.821163  4164 net.cpp:122] Setting up Convolution22
I1101 13:43:41.821171  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.821174  4164 net.cpp:137] Memory required for data: 1349518336
I1101 13:43:41.821178  4164 layer_factory.hpp:77] Creating layer BatchNorm22
I1101 13:43:41.821182  4164 net.cpp:84] Creating Layer BatchNorm22
I1101 13:43:41.821185  4164 net.cpp:406] BatchNorm22 <- Convolution22
I1101 13:43:41.821188  4164 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1101 13:43:41.821315  4164 net.cpp:122] Setting up BatchNorm22
I1101 13:43:41.821319  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.821321  4164 net.cpp:137] Memory required for data: 1353712640
I1101 13:43:41.821326  4164 layer_factory.hpp:77] Creating layer Scale22
I1101 13:43:41.821328  4164 net.cpp:84] Creating Layer Scale22
I1101 13:43:41.821331  4164 net.cpp:406] Scale22 <- Convolution22
I1101 13:43:41.821334  4164 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1101 13:43:41.821357  4164 layer_factory.hpp:77] Creating layer Scale22
I1101 13:43:41.821430  4164 net.cpp:122] Setting up Scale22
I1101 13:43:41.821435  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.821436  4164 net.cpp:137] Memory required for data: 1357906944
I1101 13:43:41.821440  4164 layer_factory.hpp:77] Creating layer Convolution23
I1101 13:43:41.821446  4164 net.cpp:84] Creating Layer Convolution23
I1101 13:43:41.821449  4164 net.cpp:406] Convolution23 <- Eltwise9_ReLU19_0_split_1
I1101 13:43:41.821452  4164 net.cpp:380] Convolution23 -> Convolution23
I1101 13:43:41.822333  4164 net.cpp:122] Setting up Convolution23
I1101 13:43:41.822343  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.822347  4164 net.cpp:137] Memory required for data: 1362101248
I1101 13:43:41.822353  4164 layer_factory.hpp:77] Creating layer BatchNorm23
I1101 13:43:41.822360  4164 net.cpp:84] Creating Layer BatchNorm23
I1101 13:43:41.822365  4164 net.cpp:406] BatchNorm23 <- Convolution23
I1101 13:43:41.822371  4164 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1101 13:43:41.822563  4164 net.cpp:122] Setting up BatchNorm23
I1101 13:43:41.822572  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.822574  4164 net.cpp:137] Memory required for data: 1366295552
I1101 13:43:41.822580  4164 layer_factory.hpp:77] Creating layer Scale23
I1101 13:43:41.822587  4164 net.cpp:84] Creating Layer Scale23
I1101 13:43:41.822592  4164 net.cpp:406] Scale23 <- Convolution23
I1101 13:43:41.822597  4164 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1101 13:43:41.822630  4164 layer_factory.hpp:77] Creating layer Scale23
I1101 13:43:41.822753  4164 net.cpp:122] Setting up Scale23
I1101 13:43:41.822772  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.822777  4164 net.cpp:137] Memory required for data: 1370489856
I1101 13:43:41.822782  4164 layer_factory.hpp:77] Creating layer Eltwise10
I1101 13:43:41.822791  4164 net.cpp:84] Creating Layer Eltwise10
I1101 13:43:41.822795  4164 net.cpp:406] Eltwise10 <- Convolution22
I1101 13:43:41.822801  4164 net.cpp:406] Eltwise10 <- Convolution23
I1101 13:43:41.822808  4164 net.cpp:380] Eltwise10 -> Eltwise10
I1101 13:43:41.822829  4164 net.cpp:122] Setting up Eltwise10
I1101 13:43:41.822836  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.822841  4164 net.cpp:137] Memory required for data: 1374684160
I1101 13:43:41.822844  4164 layer_factory.hpp:77] Creating layer ReLU21
I1101 13:43:41.822863  4164 net.cpp:84] Creating Layer ReLU21
I1101 13:43:41.822867  4164 net.cpp:406] ReLU21 <- Eltwise10
I1101 13:43:41.822875  4164 net.cpp:367] ReLU21 -> Eltwise10 (in-place)
I1101 13:43:41.823053  4164 net.cpp:122] Setting up ReLU21
I1101 13:43:41.823062  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.823065  4164 net.cpp:137] Memory required for data: 1378878464
I1101 13:43:41.823070  4164 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I1101 13:43:41.823076  4164 net.cpp:84] Creating Layer Eltwise10_ReLU21_0_split
I1101 13:43:41.823078  4164 net.cpp:406] Eltwise10_ReLU21_0_split <- Eltwise10
I1101 13:43:41.823083  4164 net.cpp:380] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I1101 13:43:41.823091  4164 net.cpp:380] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I1101 13:43:41.823129  4164 net.cpp:122] Setting up Eltwise10_ReLU21_0_split
I1101 13:43:41.823138  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.823143  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.823145  4164 net.cpp:137] Memory required for data: 1387267072
I1101 13:43:41.823148  4164 layer_factory.hpp:77] Creating layer Convolution24
I1101 13:43:41.823158  4164 net.cpp:84] Creating Layer Convolution24
I1101 13:43:41.823163  4164 net.cpp:406] Convolution24 <- Eltwise10_ReLU21_0_split_0
I1101 13:43:41.823170  4164 net.cpp:380] Convolution24 -> Convolution24
I1101 13:43:41.824167  4164 net.cpp:122] Setting up Convolution24
I1101 13:43:41.824177  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.824180  4164 net.cpp:137] Memory required for data: 1391461376
I1101 13:43:41.824184  4164 layer_factory.hpp:77] Creating layer BatchNorm24
I1101 13:43:41.824187  4164 net.cpp:84] Creating Layer BatchNorm24
I1101 13:43:41.824190  4164 net.cpp:406] BatchNorm24 <- Convolution24
I1101 13:43:41.824194  4164 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1101 13:43:41.824326  4164 net.cpp:122] Setting up BatchNorm24
I1101 13:43:41.824329  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.824331  4164 net.cpp:137] Memory required for data: 1395655680
I1101 13:43:41.824335  4164 layer_factory.hpp:77] Creating layer Scale24
I1101 13:43:41.824338  4164 net.cpp:84] Creating Layer Scale24
I1101 13:43:41.824342  4164 net.cpp:406] Scale24 <- Convolution24
I1101 13:43:41.824344  4164 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1101 13:43:41.824368  4164 layer_factory.hpp:77] Creating layer Scale24
I1101 13:43:41.824450  4164 net.cpp:122] Setting up Scale24
I1101 13:43:41.824453  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.824455  4164 net.cpp:137] Memory required for data: 1399849984
I1101 13:43:41.824460  4164 layer_factory.hpp:77] Creating layer ReLU22
I1101 13:43:41.824463  4164 net.cpp:84] Creating Layer ReLU22
I1101 13:43:41.824465  4164 net.cpp:406] ReLU22 <- Convolution24
I1101 13:43:41.824468  4164 net.cpp:367] ReLU22 -> Convolution24 (in-place)
I1101 13:43:41.824582  4164 net.cpp:122] Setting up ReLU22
I1101 13:43:41.824587  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.824589  4164 net.cpp:137] Memory required for data: 1404044288
I1101 13:43:41.824591  4164 layer_factory.hpp:77] Creating layer Convolution25
I1101 13:43:41.824604  4164 net.cpp:84] Creating Layer Convolution25
I1101 13:43:41.824607  4164 net.cpp:406] Convolution25 <- Convolution24
I1101 13:43:41.824611  4164 net.cpp:380] Convolution25 -> Convolution25
I1101 13:43:41.825539  4164 net.cpp:122] Setting up Convolution25
I1101 13:43:41.825547  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.825549  4164 net.cpp:137] Memory required for data: 1408238592
I1101 13:43:41.825553  4164 layer_factory.hpp:77] Creating layer BatchNorm25
I1101 13:43:41.825557  4164 net.cpp:84] Creating Layer BatchNorm25
I1101 13:43:41.825562  4164 net.cpp:406] BatchNorm25 <- Convolution25
I1101 13:43:41.825564  4164 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1101 13:43:41.825695  4164 net.cpp:122] Setting up BatchNorm25
I1101 13:43:41.825700  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.825701  4164 net.cpp:137] Memory required for data: 1412432896
I1101 13:43:41.825706  4164 layer_factory.hpp:77] Creating layer Scale25
I1101 13:43:41.825709  4164 net.cpp:84] Creating Layer Scale25
I1101 13:43:41.825711  4164 net.cpp:406] Scale25 <- Convolution25
I1101 13:43:41.825713  4164 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1101 13:43:41.825736  4164 layer_factory.hpp:77] Creating layer Scale25
I1101 13:43:41.825814  4164 net.cpp:122] Setting up Scale25
I1101 13:43:41.825819  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.825820  4164 net.cpp:137] Memory required for data: 1416627200
I1101 13:43:41.825824  4164 layer_factory.hpp:77] Creating layer Eltwise11
I1101 13:43:41.825826  4164 net.cpp:84] Creating Layer Eltwise11
I1101 13:43:41.825829  4164 net.cpp:406] Eltwise11 <- Convolution25
I1101 13:43:41.825830  4164 net.cpp:406] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I1101 13:43:41.825834  4164 net.cpp:380] Eltwise11 -> Eltwise11
I1101 13:43:41.825846  4164 net.cpp:122] Setting up Eltwise11
I1101 13:43:41.825850  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.825852  4164 net.cpp:137] Memory required for data: 1420821504
I1101 13:43:41.825855  4164 layer_factory.hpp:77] Creating layer ReLU23
I1101 13:43:41.825857  4164 net.cpp:84] Creating Layer ReLU23
I1101 13:43:41.825860  4164 net.cpp:406] ReLU23 <- Eltwise11
I1101 13:43:41.825863  4164 net.cpp:367] ReLU23 -> Eltwise11 (in-place)
I1101 13:43:41.825973  4164 net.cpp:122] Setting up ReLU23
I1101 13:43:41.825978  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.825979  4164 net.cpp:137] Memory required for data: 1425015808
I1101 13:43:41.825981  4164 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I1101 13:43:41.825985  4164 net.cpp:84] Creating Layer Eltwise11_ReLU23_0_split
I1101 13:43:41.825987  4164 net.cpp:406] Eltwise11_ReLU23_0_split <- Eltwise11
I1101 13:43:41.825990  4164 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I1101 13:43:41.825994  4164 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I1101 13:43:41.826020  4164 net.cpp:122] Setting up Eltwise11_ReLU23_0_split
I1101 13:43:41.826023  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.826026  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.826027  4164 net.cpp:137] Memory required for data: 1433404416
I1101 13:43:41.826030  4164 layer_factory.hpp:77] Creating layer Convolution26
I1101 13:43:41.826035  4164 net.cpp:84] Creating Layer Convolution26
I1101 13:43:41.826037  4164 net.cpp:406] Convolution26 <- Eltwise11_ReLU23_0_split_0
I1101 13:43:41.826041  4164 net.cpp:380] Convolution26 -> Convolution26
I1101 13:43:41.826982  4164 net.cpp:122] Setting up Convolution26
I1101 13:43:41.826990  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.826992  4164 net.cpp:137] Memory required for data: 1437598720
I1101 13:43:41.826997  4164 layer_factory.hpp:77] Creating layer BatchNorm26
I1101 13:43:41.827002  4164 net.cpp:84] Creating Layer BatchNorm26
I1101 13:43:41.827004  4164 net.cpp:406] BatchNorm26 <- Convolution26
I1101 13:43:41.827008  4164 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1101 13:43:41.827147  4164 net.cpp:122] Setting up BatchNorm26
I1101 13:43:41.827152  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.827153  4164 net.cpp:137] Memory required for data: 1441793024
I1101 13:43:41.827157  4164 layer_factory.hpp:77] Creating layer Scale26
I1101 13:43:41.827162  4164 net.cpp:84] Creating Layer Scale26
I1101 13:43:41.827163  4164 net.cpp:406] Scale26 <- Convolution26
I1101 13:43:41.827165  4164 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1101 13:43:41.827203  4164 layer_factory.hpp:77] Creating layer Scale26
I1101 13:43:41.827277  4164 net.cpp:122] Setting up Scale26
I1101 13:43:41.827282  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.827284  4164 net.cpp:137] Memory required for data: 1445987328
I1101 13:43:41.827287  4164 layer_factory.hpp:77] Creating layer ReLU24
I1101 13:43:41.827291  4164 net.cpp:84] Creating Layer ReLU24
I1101 13:43:41.827292  4164 net.cpp:406] ReLU24 <- Convolution26
I1101 13:43:41.827294  4164 net.cpp:367] ReLU24 -> Convolution26 (in-place)
I1101 13:43:41.827580  4164 net.cpp:122] Setting up ReLU24
I1101 13:43:41.827589  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.827590  4164 net.cpp:137] Memory required for data: 1450181632
I1101 13:43:41.827592  4164 layer_factory.hpp:77] Creating layer Convolution27
I1101 13:43:41.827597  4164 net.cpp:84] Creating Layer Convolution27
I1101 13:43:41.827600  4164 net.cpp:406] Convolution27 <- Convolution26
I1101 13:43:41.827605  4164 net.cpp:380] Convolution27 -> Convolution27
I1101 13:43:41.828500  4164 net.cpp:122] Setting up Convolution27
I1101 13:43:41.828508  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.828510  4164 net.cpp:137] Memory required for data: 1454375936
I1101 13:43:41.828514  4164 layer_factory.hpp:77] Creating layer BatchNorm27
I1101 13:43:41.828518  4164 net.cpp:84] Creating Layer BatchNorm27
I1101 13:43:41.828521  4164 net.cpp:406] BatchNorm27 <- Convolution27
I1101 13:43:41.828524  4164 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1101 13:43:41.828660  4164 net.cpp:122] Setting up BatchNorm27
I1101 13:43:41.828665  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.828665  4164 net.cpp:137] Memory required for data: 1458570240
I1101 13:43:41.828670  4164 layer_factory.hpp:77] Creating layer Scale27
I1101 13:43:41.828682  4164 net.cpp:84] Creating Layer Scale27
I1101 13:43:41.828685  4164 net.cpp:406] Scale27 <- Convolution27
I1101 13:43:41.828688  4164 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1101 13:43:41.828711  4164 layer_factory.hpp:77] Creating layer Scale27
I1101 13:43:41.828788  4164 net.cpp:122] Setting up Scale27
I1101 13:43:41.828791  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.828794  4164 net.cpp:137] Memory required for data: 1462764544
I1101 13:43:41.828797  4164 layer_factory.hpp:77] Creating layer Eltwise12
I1101 13:43:41.828800  4164 net.cpp:84] Creating Layer Eltwise12
I1101 13:43:41.828802  4164 net.cpp:406] Eltwise12 <- Convolution27
I1101 13:43:41.828804  4164 net.cpp:406] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I1101 13:43:41.828807  4164 net.cpp:380] Eltwise12 -> Eltwise12
I1101 13:43:41.828825  4164 net.cpp:122] Setting up Eltwise12
I1101 13:43:41.828830  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.828831  4164 net.cpp:137] Memory required for data: 1466958848
I1101 13:43:41.828833  4164 layer_factory.hpp:77] Creating layer ReLU25
I1101 13:43:41.828835  4164 net.cpp:84] Creating Layer ReLU25
I1101 13:43:41.828837  4164 net.cpp:406] ReLU25 <- Eltwise12
I1101 13:43:41.828840  4164 net.cpp:367] ReLU25 -> Eltwise12 (in-place)
I1101 13:43:41.829125  4164 net.cpp:122] Setting up ReLU25
I1101 13:43:41.829133  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.829134  4164 net.cpp:137] Memory required for data: 1471153152
I1101 13:43:41.829136  4164 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I1101 13:43:41.829140  4164 net.cpp:84] Creating Layer Eltwise12_ReLU25_0_split
I1101 13:43:41.829143  4164 net.cpp:406] Eltwise12_ReLU25_0_split <- Eltwise12
I1101 13:43:41.829152  4164 net.cpp:380] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I1101 13:43:41.829157  4164 net.cpp:380] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I1101 13:43:41.829187  4164 net.cpp:122] Setting up Eltwise12_ReLU25_0_split
I1101 13:43:41.829191  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.829193  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.829195  4164 net.cpp:137] Memory required for data: 1479541760
I1101 13:43:41.829196  4164 layer_factory.hpp:77] Creating layer Convolution28
I1101 13:43:41.829202  4164 net.cpp:84] Creating Layer Convolution28
I1101 13:43:41.829205  4164 net.cpp:406] Convolution28 <- Eltwise12_ReLU25_0_split_0
I1101 13:43:41.829208  4164 net.cpp:380] Convolution28 -> Convolution28
I1101 13:43:41.830147  4164 net.cpp:122] Setting up Convolution28
I1101 13:43:41.830155  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.830157  4164 net.cpp:137] Memory required for data: 1483736064
I1101 13:43:41.830176  4164 layer_factory.hpp:77] Creating layer BatchNorm28
I1101 13:43:41.830181  4164 net.cpp:84] Creating Layer BatchNorm28
I1101 13:43:41.830183  4164 net.cpp:406] BatchNorm28 <- Convolution28
I1101 13:43:41.830186  4164 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1101 13:43:41.830322  4164 net.cpp:122] Setting up BatchNorm28
I1101 13:43:41.830327  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.830328  4164 net.cpp:137] Memory required for data: 1487930368
I1101 13:43:41.830332  4164 layer_factory.hpp:77] Creating layer Scale28
I1101 13:43:41.830337  4164 net.cpp:84] Creating Layer Scale28
I1101 13:43:41.830339  4164 net.cpp:406] Scale28 <- Convolution28
I1101 13:43:41.830343  4164 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1101 13:43:41.830365  4164 layer_factory.hpp:77] Creating layer Scale28
I1101 13:43:41.830451  4164 net.cpp:122] Setting up Scale28
I1101 13:43:41.830456  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.830458  4164 net.cpp:137] Memory required for data: 1492124672
I1101 13:43:41.830461  4164 layer_factory.hpp:77] Creating layer ReLU26
I1101 13:43:41.830466  4164 net.cpp:84] Creating Layer ReLU26
I1101 13:43:41.830468  4164 net.cpp:406] ReLU26 <- Convolution28
I1101 13:43:41.830471  4164 net.cpp:367] ReLU26 -> Convolution28 (in-place)
I1101 13:43:41.830588  4164 net.cpp:122] Setting up ReLU26
I1101 13:43:41.830593  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.830596  4164 net.cpp:137] Memory required for data: 1496318976
I1101 13:43:41.830597  4164 layer_factory.hpp:77] Creating layer Convolution29
I1101 13:43:41.830603  4164 net.cpp:84] Creating Layer Convolution29
I1101 13:43:41.830606  4164 net.cpp:406] Convolution29 <- Convolution28
I1101 13:43:41.830610  4164 net.cpp:380] Convolution29 -> Convolution29
I1101 13:43:41.831712  4164 net.cpp:122] Setting up Convolution29
I1101 13:43:41.831719  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.831722  4164 net.cpp:137] Memory required for data: 1500513280
I1101 13:43:41.831727  4164 layer_factory.hpp:77] Creating layer BatchNorm29
I1101 13:43:41.831732  4164 net.cpp:84] Creating Layer BatchNorm29
I1101 13:43:41.831734  4164 net.cpp:406] BatchNorm29 <- Convolution29
I1101 13:43:41.831737  4164 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1101 13:43:41.831877  4164 net.cpp:122] Setting up BatchNorm29
I1101 13:43:41.831882  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.831884  4164 net.cpp:137] Memory required for data: 1504707584
I1101 13:43:41.831888  4164 layer_factory.hpp:77] Creating layer Scale29
I1101 13:43:41.831892  4164 net.cpp:84] Creating Layer Scale29
I1101 13:43:41.831894  4164 net.cpp:406] Scale29 <- Convolution29
I1101 13:43:41.831897  4164 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1101 13:43:41.831920  4164 layer_factory.hpp:77] Creating layer Scale29
I1101 13:43:41.832000  4164 net.cpp:122] Setting up Scale29
I1101 13:43:41.832005  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.832013  4164 net.cpp:137] Memory required for data: 1508901888
I1101 13:43:41.832017  4164 layer_factory.hpp:77] Creating layer Eltwise13
I1101 13:43:41.832021  4164 net.cpp:84] Creating Layer Eltwise13
I1101 13:43:41.832022  4164 net.cpp:406] Eltwise13 <- Convolution29
I1101 13:43:41.832026  4164 net.cpp:406] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I1101 13:43:41.832028  4164 net.cpp:380] Eltwise13 -> Eltwise13
I1101 13:43:41.832042  4164 net.cpp:122] Setting up Eltwise13
I1101 13:43:41.832046  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.832047  4164 net.cpp:137] Memory required for data: 1513096192
I1101 13:43:41.832049  4164 layer_factory.hpp:77] Creating layer ReLU27
I1101 13:43:41.832052  4164 net.cpp:84] Creating Layer ReLU27
I1101 13:43:41.832054  4164 net.cpp:406] ReLU27 <- Eltwise13
I1101 13:43:41.832058  4164 net.cpp:367] ReLU27 -> Eltwise13 (in-place)
I1101 13:43:41.832175  4164 net.cpp:122] Setting up ReLU27
I1101 13:43:41.832180  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.832182  4164 net.cpp:137] Memory required for data: 1517290496
I1101 13:43:41.832185  4164 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I1101 13:43:41.832187  4164 net.cpp:84] Creating Layer Eltwise13_ReLU27_0_split
I1101 13:43:41.832190  4164 net.cpp:406] Eltwise13_ReLU27_0_split <- Eltwise13
I1101 13:43:41.832193  4164 net.cpp:380] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I1101 13:43:41.832197  4164 net.cpp:380] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I1101 13:43:41.832223  4164 net.cpp:122] Setting up Eltwise13_ReLU27_0_split
I1101 13:43:41.832228  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.832231  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.832231  4164 net.cpp:137] Memory required for data: 1525679104
I1101 13:43:41.832233  4164 layer_factory.hpp:77] Creating layer Convolution30
I1101 13:43:41.832239  4164 net.cpp:84] Creating Layer Convolution30
I1101 13:43:41.832242  4164 net.cpp:406] Convolution30 <- Eltwise13_ReLU27_0_split_0
I1101 13:43:41.832247  4164 net.cpp:380] Convolution30 -> Convolution30
I1101 13:43:41.833196  4164 net.cpp:122] Setting up Convolution30
I1101 13:43:41.833205  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.833209  4164 net.cpp:137] Memory required for data: 1529873408
I1101 13:43:41.833211  4164 layer_factory.hpp:77] Creating layer BatchNorm30
I1101 13:43:41.833215  4164 net.cpp:84] Creating Layer BatchNorm30
I1101 13:43:41.833218  4164 net.cpp:406] BatchNorm30 <- Convolution30
I1101 13:43:41.833222  4164 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1101 13:43:41.833358  4164 net.cpp:122] Setting up BatchNorm30
I1101 13:43:41.833361  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.833364  4164 net.cpp:137] Memory required for data: 1534067712
I1101 13:43:41.833367  4164 layer_factory.hpp:77] Creating layer Scale30
I1101 13:43:41.833371  4164 net.cpp:84] Creating Layer Scale30
I1101 13:43:41.833374  4164 net.cpp:406] Scale30 <- Convolution30
I1101 13:43:41.833376  4164 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1101 13:43:41.833400  4164 layer_factory.hpp:77] Creating layer Scale30
I1101 13:43:41.833477  4164 net.cpp:122] Setting up Scale30
I1101 13:43:41.833480  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.833482  4164 net.cpp:137] Memory required for data: 1538262016
I1101 13:43:41.833485  4164 layer_factory.hpp:77] Creating layer ReLU28
I1101 13:43:41.833488  4164 net.cpp:84] Creating Layer ReLU28
I1101 13:43:41.833489  4164 net.cpp:406] ReLU28 <- Convolution30
I1101 13:43:41.833493  4164 net.cpp:367] ReLU28 -> Convolution30 (in-place)
I1101 13:43:41.833608  4164 net.cpp:122] Setting up ReLU28
I1101 13:43:41.833613  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.833616  4164 net.cpp:137] Memory required for data: 1542456320
I1101 13:43:41.833617  4164 layer_factory.hpp:77] Creating layer Convolution31
I1101 13:43:41.833622  4164 net.cpp:84] Creating Layer Convolution31
I1101 13:43:41.833631  4164 net.cpp:406] Convolution31 <- Convolution30
I1101 13:43:41.833634  4164 net.cpp:380] Convolution31 -> Convolution31
I1101 13:43:41.834753  4164 net.cpp:122] Setting up Convolution31
I1101 13:43:41.834760  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.834763  4164 net.cpp:137] Memory required for data: 1546650624
I1101 13:43:41.834766  4164 layer_factory.hpp:77] Creating layer BatchNorm31
I1101 13:43:41.834771  4164 net.cpp:84] Creating Layer BatchNorm31
I1101 13:43:41.834774  4164 net.cpp:406] BatchNorm31 <- Convolution31
I1101 13:43:41.834779  4164 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1101 13:43:41.834913  4164 net.cpp:122] Setting up BatchNorm31
I1101 13:43:41.834918  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.834919  4164 net.cpp:137] Memory required for data: 1550844928
I1101 13:43:41.834923  4164 layer_factory.hpp:77] Creating layer Scale31
I1101 13:43:41.834926  4164 net.cpp:84] Creating Layer Scale31
I1101 13:43:41.834928  4164 net.cpp:406] Scale31 <- Convolution31
I1101 13:43:41.834931  4164 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1101 13:43:41.834954  4164 layer_factory.hpp:77] Creating layer Scale31
I1101 13:43:41.835033  4164 net.cpp:122] Setting up Scale31
I1101 13:43:41.835037  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.835039  4164 net.cpp:137] Memory required for data: 1555039232
I1101 13:43:41.835042  4164 layer_factory.hpp:77] Creating layer Eltwise14
I1101 13:43:41.835047  4164 net.cpp:84] Creating Layer Eltwise14
I1101 13:43:41.835047  4164 net.cpp:406] Eltwise14 <- Convolution31
I1101 13:43:41.835050  4164 net.cpp:406] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I1101 13:43:41.835054  4164 net.cpp:380] Eltwise14 -> Eltwise14
I1101 13:43:41.835067  4164 net.cpp:122] Setting up Eltwise14
I1101 13:43:41.835070  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.835072  4164 net.cpp:137] Memory required for data: 1559233536
I1101 13:43:41.835074  4164 layer_factory.hpp:77] Creating layer ReLU29
I1101 13:43:41.835078  4164 net.cpp:84] Creating Layer ReLU29
I1101 13:43:41.835079  4164 net.cpp:406] ReLU29 <- Eltwise14
I1101 13:43:41.835083  4164 net.cpp:367] ReLU29 -> Eltwise14 (in-place)
I1101 13:43:41.835197  4164 net.cpp:122] Setting up ReLU29
I1101 13:43:41.835202  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.835204  4164 net.cpp:137] Memory required for data: 1563427840
I1101 13:43:41.835206  4164 layer_factory.hpp:77] Creating layer Eltwise14_ReLU29_0_split
I1101 13:43:41.835211  4164 net.cpp:84] Creating Layer Eltwise14_ReLU29_0_split
I1101 13:43:41.835211  4164 net.cpp:406] Eltwise14_ReLU29_0_split <- Eltwise14
I1101 13:43:41.835214  4164 net.cpp:380] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_0
I1101 13:43:41.835219  4164 net.cpp:380] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_1
I1101 13:43:41.835247  4164 net.cpp:122] Setting up Eltwise14_ReLU29_0_split
I1101 13:43:41.835250  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.835253  4164 net.cpp:129] Top shape: 256 64 8 8 (1048576)
I1101 13:43:41.835254  4164 net.cpp:137] Memory required for data: 1571816448
I1101 13:43:41.835256  4164 layer_factory.hpp:77] Creating layer Convolution32
I1101 13:43:41.835261  4164 net.cpp:84] Creating Layer Convolution32
I1101 13:43:41.835263  4164 net.cpp:406] Convolution32 <- Eltwise14_ReLU29_0_split_0
I1101 13:43:41.835268  4164 net.cpp:380] Convolution32 -> Convolution32
I1101 13:43:41.836979  4164 net.cpp:122] Setting up Convolution32
I1101 13:43:41.836988  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.836990  4164 net.cpp:137] Memory required for data: 1573913600
I1101 13:43:41.836994  4164 layer_factory.hpp:77] Creating layer BatchNorm32
I1101 13:43:41.836999  4164 net.cpp:84] Creating Layer BatchNorm32
I1101 13:43:41.837002  4164 net.cpp:406] BatchNorm32 <- Convolution32
I1101 13:43:41.837005  4164 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1101 13:43:41.837139  4164 net.cpp:122] Setting up BatchNorm32
I1101 13:43:41.837152  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.837153  4164 net.cpp:137] Memory required for data: 1576010752
I1101 13:43:41.837157  4164 layer_factory.hpp:77] Creating layer Scale32
I1101 13:43:41.837162  4164 net.cpp:84] Creating Layer Scale32
I1101 13:43:41.837163  4164 net.cpp:406] Scale32 <- Convolution32
I1101 13:43:41.837167  4164 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1101 13:43:41.837189  4164 layer_factory.hpp:77] Creating layer Scale32
I1101 13:43:41.837263  4164 net.cpp:122] Setting up Scale32
I1101 13:43:41.837268  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.837270  4164 net.cpp:137] Memory required for data: 1578107904
I1101 13:43:41.837273  4164 layer_factory.hpp:77] Creating layer ReLU30
I1101 13:43:41.837276  4164 net.cpp:84] Creating Layer ReLU30
I1101 13:43:41.837278  4164 net.cpp:406] ReLU30 <- Convolution32
I1101 13:43:41.837280  4164 net.cpp:367] ReLU30 -> Convolution32 (in-place)
I1101 13:43:41.837579  4164 net.cpp:122] Setting up ReLU30
I1101 13:43:41.837586  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.837589  4164 net.cpp:137] Memory required for data: 1580205056
I1101 13:43:41.837590  4164 layer_factory.hpp:77] Creating layer Convolution33
I1101 13:43:41.837596  4164 net.cpp:84] Creating Layer Convolution33
I1101 13:43:41.837599  4164 net.cpp:406] Convolution33 <- Convolution32
I1101 13:43:41.837602  4164 net.cpp:380] Convolution33 -> Convolution33
I1101 13:43:41.839447  4164 net.cpp:122] Setting up Convolution33
I1101 13:43:41.839457  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.839459  4164 net.cpp:137] Memory required for data: 1582302208
I1101 13:43:41.839462  4164 layer_factory.hpp:77] Creating layer BatchNorm33
I1101 13:43:41.839467  4164 net.cpp:84] Creating Layer BatchNorm33
I1101 13:43:41.839469  4164 net.cpp:406] BatchNorm33 <- Convolution33
I1101 13:43:41.839474  4164 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1101 13:43:41.839606  4164 net.cpp:122] Setting up BatchNorm33
I1101 13:43:41.839609  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.839612  4164 net.cpp:137] Memory required for data: 1584399360
I1101 13:43:41.839617  4164 layer_factory.hpp:77] Creating layer Scale33
I1101 13:43:41.839619  4164 net.cpp:84] Creating Layer Scale33
I1101 13:43:41.839622  4164 net.cpp:406] Scale33 <- Convolution33
I1101 13:43:41.839624  4164 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1101 13:43:41.839648  4164 layer_factory.hpp:77] Creating layer Scale33
I1101 13:43:41.839720  4164 net.cpp:122] Setting up Scale33
I1101 13:43:41.839723  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.839725  4164 net.cpp:137] Memory required for data: 1586496512
I1101 13:43:41.839728  4164 layer_factory.hpp:77] Creating layer Convolution34
I1101 13:43:41.839733  4164 net.cpp:84] Creating Layer Convolution34
I1101 13:43:41.839737  4164 net.cpp:406] Convolution34 <- Eltwise14_ReLU29_0_split_1
I1101 13:43:41.839741  4164 net.cpp:380] Convolution34 -> Convolution34
I1101 13:43:41.840503  4164 net.cpp:122] Setting up Convolution34
I1101 13:43:41.840512  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.840513  4164 net.cpp:137] Memory required for data: 1588593664
I1101 13:43:41.840531  4164 layer_factory.hpp:77] Creating layer BatchNorm34
I1101 13:43:41.840538  4164 net.cpp:84] Creating Layer BatchNorm34
I1101 13:43:41.840539  4164 net.cpp:406] BatchNorm34 <- Convolution34
I1101 13:43:41.840543  4164 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I1101 13:43:41.840684  4164 net.cpp:122] Setting up BatchNorm34
I1101 13:43:41.840689  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.840690  4164 net.cpp:137] Memory required for data: 1590690816
I1101 13:43:41.840694  4164 layer_factory.hpp:77] Creating layer Scale34
I1101 13:43:41.840699  4164 net.cpp:84] Creating Layer Scale34
I1101 13:43:41.840703  4164 net.cpp:406] Scale34 <- Convolution34
I1101 13:43:41.840705  4164 net.cpp:367] Scale34 -> Convolution34 (in-place)
I1101 13:43:41.840737  4164 layer_factory.hpp:77] Creating layer Scale34
I1101 13:43:41.840829  4164 net.cpp:122] Setting up Scale34
I1101 13:43:41.840834  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.840837  4164 net.cpp:137] Memory required for data: 1592787968
I1101 13:43:41.840839  4164 layer_factory.hpp:77] Creating layer Eltwise15
I1101 13:43:41.840842  4164 net.cpp:84] Creating Layer Eltwise15
I1101 13:43:41.840844  4164 net.cpp:406] Eltwise15 <- Convolution33
I1101 13:43:41.840847  4164 net.cpp:406] Eltwise15 <- Convolution34
I1101 13:43:41.840852  4164 net.cpp:380] Eltwise15 -> Eltwise15
I1101 13:43:41.840876  4164 net.cpp:122] Setting up Eltwise15
I1101 13:43:41.840880  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.840881  4164 net.cpp:137] Memory required for data: 1594885120
I1101 13:43:41.840883  4164 layer_factory.hpp:77] Creating layer ReLU31
I1101 13:43:41.840886  4164 net.cpp:84] Creating Layer ReLU31
I1101 13:43:41.840889  4164 net.cpp:406] ReLU31 <- Eltwise15
I1101 13:43:41.840893  4164 net.cpp:367] ReLU31 -> Eltwise15 (in-place)
I1101 13:43:41.841207  4164 net.cpp:122] Setting up ReLU31
I1101 13:43:41.841214  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.841217  4164 net.cpp:137] Memory required for data: 1596982272
I1101 13:43:41.841219  4164 layer_factory.hpp:77] Creating layer Eltwise15_ReLU31_0_split
I1101 13:43:41.841238  4164 net.cpp:84] Creating Layer Eltwise15_ReLU31_0_split
I1101 13:43:41.841240  4164 net.cpp:406] Eltwise15_ReLU31_0_split <- Eltwise15
I1101 13:43:41.841244  4164 net.cpp:380] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_0
I1101 13:43:41.841249  4164 net.cpp:380] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_1
I1101 13:43:41.841292  4164 net.cpp:122] Setting up Eltwise15_ReLU31_0_split
I1101 13:43:41.841296  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.841298  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.841313  4164 net.cpp:137] Memory required for data: 1601176576
I1101 13:43:41.841315  4164 layer_factory.hpp:77] Creating layer Convolution35
I1101 13:43:41.841320  4164 net.cpp:84] Creating Layer Convolution35
I1101 13:43:41.841323  4164 net.cpp:406] Convolution35 <- Eltwise15_ReLU31_0_split_0
I1101 13:43:41.841327  4164 net.cpp:380] Convolution35 -> Convolution35
I1101 13:43:41.843152  4164 net.cpp:122] Setting up Convolution35
I1101 13:43:41.843160  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.843163  4164 net.cpp:137] Memory required for data: 1603273728
I1101 13:43:41.843168  4164 layer_factory.hpp:77] Creating layer BatchNorm35
I1101 13:43:41.843170  4164 net.cpp:84] Creating Layer BatchNorm35
I1101 13:43:41.843173  4164 net.cpp:406] BatchNorm35 <- Convolution35
I1101 13:43:41.843176  4164 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I1101 13:43:41.843338  4164 net.cpp:122] Setting up BatchNorm35
I1101 13:43:41.843343  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.843344  4164 net.cpp:137] Memory required for data: 1605370880
I1101 13:43:41.843364  4164 layer_factory.hpp:77] Creating layer Scale35
I1101 13:43:41.843367  4164 net.cpp:84] Creating Layer Scale35
I1101 13:43:41.843369  4164 net.cpp:406] Scale35 <- Convolution35
I1101 13:43:41.843371  4164 net.cpp:367] Scale35 -> Convolution35 (in-place)
I1101 13:43:41.843395  4164 layer_factory.hpp:77] Creating layer Scale35
I1101 13:43:41.843482  4164 net.cpp:122] Setting up Scale35
I1101 13:43:41.843485  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.843487  4164 net.cpp:137] Memory required for data: 1607468032
I1101 13:43:41.843490  4164 layer_factory.hpp:77] Creating layer ReLU32
I1101 13:43:41.843493  4164 net.cpp:84] Creating Layer ReLU32
I1101 13:43:41.843495  4164 net.cpp:406] ReLU32 <- Convolution35
I1101 13:43:41.843498  4164 net.cpp:367] ReLU32 -> Convolution35 (in-place)
I1101 13:43:41.843617  4164 net.cpp:122] Setting up ReLU32
I1101 13:43:41.843622  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.843631  4164 net.cpp:137] Memory required for data: 1609565184
I1101 13:43:41.843633  4164 layer_factory.hpp:77] Creating layer Convolution36
I1101 13:43:41.843639  4164 net.cpp:84] Creating Layer Convolution36
I1101 13:43:41.843642  4164 net.cpp:406] Convolution36 <- Convolution35
I1101 13:43:41.843646  4164 net.cpp:380] Convolution36 -> Convolution36
I1101 13:43:41.845465  4164 net.cpp:122] Setting up Convolution36
I1101 13:43:41.845474  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.845475  4164 net.cpp:137] Memory required for data: 1611662336
I1101 13:43:41.845479  4164 layer_factory.hpp:77] Creating layer BatchNorm36
I1101 13:43:41.845484  4164 net.cpp:84] Creating Layer BatchNorm36
I1101 13:43:41.845487  4164 net.cpp:406] BatchNorm36 <- Convolution36
I1101 13:43:41.845490  4164 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I1101 13:43:41.845624  4164 net.cpp:122] Setting up BatchNorm36
I1101 13:43:41.845629  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.845631  4164 net.cpp:137] Memory required for data: 1613759488
I1101 13:43:41.845635  4164 layer_factory.hpp:77] Creating layer Scale36
I1101 13:43:41.845639  4164 net.cpp:84] Creating Layer Scale36
I1101 13:43:41.845641  4164 net.cpp:406] Scale36 <- Convolution36
I1101 13:43:41.845643  4164 net.cpp:367] Scale36 -> Convolution36 (in-place)
I1101 13:43:41.845681  4164 layer_factory.hpp:77] Creating layer Scale36
I1101 13:43:41.845795  4164 net.cpp:122] Setting up Scale36
I1101 13:43:41.845799  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.845801  4164 net.cpp:137] Memory required for data: 1615856640
I1101 13:43:41.845819  4164 layer_factory.hpp:77] Creating layer Eltwise16
I1101 13:43:41.845824  4164 net.cpp:84] Creating Layer Eltwise16
I1101 13:43:41.845825  4164 net.cpp:406] Eltwise16 <- Convolution36
I1101 13:43:41.845829  4164 net.cpp:406] Eltwise16 <- Eltwise15_ReLU31_0_split_1
I1101 13:43:41.845832  4164 net.cpp:380] Eltwise16 -> Eltwise16
I1101 13:43:41.845845  4164 net.cpp:122] Setting up Eltwise16
I1101 13:43:41.845849  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.845851  4164 net.cpp:137] Memory required for data: 1617953792
I1101 13:43:41.845852  4164 layer_factory.hpp:77] Creating layer ReLU33
I1101 13:43:41.845855  4164 net.cpp:84] Creating Layer ReLU33
I1101 13:43:41.845859  4164 net.cpp:406] ReLU33 <- Eltwise16
I1101 13:43:41.845875  4164 net.cpp:367] ReLU33 -> Eltwise16 (in-place)
I1101 13:43:41.846019  4164 net.cpp:122] Setting up ReLU33
I1101 13:43:41.846024  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.846025  4164 net.cpp:137] Memory required for data: 1620050944
I1101 13:43:41.846029  4164 layer_factory.hpp:77] Creating layer Eltwise16_ReLU33_0_split
I1101 13:43:41.846031  4164 net.cpp:84] Creating Layer Eltwise16_ReLU33_0_split
I1101 13:43:41.846034  4164 net.cpp:406] Eltwise16_ReLU33_0_split <- Eltwise16
I1101 13:43:41.846037  4164 net.cpp:380] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_0
I1101 13:43:41.846041  4164 net.cpp:380] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_1
I1101 13:43:41.846086  4164 net.cpp:122] Setting up Eltwise16_ReLU33_0_split
I1101 13:43:41.846091  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.846093  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.846094  4164 net.cpp:137] Memory required for data: 1624245248
I1101 13:43:41.846096  4164 layer_factory.hpp:77] Creating layer Convolution37
I1101 13:43:41.846102  4164 net.cpp:84] Creating Layer Convolution37
I1101 13:43:41.846105  4164 net.cpp:406] Convolution37 <- Eltwise16_ReLU33_0_split_0
I1101 13:43:41.846108  4164 net.cpp:380] Convolution37 -> Convolution37
I1101 13:43:41.848443  4164 net.cpp:122] Setting up Convolution37
I1101 13:43:41.848453  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.848455  4164 net.cpp:137] Memory required for data: 1626342400
I1101 13:43:41.848474  4164 layer_factory.hpp:77] Creating layer BatchNorm37
I1101 13:43:41.848479  4164 net.cpp:84] Creating Layer BatchNorm37
I1101 13:43:41.848489  4164 net.cpp:406] BatchNorm37 <- Convolution37
I1101 13:43:41.848495  4164 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I1101 13:43:41.848634  4164 net.cpp:122] Setting up BatchNorm37
I1101 13:43:41.848637  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.848639  4164 net.cpp:137] Memory required for data: 1628439552
I1101 13:43:41.848660  4164 layer_factory.hpp:77] Creating layer Scale37
I1101 13:43:41.848665  4164 net.cpp:84] Creating Layer Scale37
I1101 13:43:41.848667  4164 net.cpp:406] Scale37 <- Convolution37
I1101 13:43:41.848670  4164 net.cpp:367] Scale37 -> Convolution37 (in-place)
I1101 13:43:41.848721  4164 layer_factory.hpp:77] Creating layer Scale37
I1101 13:43:41.848809  4164 net.cpp:122] Setting up Scale37
I1101 13:43:41.848814  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.848815  4164 net.cpp:137] Memory required for data: 1630536704
I1101 13:43:41.848819  4164 layer_factory.hpp:77] Creating layer ReLU34
I1101 13:43:41.848834  4164 net.cpp:84] Creating Layer ReLU34
I1101 13:43:41.848836  4164 net.cpp:406] ReLU34 <- Convolution37
I1101 13:43:41.848839  4164 net.cpp:367] ReLU34 -> Convolution37 (in-place)
I1101 13:43:41.848973  4164 net.cpp:122] Setting up ReLU34
I1101 13:43:41.848978  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.848979  4164 net.cpp:137] Memory required for data: 1632633856
I1101 13:43:41.848981  4164 layer_factory.hpp:77] Creating layer Convolution38
I1101 13:43:41.848987  4164 net.cpp:84] Creating Layer Convolution38
I1101 13:43:41.849002  4164 net.cpp:406] Convolution38 <- Convolution37
I1101 13:43:41.849006  4164 net.cpp:380] Convolution38 -> Convolution38
I1101 13:43:41.850826  4164 net.cpp:122] Setting up Convolution38
I1101 13:43:41.850833  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.850836  4164 net.cpp:137] Memory required for data: 1634731008
I1101 13:43:41.850839  4164 layer_factory.hpp:77] Creating layer BatchNorm38
I1101 13:43:41.850844  4164 net.cpp:84] Creating Layer BatchNorm38
I1101 13:43:41.850847  4164 net.cpp:406] BatchNorm38 <- Convolution38
I1101 13:43:41.850852  4164 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I1101 13:43:41.851016  4164 net.cpp:122] Setting up BatchNorm38
I1101 13:43:41.851020  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.851022  4164 net.cpp:137] Memory required for data: 1636828160
I1101 13:43:41.851040  4164 layer_factory.hpp:77] Creating layer Scale38
I1101 13:43:41.851045  4164 net.cpp:84] Creating Layer Scale38
I1101 13:43:41.851047  4164 net.cpp:406] Scale38 <- Convolution38
I1101 13:43:41.851049  4164 net.cpp:367] Scale38 -> Convolution38 (in-place)
I1101 13:43:41.851073  4164 layer_factory.hpp:77] Creating layer Scale38
I1101 13:43:41.851158  4164 net.cpp:122] Setting up Scale38
I1101 13:43:41.851162  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.851164  4164 net.cpp:137] Memory required for data: 1638925312
I1101 13:43:41.851167  4164 layer_factory.hpp:77] Creating layer Eltwise17
I1101 13:43:41.851171  4164 net.cpp:84] Creating Layer Eltwise17
I1101 13:43:41.851172  4164 net.cpp:406] Eltwise17 <- Convolution38
I1101 13:43:41.851176  4164 net.cpp:406] Eltwise17 <- Eltwise16_ReLU33_0_split_1
I1101 13:43:41.851179  4164 net.cpp:380] Eltwise17 -> Eltwise17
I1101 13:43:41.851191  4164 net.cpp:122] Setting up Eltwise17
I1101 13:43:41.851196  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.851197  4164 net.cpp:137] Memory required for data: 1641022464
I1101 13:43:41.851198  4164 layer_factory.hpp:77] Creating layer ReLU35
I1101 13:43:41.851202  4164 net.cpp:84] Creating Layer ReLU35
I1101 13:43:41.851203  4164 net.cpp:406] ReLU35 <- Eltwise17
I1101 13:43:41.851207  4164 net.cpp:367] ReLU35 -> Eltwise17 (in-place)
I1101 13:43:41.851325  4164 net.cpp:122] Setting up ReLU35
I1101 13:43:41.851330  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.851330  4164 net.cpp:137] Memory required for data: 1643119616
I1101 13:43:41.851332  4164 layer_factory.hpp:77] Creating layer Eltwise17_ReLU35_0_split
I1101 13:43:41.851342  4164 net.cpp:84] Creating Layer Eltwise17_ReLU35_0_split
I1101 13:43:41.851346  4164 net.cpp:406] Eltwise17_ReLU35_0_split <- Eltwise17
I1101 13:43:41.851348  4164 net.cpp:380] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_0
I1101 13:43:41.851352  4164 net.cpp:380] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_1
I1101 13:43:41.851382  4164 net.cpp:122] Setting up Eltwise17_ReLU35_0_split
I1101 13:43:41.851385  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.851387  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.851389  4164 net.cpp:137] Memory required for data: 1647313920
I1101 13:43:41.851392  4164 layer_factory.hpp:77] Creating layer Convolution39
I1101 13:43:41.851397  4164 net.cpp:84] Creating Layer Convolution39
I1101 13:43:41.851399  4164 net.cpp:406] Convolution39 <- Eltwise17_ReLU35_0_split_0
I1101 13:43:41.851402  4164 net.cpp:380] Convolution39 -> Convolution39
I1101 13:43:41.853197  4164 net.cpp:122] Setting up Convolution39
I1101 13:43:41.853206  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.853209  4164 net.cpp:137] Memory required for data: 1649411072
I1101 13:43:41.853211  4164 layer_factory.hpp:77] Creating layer BatchNorm39
I1101 13:43:41.853216  4164 net.cpp:84] Creating Layer BatchNorm39
I1101 13:43:41.853219  4164 net.cpp:406] BatchNorm39 <- Convolution39
I1101 13:43:41.853222  4164 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I1101 13:43:41.853387  4164 net.cpp:122] Setting up BatchNorm39
I1101 13:43:41.853391  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.853394  4164 net.cpp:137] Memory required for data: 1651508224
I1101 13:43:41.853397  4164 layer_factory.hpp:77] Creating layer Scale39
I1101 13:43:41.853415  4164 net.cpp:84] Creating Layer Scale39
I1101 13:43:41.853417  4164 net.cpp:406] Scale39 <- Convolution39
I1101 13:43:41.853420  4164 net.cpp:367] Scale39 -> Convolution39 (in-place)
I1101 13:43:41.853468  4164 layer_factory.hpp:77] Creating layer Scale39
I1101 13:43:41.853557  4164 net.cpp:122] Setting up Scale39
I1101 13:43:41.853564  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.853565  4164 net.cpp:137] Memory required for data: 1653605376
I1101 13:43:41.853582  4164 layer_factory.hpp:77] Creating layer ReLU36
I1101 13:43:41.853586  4164 net.cpp:84] Creating Layer ReLU36
I1101 13:43:41.853588  4164 net.cpp:406] ReLU36 <- Convolution39
I1101 13:43:41.853591  4164 net.cpp:367] ReLU36 -> Convolution39 (in-place)
I1101 13:43:41.853761  4164 net.cpp:122] Setting up ReLU36
I1101 13:43:41.853768  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.853770  4164 net.cpp:137] Memory required for data: 1655702528
I1101 13:43:41.853772  4164 layer_factory.hpp:77] Creating layer Convolution40
I1101 13:43:41.853790  4164 net.cpp:84] Creating Layer Convolution40
I1101 13:43:41.853792  4164 net.cpp:406] Convolution40 <- Convolution39
I1101 13:43:41.853796  4164 net.cpp:380] Convolution40 -> Convolution40
I1101 13:43:41.856550  4164 net.cpp:122] Setting up Convolution40
I1101 13:43:41.856566  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.856570  4164 net.cpp:137] Memory required for data: 1657799680
I1101 13:43:41.856577  4164 layer_factory.hpp:77] Creating layer BatchNorm40
I1101 13:43:41.856585  4164 net.cpp:84] Creating Layer BatchNorm40
I1101 13:43:41.856586  4164 net.cpp:406] BatchNorm40 <- Convolution40
I1101 13:43:41.856592  4164 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I1101 13:43:41.856777  4164 net.cpp:122] Setting up BatchNorm40
I1101 13:43:41.856783  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.856786  4164 net.cpp:137] Memory required for data: 1659896832
I1101 13:43:41.856789  4164 layer_factory.hpp:77] Creating layer Scale40
I1101 13:43:41.856793  4164 net.cpp:84] Creating Layer Scale40
I1101 13:43:41.856796  4164 net.cpp:406] Scale40 <- Convolution40
I1101 13:43:41.856798  4164 net.cpp:367] Scale40 -> Convolution40 (in-place)
I1101 13:43:41.856822  4164 layer_factory.hpp:77] Creating layer Scale40
I1101 13:43:41.856945  4164 net.cpp:122] Setting up Scale40
I1101 13:43:41.856950  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.856951  4164 net.cpp:137] Memory required for data: 1661993984
I1101 13:43:41.856954  4164 layer_factory.hpp:77] Creating layer Eltwise18
I1101 13:43:41.856958  4164 net.cpp:84] Creating Layer Eltwise18
I1101 13:43:41.856961  4164 net.cpp:406] Eltwise18 <- Convolution40
I1101 13:43:41.856963  4164 net.cpp:406] Eltwise18 <- Eltwise17_ReLU35_0_split_1
I1101 13:43:41.856967  4164 net.cpp:380] Eltwise18 -> Eltwise18
I1101 13:43:41.856981  4164 net.cpp:122] Setting up Eltwise18
I1101 13:43:41.856984  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.856986  4164 net.cpp:137] Memory required for data: 1664091136
I1101 13:43:41.856987  4164 layer_factory.hpp:77] Creating layer ReLU37
I1101 13:43:41.856990  4164 net.cpp:84] Creating Layer ReLU37
I1101 13:43:41.856993  4164 net.cpp:406] ReLU37 <- Eltwise18
I1101 13:43:41.856997  4164 net.cpp:367] ReLU37 -> Eltwise18 (in-place)
I1101 13:43:41.857338  4164 net.cpp:122] Setting up ReLU37
I1101 13:43:41.857345  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.857347  4164 net.cpp:137] Memory required for data: 1666188288
I1101 13:43:41.857350  4164 layer_factory.hpp:77] Creating layer Eltwise18_ReLU37_0_split
I1101 13:43:41.857353  4164 net.cpp:84] Creating Layer Eltwise18_ReLU37_0_split
I1101 13:43:41.857355  4164 net.cpp:406] Eltwise18_ReLU37_0_split <- Eltwise18
I1101 13:43:41.857359  4164 net.cpp:380] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_0
I1101 13:43:41.857363  4164 net.cpp:380] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_1
I1101 13:43:41.857393  4164 net.cpp:122] Setting up Eltwise18_ReLU37_0_split
I1101 13:43:41.857398  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.857399  4164 net.cpp:129] Top shape: 256 128 4 4 (524288)
I1101 13:43:41.857401  4164 net.cpp:137] Memory required for data: 1670382592
I1101 13:43:41.857403  4164 layer_factory.hpp:77] Creating layer Convolution41
I1101 13:43:41.857409  4164 net.cpp:84] Creating Layer Convolution41
I1101 13:43:41.857410  4164 net.cpp:406] Convolution41 <- Eltwise18_ReLU37_0_split_0
I1101 13:43:41.857414  4164 net.cpp:380] Convolution41 -> Convolution41
I1101 13:43:41.860039  4164 net.cpp:122] Setting up Convolution41
I1101 13:43:41.860049  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.860050  4164 net.cpp:137] Memory required for data: 1671431168
I1101 13:43:41.860054  4164 layer_factory.hpp:77] Creating layer BatchNorm41
I1101 13:43:41.860059  4164 net.cpp:84] Creating Layer BatchNorm41
I1101 13:43:41.860060  4164 net.cpp:406] BatchNorm41 <- Convolution41
I1101 13:43:41.860064  4164 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I1101 13:43:41.860200  4164 net.cpp:122] Setting up BatchNorm41
I1101 13:43:41.860204  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.860205  4164 net.cpp:137] Memory required for data: 1672479744
I1101 13:43:41.860209  4164 layer_factory.hpp:77] Creating layer Scale41
I1101 13:43:41.860213  4164 net.cpp:84] Creating Layer Scale41
I1101 13:43:41.860215  4164 net.cpp:406] Scale41 <- Convolution41
I1101 13:43:41.860218  4164 net.cpp:367] Scale41 -> Convolution41 (in-place)
I1101 13:43:41.860240  4164 layer_factory.hpp:77] Creating layer Scale41
I1101 13:43:41.860314  4164 net.cpp:122] Setting up Scale41
I1101 13:43:41.860318  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.860321  4164 net.cpp:137] Memory required for data: 1673528320
I1101 13:43:41.860323  4164 layer_factory.hpp:77] Creating layer ReLU38
I1101 13:43:41.860327  4164 net.cpp:84] Creating Layer ReLU38
I1101 13:43:41.860328  4164 net.cpp:406] ReLU38 <- Convolution41
I1101 13:43:41.860332  4164 net.cpp:367] ReLU38 -> Convolution41 (in-place)
I1101 13:43:41.860446  4164 net.cpp:122] Setting up ReLU38
I1101 13:43:41.860451  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.860453  4164 net.cpp:137] Memory required for data: 1674576896
I1101 13:43:41.860461  4164 layer_factory.hpp:77] Creating layer Convolution42
I1101 13:43:41.860467  4164 net.cpp:84] Creating Layer Convolution42
I1101 13:43:41.860469  4164 net.cpp:406] Convolution42 <- Convolution41
I1101 13:43:41.860473  4164 net.cpp:380] Convolution42 -> Convolution42
I1101 13:43:41.865614  4164 net.cpp:122] Setting up Convolution42
I1101 13:43:41.865638  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.865640  4164 net.cpp:137] Memory required for data: 1675625472
I1101 13:43:41.865644  4164 layer_factory.hpp:77] Creating layer BatchNorm42
I1101 13:43:41.865649  4164 net.cpp:84] Creating Layer BatchNorm42
I1101 13:43:41.865651  4164 net.cpp:406] BatchNorm42 <- Convolution42
I1101 13:43:41.865655  4164 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I1101 13:43:41.865808  4164 net.cpp:122] Setting up BatchNorm42
I1101 13:43:41.865813  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.865813  4164 net.cpp:137] Memory required for data: 1676674048
I1101 13:43:41.865818  4164 layer_factory.hpp:77] Creating layer Scale42
I1101 13:43:41.865821  4164 net.cpp:84] Creating Layer Scale42
I1101 13:43:41.865823  4164 net.cpp:406] Scale42 <- Convolution42
I1101 13:43:41.865825  4164 net.cpp:367] Scale42 -> Convolution42 (in-place)
I1101 13:43:41.865849  4164 layer_factory.hpp:77] Creating layer Scale42
I1101 13:43:41.865924  4164 net.cpp:122] Setting up Scale42
I1101 13:43:41.865928  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.865929  4164 net.cpp:137] Memory required for data: 1677722624
I1101 13:43:41.865933  4164 layer_factory.hpp:77] Creating layer Convolution43
I1101 13:43:41.865938  4164 net.cpp:84] Creating Layer Convolution43
I1101 13:43:41.865941  4164 net.cpp:406] Convolution43 <- Eltwise18_ReLU37_0_split_1
I1101 13:43:41.865943  4164 net.cpp:380] Convolution43 -> Convolution43
I1101 13:43:41.866892  4164 net.cpp:122] Setting up Convolution43
I1101 13:43:41.866901  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.866904  4164 net.cpp:137] Memory required for data: 1678771200
I1101 13:43:41.866906  4164 layer_factory.hpp:77] Creating layer BatchNorm43
I1101 13:43:41.866911  4164 net.cpp:84] Creating Layer BatchNorm43
I1101 13:43:41.866914  4164 net.cpp:406] BatchNorm43 <- Convolution43
I1101 13:43:41.866916  4164 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I1101 13:43:41.867053  4164 net.cpp:122] Setting up BatchNorm43
I1101 13:43:41.867056  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.867058  4164 net.cpp:137] Memory required for data: 1679819776
I1101 13:43:41.867063  4164 layer_factory.hpp:77] Creating layer Scale43
I1101 13:43:41.867065  4164 net.cpp:84] Creating Layer Scale43
I1101 13:43:41.867067  4164 net.cpp:406] Scale43 <- Convolution43
I1101 13:43:41.867071  4164 net.cpp:367] Scale43 -> Convolution43 (in-place)
I1101 13:43:41.867094  4164 layer_factory.hpp:77] Creating layer Scale43
I1101 13:43:41.867172  4164 net.cpp:122] Setting up Scale43
I1101 13:43:41.867175  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.867177  4164 net.cpp:137] Memory required for data: 1680868352
I1101 13:43:41.867180  4164 layer_factory.hpp:77] Creating layer Eltwise19
I1101 13:43:41.867184  4164 net.cpp:84] Creating Layer Eltwise19
I1101 13:43:41.867185  4164 net.cpp:406] Eltwise19 <- Convolution42
I1101 13:43:41.867188  4164 net.cpp:406] Eltwise19 <- Convolution43
I1101 13:43:41.867192  4164 net.cpp:380] Eltwise19 -> Eltwise19
I1101 13:43:41.867204  4164 net.cpp:122] Setting up Eltwise19
I1101 13:43:41.867208  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.867209  4164 net.cpp:137] Memory required for data: 1681916928
I1101 13:43:41.867211  4164 layer_factory.hpp:77] Creating layer ReLU39
I1101 13:43:41.867214  4164 net.cpp:84] Creating Layer ReLU39
I1101 13:43:41.867218  4164 net.cpp:406] ReLU39 <- Eltwise19
I1101 13:43:41.867221  4164 net.cpp:367] ReLU39 -> Eltwise19 (in-place)
I1101 13:43:41.867360  4164 net.cpp:122] Setting up ReLU39
I1101 13:43:41.867373  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.867375  4164 net.cpp:137] Memory required for data: 1682965504
I1101 13:43:41.867377  4164 layer_factory.hpp:77] Creating layer Eltwise19_ReLU39_0_split
I1101 13:43:41.867380  4164 net.cpp:84] Creating Layer Eltwise19_ReLU39_0_split
I1101 13:43:41.867383  4164 net.cpp:406] Eltwise19_ReLU39_0_split <- Eltwise19
I1101 13:43:41.867385  4164 net.cpp:380] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_0
I1101 13:43:41.867390  4164 net.cpp:380] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_1
I1101 13:43:41.867419  4164 net.cpp:122] Setting up Eltwise19_ReLU39_0_split
I1101 13:43:41.867421  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.867424  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.867425  4164 net.cpp:137] Memory required for data: 1685062656
I1101 13:43:41.867427  4164 layer_factory.hpp:77] Creating layer Convolution44
I1101 13:43:41.867434  4164 net.cpp:84] Creating Layer Convolution44
I1101 13:43:41.867435  4164 net.cpp:406] Convolution44 <- Eltwise19_ReLU39_0_split_0
I1101 13:43:41.867439  4164 net.cpp:380] Convolution44 -> Convolution44
I1101 13:43:41.872620  4164 net.cpp:122] Setting up Convolution44
I1101 13:43:41.872629  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.872632  4164 net.cpp:137] Memory required for data: 1686111232
I1101 13:43:41.872635  4164 layer_factory.hpp:77] Creating layer BatchNorm44
I1101 13:43:41.872640  4164 net.cpp:84] Creating Layer BatchNorm44
I1101 13:43:41.872643  4164 net.cpp:406] BatchNorm44 <- Convolution44
I1101 13:43:41.872647  4164 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I1101 13:43:41.872788  4164 net.cpp:122] Setting up BatchNorm44
I1101 13:43:41.872792  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.872794  4164 net.cpp:137] Memory required for data: 1687159808
I1101 13:43:41.872798  4164 layer_factory.hpp:77] Creating layer Scale44
I1101 13:43:41.872802  4164 net.cpp:84] Creating Layer Scale44
I1101 13:43:41.872803  4164 net.cpp:406] Scale44 <- Convolution44
I1101 13:43:41.872805  4164 net.cpp:367] Scale44 -> Convolution44 (in-place)
I1101 13:43:41.872829  4164 layer_factory.hpp:77] Creating layer Scale44
I1101 13:43:41.872907  4164 net.cpp:122] Setting up Scale44
I1101 13:43:41.872911  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.872913  4164 net.cpp:137] Memory required for data: 1688208384
I1101 13:43:41.872916  4164 layer_factory.hpp:77] Creating layer ReLU40
I1101 13:43:41.872920  4164 net.cpp:84] Creating Layer ReLU40
I1101 13:43:41.872922  4164 net.cpp:406] ReLU40 <- Convolution44
I1101 13:43:41.872925  4164 net.cpp:367] ReLU40 -> Convolution44 (in-place)
I1101 13:43:41.873045  4164 net.cpp:122] Setting up ReLU40
I1101 13:43:41.873051  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.873054  4164 net.cpp:137] Memory required for data: 1689256960
I1101 13:43:41.873054  4164 layer_factory.hpp:77] Creating layer Convolution45
I1101 13:43:41.873060  4164 net.cpp:84] Creating Layer Convolution45
I1101 13:43:41.873062  4164 net.cpp:406] Convolution45 <- Convolution44
I1101 13:43:41.873066  4164 net.cpp:380] Convolution45 -> Convolution45
I1101 13:43:41.878199  4164 net.cpp:122] Setting up Convolution45
I1101 13:43:41.878207  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.878211  4164 net.cpp:137] Memory required for data: 1690305536
I1101 13:43:41.878216  4164 layer_factory.hpp:77] Creating layer BatchNorm45
I1101 13:43:41.878221  4164 net.cpp:84] Creating Layer BatchNorm45
I1101 13:43:41.878222  4164 net.cpp:406] BatchNorm45 <- Convolution45
I1101 13:43:41.878226  4164 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I1101 13:43:41.878406  4164 net.cpp:122] Setting up BatchNorm45
I1101 13:43:41.878410  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.878412  4164 net.cpp:137] Memory required for data: 1691354112
I1101 13:43:41.878422  4164 layer_factory.hpp:77] Creating layer Scale45
I1101 13:43:41.878427  4164 net.cpp:84] Creating Layer Scale45
I1101 13:43:41.878437  4164 net.cpp:406] Scale45 <- Convolution45
I1101 13:43:41.878440  4164 net.cpp:367] Scale45 -> Convolution45 (in-place)
I1101 13:43:41.878499  4164 layer_factory.hpp:77] Creating layer Scale45
I1101 13:43:41.878576  4164 net.cpp:122] Setting up Scale45
I1101 13:43:41.878581  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.878582  4164 net.cpp:137] Memory required for data: 1692402688
I1101 13:43:41.878584  4164 layer_factory.hpp:77] Creating layer Eltwise20
I1101 13:43:41.878589  4164 net.cpp:84] Creating Layer Eltwise20
I1101 13:43:41.878592  4164 net.cpp:406] Eltwise20 <- Convolution45
I1101 13:43:41.878594  4164 net.cpp:406] Eltwise20 <- Eltwise19_ReLU39_0_split_1
I1101 13:43:41.878597  4164 net.cpp:380] Eltwise20 -> Eltwise20
I1101 13:43:41.878612  4164 net.cpp:122] Setting up Eltwise20
I1101 13:43:41.878615  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.878617  4164 net.cpp:137] Memory required for data: 1693451264
I1101 13:43:41.878618  4164 layer_factory.hpp:77] Creating layer ReLU41
I1101 13:43:41.878621  4164 net.cpp:84] Creating Layer ReLU41
I1101 13:43:41.878623  4164 net.cpp:406] ReLU41 <- Eltwise20
I1101 13:43:41.878643  4164 net.cpp:367] ReLU41 -> Eltwise20 (in-place)
I1101 13:43:41.878777  4164 net.cpp:122] Setting up ReLU41
I1101 13:43:41.878782  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.878784  4164 net.cpp:137] Memory required for data: 1694499840
I1101 13:43:41.878785  4164 layer_factory.hpp:77] Creating layer Eltwise20_ReLU41_0_split
I1101 13:43:41.878789  4164 net.cpp:84] Creating Layer Eltwise20_ReLU41_0_split
I1101 13:43:41.878793  4164 net.cpp:406] Eltwise20_ReLU41_0_split <- Eltwise20
I1101 13:43:41.878795  4164 net.cpp:380] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_0
I1101 13:43:41.878799  4164 net.cpp:380] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_1
I1101 13:43:41.878857  4164 net.cpp:122] Setting up Eltwise20_ReLU41_0_split
I1101 13:43:41.878861  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.878865  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.878865  4164 net.cpp:137] Memory required for data: 1696596992
I1101 13:43:41.878882  4164 layer_factory.hpp:77] Creating layer Convolution46
I1101 13:43:41.878888  4164 net.cpp:84] Creating Layer Convolution46
I1101 13:43:41.878891  4164 net.cpp:406] Convolution46 <- Eltwise20_ReLU41_0_split_0
I1101 13:43:41.878895  4164 net.cpp:380] Convolution46 -> Convolution46
I1101 13:43:41.884137  4164 net.cpp:122] Setting up Convolution46
I1101 13:43:41.884160  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.884163  4164 net.cpp:137] Memory required for data: 1697645568
I1101 13:43:41.884167  4164 layer_factory.hpp:77] Creating layer BatchNorm46
I1101 13:43:41.884172  4164 net.cpp:84] Creating Layer BatchNorm46
I1101 13:43:41.884174  4164 net.cpp:406] BatchNorm46 <- Convolution46
I1101 13:43:41.884178  4164 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I1101 13:43:41.884335  4164 net.cpp:122] Setting up BatchNorm46
I1101 13:43:41.884340  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.884341  4164 net.cpp:137] Memory required for data: 1698694144
I1101 13:43:41.884359  4164 layer_factory.hpp:77] Creating layer Scale46
I1101 13:43:41.884362  4164 net.cpp:84] Creating Layer Scale46
I1101 13:43:41.884364  4164 net.cpp:406] Scale46 <- Convolution46
I1101 13:43:41.884367  4164 net.cpp:367] Scale46 -> Convolution46 (in-place)
I1101 13:43:41.884392  4164 layer_factory.hpp:77] Creating layer Scale46
I1101 13:43:41.884496  4164 net.cpp:122] Setting up Scale46
I1101 13:43:41.884501  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.884502  4164 net.cpp:137] Memory required for data: 1699742720
I1101 13:43:41.884506  4164 layer_factory.hpp:77] Creating layer ReLU42
I1101 13:43:41.884510  4164 net.cpp:84] Creating Layer ReLU42
I1101 13:43:41.884511  4164 net.cpp:406] ReLU42 <- Convolution46
I1101 13:43:41.884513  4164 net.cpp:367] ReLU42 -> Convolution46 (in-place)
I1101 13:43:41.884666  4164 net.cpp:122] Setting up ReLU42
I1101 13:43:41.884672  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.884673  4164 net.cpp:137] Memory required for data: 1700791296
I1101 13:43:41.884675  4164 layer_factory.hpp:77] Creating layer Convolution47
I1101 13:43:41.884681  4164 net.cpp:84] Creating Layer Convolution47
I1101 13:43:41.884683  4164 net.cpp:406] Convolution47 <- Convolution46
I1101 13:43:41.884687  4164 net.cpp:380] Convolution47 -> Convolution47
I1101 13:43:41.890399  4164 net.cpp:122] Setting up Convolution47
I1101 13:43:41.890424  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.890429  4164 net.cpp:137] Memory required for data: 1701839872
I1101 13:43:41.890457  4164 layer_factory.hpp:77] Creating layer BatchNorm47
I1101 13:43:41.890466  4164 net.cpp:84] Creating Layer BatchNorm47
I1101 13:43:41.890470  4164 net.cpp:406] BatchNorm47 <- Convolution47
I1101 13:43:41.890478  4164 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I1101 13:43:41.890651  4164 net.cpp:122] Setting up BatchNorm47
I1101 13:43:41.890655  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.890671  4164 net.cpp:137] Memory required for data: 1702888448
I1101 13:43:41.890676  4164 layer_factory.hpp:77] Creating layer Scale47
I1101 13:43:41.890681  4164 net.cpp:84] Creating Layer Scale47
I1101 13:43:41.890681  4164 net.cpp:406] Scale47 <- Convolution47
I1101 13:43:41.890684  4164 net.cpp:367] Scale47 -> Convolution47 (in-place)
I1101 13:43:41.890710  4164 layer_factory.hpp:77] Creating layer Scale47
I1101 13:43:41.890817  4164 net.cpp:122] Setting up Scale47
I1101 13:43:41.890821  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.890823  4164 net.cpp:137] Memory required for data: 1703937024
I1101 13:43:41.890826  4164 layer_factory.hpp:77] Creating layer Eltwise21
I1101 13:43:41.890830  4164 net.cpp:84] Creating Layer Eltwise21
I1101 13:43:41.890831  4164 net.cpp:406] Eltwise21 <- Convolution47
I1101 13:43:41.890835  4164 net.cpp:406] Eltwise21 <- Eltwise20_ReLU41_0_split_1
I1101 13:43:41.890838  4164 net.cpp:380] Eltwise21 -> Eltwise21
I1101 13:43:41.890851  4164 net.cpp:122] Setting up Eltwise21
I1101 13:43:41.890856  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.890856  4164 net.cpp:137] Memory required for data: 1704985600
I1101 13:43:41.890858  4164 layer_factory.hpp:77] Creating layer ReLU43
I1101 13:43:41.890862  4164 net.cpp:84] Creating Layer ReLU43
I1101 13:43:41.890866  4164 net.cpp:406] ReLU43 <- Eltwise21
I1101 13:43:41.890867  4164 net.cpp:367] ReLU43 -> Eltwise21 (in-place)
I1101 13:43:41.891185  4164 net.cpp:122] Setting up ReLU43
I1101 13:43:41.891191  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.891207  4164 net.cpp:137] Memory required for data: 1706034176
I1101 13:43:41.891209  4164 layer_factory.hpp:77] Creating layer Eltwise21_ReLU43_0_split
I1101 13:43:41.891212  4164 net.cpp:84] Creating Layer Eltwise21_ReLU43_0_split
I1101 13:43:41.891214  4164 net.cpp:406] Eltwise21_ReLU43_0_split <- Eltwise21
I1101 13:43:41.891218  4164 net.cpp:380] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_0
I1101 13:43:41.891223  4164 net.cpp:380] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_1
I1101 13:43:41.891255  4164 net.cpp:122] Setting up Eltwise21_ReLU43_0_split
I1101 13:43:41.891258  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.891261  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.891263  4164 net.cpp:137] Memory required for data: 1708131328
I1101 13:43:41.891264  4164 layer_factory.hpp:77] Creating layer Convolution48
I1101 13:43:41.891271  4164 net.cpp:84] Creating Layer Convolution48
I1101 13:43:41.891273  4164 net.cpp:406] Convolution48 <- Eltwise21_ReLU43_0_split_0
I1101 13:43:41.891278  4164 net.cpp:380] Convolution48 -> Convolution48
I1101 13:43:41.896292  4164 net.cpp:122] Setting up Convolution48
I1101 13:43:41.896301  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.896303  4164 net.cpp:137] Memory required for data: 1709179904
I1101 13:43:41.896317  4164 layer_factory.hpp:77] Creating layer BatchNorm48
I1101 13:43:41.896322  4164 net.cpp:84] Creating Layer BatchNorm48
I1101 13:43:41.896325  4164 net.cpp:406] BatchNorm48 <- Convolution48
I1101 13:43:41.896328  4164 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I1101 13:43:41.896510  4164 net.cpp:122] Setting up BatchNorm48
I1101 13:43:41.896514  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.896517  4164 net.cpp:137] Memory required for data: 1710228480
I1101 13:43:41.896520  4164 layer_factory.hpp:77] Creating layer Scale48
I1101 13:43:41.896525  4164 net.cpp:84] Creating Layer Scale48
I1101 13:43:41.896526  4164 net.cpp:406] Scale48 <- Convolution48
I1101 13:43:41.896529  4164 net.cpp:367] Scale48 -> Convolution48 (in-place)
I1101 13:43:41.896554  4164 layer_factory.hpp:77] Creating layer Scale48
I1101 13:43:41.896670  4164 net.cpp:122] Setting up Scale48
I1101 13:43:41.896674  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.896677  4164 net.cpp:137] Memory required for data: 1711277056
I1101 13:43:41.896679  4164 layer_factory.hpp:77] Creating layer ReLU44
I1101 13:43:41.896683  4164 net.cpp:84] Creating Layer ReLU44
I1101 13:43:41.896685  4164 net.cpp:406] ReLU44 <- Convolution48
I1101 13:43:41.896689  4164 net.cpp:367] ReLU44 -> Convolution48 (in-place)
I1101 13:43:41.897030  4164 net.cpp:122] Setting up ReLU44
I1101 13:43:41.897037  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.897039  4164 net.cpp:137] Memory required for data: 1712325632
I1101 13:43:41.897042  4164 layer_factory.hpp:77] Creating layer Convolution49
I1101 13:43:41.897048  4164 net.cpp:84] Creating Layer Convolution49
I1101 13:43:41.897052  4164 net.cpp:406] Convolution49 <- Convolution48
I1101 13:43:41.897055  4164 net.cpp:380] Convolution49 -> Convolution49
I1101 13:43:41.902439  4164 net.cpp:122] Setting up Convolution49
I1101 13:43:41.902449  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.902451  4164 net.cpp:137] Memory required for data: 1713374208
I1101 13:43:41.902456  4164 layer_factory.hpp:77] Creating layer BatchNorm49
I1101 13:43:41.902477  4164 net.cpp:84] Creating Layer BatchNorm49
I1101 13:43:41.902479  4164 net.cpp:406] BatchNorm49 <- Convolution49
I1101 13:43:41.902482  4164 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I1101 13:43:41.902645  4164 net.cpp:122] Setting up BatchNorm49
I1101 13:43:41.902649  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.902652  4164 net.cpp:137] Memory required for data: 1714422784
I1101 13:43:41.902655  4164 layer_factory.hpp:77] Creating layer Scale49
I1101 13:43:41.902658  4164 net.cpp:84] Creating Layer Scale49
I1101 13:43:41.902660  4164 net.cpp:406] Scale49 <- Convolution49
I1101 13:43:41.902663  4164 net.cpp:367] Scale49 -> Convolution49 (in-place)
I1101 13:43:41.902688  4164 layer_factory.hpp:77] Creating layer Scale49
I1101 13:43:41.902812  4164 net.cpp:122] Setting up Scale49
I1101 13:43:41.902817  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.902818  4164 net.cpp:137] Memory required for data: 1715471360
I1101 13:43:41.902822  4164 layer_factory.hpp:77] Creating layer Eltwise22
I1101 13:43:41.902825  4164 net.cpp:84] Creating Layer Eltwise22
I1101 13:43:41.902827  4164 net.cpp:406] Eltwise22 <- Convolution49
I1101 13:43:41.902830  4164 net.cpp:406] Eltwise22 <- Eltwise21_ReLU43_0_split_1
I1101 13:43:41.902834  4164 net.cpp:380] Eltwise22 -> Eltwise22
I1101 13:43:41.902848  4164 net.cpp:122] Setting up Eltwise22
I1101 13:43:41.902851  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.902853  4164 net.cpp:137] Memory required for data: 1716519936
I1101 13:43:41.902855  4164 layer_factory.hpp:77] Creating layer ReLU45
I1101 13:43:41.902858  4164 net.cpp:84] Creating Layer ReLU45
I1101 13:43:41.902860  4164 net.cpp:406] ReLU45 <- Eltwise22
I1101 13:43:41.902864  4164 net.cpp:367] ReLU45 -> Eltwise22 (in-place)
I1101 13:43:41.902988  4164 net.cpp:122] Setting up ReLU45
I1101 13:43:41.902993  4164 net.cpp:129] Top shape: 256 256 2 2 (262144)
I1101 13:43:41.903002  4164 net.cpp:137] Memory required for data: 1717568512
I1101 13:43:41.903005  4164 layer_factory.hpp:77] Creating layer Pooling1
I1101 13:43:41.903008  4164 net.cpp:84] Creating Layer Pooling1
I1101 13:43:41.903010  4164 net.cpp:406] Pooling1 <- Eltwise22
I1101 13:43:41.903014  4164 net.cpp:380] Pooling1 -> Pooling1
I1101 13:43:41.903162  4164 net.cpp:122] Setting up Pooling1
I1101 13:43:41.903167  4164 net.cpp:129] Top shape: 256 256 1 1 (65536)
I1101 13:43:41.903169  4164 net.cpp:137] Memory required for data: 1717830656
I1101 13:43:41.903172  4164 layer_factory.hpp:77] Creating layer InnerProduct1
I1101 13:43:41.903175  4164 net.cpp:84] Creating Layer InnerProduct1
I1101 13:43:41.903177  4164 net.cpp:406] InnerProduct1 <- Pooling1
I1101 13:43:41.903182  4164 net.cpp:380] InnerProduct1 -> InnerProduct1
I1101 13:43:41.903378  4164 net.cpp:122] Setting up InnerProduct1
I1101 13:43:41.903383  4164 net.cpp:129] Top shape: 256 62 (15872)
I1101 13:43:41.903384  4164 net.cpp:137] Memory required for data: 1717894144
I1101 13:43:41.903388  4164 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1101 13:43:41.903390  4164 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1101 13:43:41.903393  4164 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1101 13:43:41.903395  4164 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1101 13:43:41.903399  4164 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1101 13:43:41.903404  4164 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1101 13:43:41.903595  4164 net.cpp:122] Setting up SoftmaxWithLoss1
I1101 13:43:41.903601  4164 net.cpp:129] Top shape: (1)
I1101 13:43:41.903602  4164 net.cpp:132]     with loss weight 1
I1101 13:43:41.903614  4164 net.cpp:137] Memory required for data: 1717894148
I1101 13:43:41.903616  4164 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1101 13:43:41.903621  4164 net.cpp:198] InnerProduct1 needs backward computation.
I1101 13:43:41.903622  4164 net.cpp:198] Pooling1 needs backward computation.
I1101 13:43:41.903625  4164 net.cpp:198] ReLU45 needs backward computation.
I1101 13:43:41.903625  4164 net.cpp:198] Eltwise22 needs backward computation.
I1101 13:43:41.903628  4164 net.cpp:198] Scale49 needs backward computation.
I1101 13:43:41.903630  4164 net.cpp:198] BatchNorm49 needs backward computation.
I1101 13:43:41.903631  4164 net.cpp:198] Convolution49 needs backward computation.
I1101 13:43:41.903632  4164 net.cpp:198] ReLU44 needs backward computation.
I1101 13:43:41.903635  4164 net.cpp:198] Scale48 needs backward computation.
I1101 13:43:41.903636  4164 net.cpp:198] BatchNorm48 needs backward computation.
I1101 13:43:41.903637  4164 net.cpp:198] Convolution48 needs backward computation.
I1101 13:43:41.903640  4164 net.cpp:198] Eltwise21_ReLU43_0_split needs backward computation.
I1101 13:43:41.903642  4164 net.cpp:198] ReLU43 needs backward computation.
I1101 13:43:41.903643  4164 net.cpp:198] Eltwise21 needs backward computation.
I1101 13:43:41.903645  4164 net.cpp:198] Scale47 needs backward computation.
I1101 13:43:41.903648  4164 net.cpp:198] BatchNorm47 needs backward computation.
I1101 13:43:41.903650  4164 net.cpp:198] Convolution47 needs backward computation.
I1101 13:43:41.903652  4164 net.cpp:198] ReLU42 needs backward computation.
I1101 13:43:41.903654  4164 net.cpp:198] Scale46 needs backward computation.
I1101 13:43:41.903656  4164 net.cpp:198] BatchNorm46 needs backward computation.
I1101 13:43:41.903658  4164 net.cpp:198] Convolution46 needs backward computation.
I1101 13:43:41.903661  4164 net.cpp:198] Eltwise20_ReLU41_0_split needs backward computation.
I1101 13:43:41.903663  4164 net.cpp:198] ReLU41 needs backward computation.
I1101 13:43:41.903681  4164 net.cpp:198] Eltwise20 needs backward computation.
I1101 13:43:41.903683  4164 net.cpp:198] Scale45 needs backward computation.
I1101 13:43:41.903686  4164 net.cpp:198] BatchNorm45 needs backward computation.
I1101 13:43:41.903687  4164 net.cpp:198] Convolution45 needs backward computation.
I1101 13:43:41.903688  4164 net.cpp:198] ReLU40 needs backward computation.
I1101 13:43:41.903697  4164 net.cpp:198] Scale44 needs backward computation.
I1101 13:43:41.903698  4164 net.cpp:198] BatchNorm44 needs backward computation.
I1101 13:43:41.903699  4164 net.cpp:198] Convolution44 needs backward computation.
I1101 13:43:41.903702  4164 net.cpp:198] Eltwise19_ReLU39_0_split needs backward computation.
I1101 13:43:41.903704  4164 net.cpp:198] ReLU39 needs backward computation.
I1101 13:43:41.903718  4164 net.cpp:198] Eltwise19 needs backward computation.
I1101 13:43:41.903720  4164 net.cpp:198] Scale43 needs backward computation.
I1101 13:43:41.903723  4164 net.cpp:198] BatchNorm43 needs backward computation.
I1101 13:43:41.903724  4164 net.cpp:198] Convolution43 needs backward computation.
I1101 13:43:41.903726  4164 net.cpp:198] Scale42 needs backward computation.
I1101 13:43:41.903743  4164 net.cpp:198] BatchNorm42 needs backward computation.
I1101 13:43:41.903744  4164 net.cpp:198] Convolution42 needs backward computation.
I1101 13:43:41.903748  4164 net.cpp:198] ReLU38 needs backward computation.
I1101 13:43:41.903748  4164 net.cpp:198] Scale41 needs backward computation.
I1101 13:43:41.903750  4164 net.cpp:198] BatchNorm41 needs backward computation.
I1101 13:43:41.903751  4164 net.cpp:198] Convolution41 needs backward computation.
I1101 13:43:41.903754  4164 net.cpp:198] Eltwise18_ReLU37_0_split needs backward computation.
I1101 13:43:41.903756  4164 net.cpp:198] ReLU37 needs backward computation.
I1101 13:43:41.903758  4164 net.cpp:198] Eltwise18 needs backward computation.
I1101 13:43:41.903759  4164 net.cpp:198] Scale40 needs backward computation.
I1101 13:43:41.903761  4164 net.cpp:198] BatchNorm40 needs backward computation.
I1101 13:43:41.903764  4164 net.cpp:198] Convolution40 needs backward computation.
I1101 13:43:41.903765  4164 net.cpp:198] ReLU36 needs backward computation.
I1101 13:43:41.903767  4164 net.cpp:198] Scale39 needs backward computation.
I1101 13:43:41.903769  4164 net.cpp:198] BatchNorm39 needs backward computation.
I1101 13:43:41.903770  4164 net.cpp:198] Convolution39 needs backward computation.
I1101 13:43:41.903772  4164 net.cpp:198] Eltwise17_ReLU35_0_split needs backward computation.
I1101 13:43:41.903787  4164 net.cpp:198] ReLU35 needs backward computation.
I1101 13:43:41.903789  4164 net.cpp:198] Eltwise17 needs backward computation.
I1101 13:43:41.903792  4164 net.cpp:198] Scale38 needs backward computation.
I1101 13:43:41.903795  4164 net.cpp:198] BatchNorm38 needs backward computation.
I1101 13:43:41.903811  4164 net.cpp:198] Convolution38 needs backward computation.
I1101 13:43:41.903813  4164 net.cpp:198] ReLU34 needs backward computation.
I1101 13:43:41.903815  4164 net.cpp:198] Scale37 needs backward computation.
I1101 13:43:41.903816  4164 net.cpp:198] BatchNorm37 needs backward computation.
I1101 13:43:41.903818  4164 net.cpp:198] Convolution37 needs backward computation.
I1101 13:43:41.903821  4164 net.cpp:198] Eltwise16_ReLU33_0_split needs backward computation.
I1101 13:43:41.903822  4164 net.cpp:198] ReLU33 needs backward computation.
I1101 13:43:41.903825  4164 net.cpp:198] Eltwise16 needs backward computation.
I1101 13:43:41.903826  4164 net.cpp:198] Scale36 needs backward computation.
I1101 13:43:41.903828  4164 net.cpp:198] BatchNorm36 needs backward computation.
I1101 13:43:41.903831  4164 net.cpp:198] Convolution36 needs backward computation.
I1101 13:43:41.903832  4164 net.cpp:198] ReLU32 needs backward computation.
I1101 13:43:41.903834  4164 net.cpp:198] Scale35 needs backward computation.
I1101 13:43:41.903836  4164 net.cpp:198] BatchNorm35 needs backward computation.
I1101 13:43:41.903838  4164 net.cpp:198] Convolution35 needs backward computation.
I1101 13:43:41.903839  4164 net.cpp:198] Eltwise15_ReLU31_0_split needs backward computation.
I1101 13:43:41.903841  4164 net.cpp:198] ReLU31 needs backward computation.
I1101 13:43:41.903843  4164 net.cpp:198] Eltwise15 needs backward computation.
I1101 13:43:41.903846  4164 net.cpp:198] Scale34 needs backward computation.
I1101 13:43:41.903847  4164 net.cpp:198] BatchNorm34 needs backward computation.
I1101 13:43:41.903852  4164 net.cpp:198] Convolution34 needs backward computation.
I1101 13:43:41.903856  4164 net.cpp:198] Scale33 needs backward computation.
I1101 13:43:41.903857  4164 net.cpp:198] BatchNorm33 needs backward computation.
I1101 13:43:41.903858  4164 net.cpp:198] Convolution33 needs backward computation.
I1101 13:43:41.903861  4164 net.cpp:198] ReLU30 needs backward computation.
I1101 13:43:41.903862  4164 net.cpp:198] Scale32 needs backward computation.
I1101 13:43:41.903864  4164 net.cpp:198] BatchNorm32 needs backward computation.
I1101 13:43:41.903865  4164 net.cpp:198] Convolution32 needs backward computation.
I1101 13:43:41.903867  4164 net.cpp:198] Eltwise14_ReLU29_0_split needs backward computation.
I1101 13:43:41.903870  4164 net.cpp:198] ReLU29 needs backward computation.
I1101 13:43:41.903872  4164 net.cpp:198] Eltwise14 needs backward computation.
I1101 13:43:41.903873  4164 net.cpp:198] Scale31 needs backward computation.
I1101 13:43:41.903875  4164 net.cpp:198] BatchNorm31 needs backward computation.
I1101 13:43:41.903877  4164 net.cpp:198] Convolution31 needs backward computation.
I1101 13:43:41.903879  4164 net.cpp:198] ReLU28 needs backward computation.
I1101 13:43:41.903882  4164 net.cpp:198] Scale30 needs backward computation.
I1101 13:43:41.903883  4164 net.cpp:198] BatchNorm30 needs backward computation.
I1101 13:43:41.903885  4164 net.cpp:198] Convolution30 needs backward computation.
I1101 13:43:41.903887  4164 net.cpp:198] Eltwise13_ReLU27_0_split needs backward computation.
I1101 13:43:41.903888  4164 net.cpp:198] ReLU27 needs backward computation.
I1101 13:43:41.903890  4164 net.cpp:198] Eltwise13 needs backward computation.
I1101 13:43:41.903892  4164 net.cpp:198] Scale29 needs backward computation.
I1101 13:43:41.903895  4164 net.cpp:198] BatchNorm29 needs backward computation.
I1101 13:43:41.903897  4164 net.cpp:198] Convolution29 needs backward computation.
I1101 13:43:41.903898  4164 net.cpp:198] ReLU26 needs backward computation.
I1101 13:43:41.903900  4164 net.cpp:198] Scale28 needs backward computation.
I1101 13:43:41.903903  4164 net.cpp:198] BatchNorm28 needs backward computation.
I1101 13:43:41.903903  4164 net.cpp:198] Convolution28 needs backward computation.
I1101 13:43:41.903906  4164 net.cpp:198] Eltwise12_ReLU25_0_split needs backward computation.
I1101 13:43:41.903908  4164 net.cpp:198] ReLU25 needs backward computation.
I1101 13:43:41.903910  4164 net.cpp:198] Eltwise12 needs backward computation.
I1101 13:43:41.903913  4164 net.cpp:198] Scale27 needs backward computation.
I1101 13:43:41.903914  4164 net.cpp:198] BatchNorm27 needs backward computation.
I1101 13:43:41.903916  4164 net.cpp:198] Convolution27 needs backward computation.
I1101 13:43:41.903918  4164 net.cpp:198] ReLU24 needs backward computation.
I1101 13:43:41.903920  4164 net.cpp:198] Scale26 needs backward computation.
I1101 13:43:41.903921  4164 net.cpp:198] BatchNorm26 needs backward computation.
I1101 13:43:41.903923  4164 net.cpp:198] Convolution26 needs backward computation.
I1101 13:43:41.903925  4164 net.cpp:198] Eltwise11_ReLU23_0_split needs backward computation.
I1101 13:43:41.903928  4164 net.cpp:198] ReLU23 needs backward computation.
I1101 13:43:41.903929  4164 net.cpp:198] Eltwise11 needs backward computation.
I1101 13:43:41.903931  4164 net.cpp:198] Scale25 needs backward computation.
I1101 13:43:41.903934  4164 net.cpp:198] BatchNorm25 needs backward computation.
I1101 13:43:41.903935  4164 net.cpp:198] Convolution25 needs backward computation.
I1101 13:43:41.903936  4164 net.cpp:198] ReLU22 needs backward computation.
I1101 13:43:41.903939  4164 net.cpp:198] Scale24 needs backward computation.
I1101 13:43:41.903940  4164 net.cpp:198] BatchNorm24 needs backward computation.
I1101 13:43:41.903942  4164 net.cpp:198] Convolution24 needs backward computation.
I1101 13:43:41.903944  4164 net.cpp:198] Eltwise10_ReLU21_0_split needs backward computation.
I1101 13:43:41.903946  4164 net.cpp:198] ReLU21 needs backward computation.
I1101 13:43:41.903951  4164 net.cpp:198] Eltwise10 needs backward computation.
I1101 13:43:41.903954  4164 net.cpp:198] Scale23 needs backward computation.
I1101 13:43:41.903955  4164 net.cpp:198] BatchNorm23 needs backward computation.
I1101 13:43:41.903957  4164 net.cpp:198] Convolution23 needs backward computation.
I1101 13:43:41.903959  4164 net.cpp:198] Scale22 needs backward computation.
I1101 13:43:41.903961  4164 net.cpp:198] BatchNorm22 needs backward computation.
I1101 13:43:41.903964  4164 net.cpp:198] Convolution22 needs backward computation.
I1101 13:43:41.903965  4164 net.cpp:198] ReLU20 needs backward computation.
I1101 13:43:41.903967  4164 net.cpp:198] Scale21 needs backward computation.
I1101 13:43:41.903970  4164 net.cpp:198] BatchNorm21 needs backward computation.
I1101 13:43:41.903970  4164 net.cpp:198] Convolution21 needs backward computation.
I1101 13:43:41.903973  4164 net.cpp:198] Eltwise9_ReLU19_0_split needs backward computation.
I1101 13:43:41.903975  4164 net.cpp:198] ReLU19 needs backward computation.
I1101 13:43:41.903977  4164 net.cpp:198] Eltwise9 needs backward computation.
I1101 13:43:41.903980  4164 net.cpp:198] Scale20 needs backward computation.
I1101 13:43:41.903982  4164 net.cpp:198] BatchNorm20 needs backward computation.
I1101 13:43:41.903985  4164 net.cpp:198] Convolution20 needs backward computation.
I1101 13:43:41.903985  4164 net.cpp:198] ReLU18 needs backward computation.
I1101 13:43:41.903987  4164 net.cpp:198] Scale19 needs backward computation.
I1101 13:43:41.903990  4164 net.cpp:198] BatchNorm19 needs backward computation.
I1101 13:43:41.903991  4164 net.cpp:198] Convolution19 needs backward computation.
I1101 13:43:41.903993  4164 net.cpp:198] Eltwise8_ReLU17_0_split needs backward computation.
I1101 13:43:41.903995  4164 net.cpp:198] ReLU17 needs backward computation.
I1101 13:43:41.903997  4164 net.cpp:198] Eltwise8 needs backward computation.
I1101 13:43:41.904000  4164 net.cpp:198] Scale18 needs backward computation.
I1101 13:43:41.904001  4164 net.cpp:198] BatchNorm18 needs backward computation.
I1101 13:43:41.904002  4164 net.cpp:198] Convolution18 needs backward computation.
I1101 13:43:41.904006  4164 net.cpp:198] ReLU16 needs backward computation.
I1101 13:43:41.904006  4164 net.cpp:198] Scale17 needs backward computation.
I1101 13:43:41.904008  4164 net.cpp:198] BatchNorm17 needs backward computation.
I1101 13:43:41.904011  4164 net.cpp:198] Convolution17 needs backward computation.
I1101 13:43:41.904012  4164 net.cpp:198] Eltwise7_ReLU15_0_split needs backward computation.
I1101 13:43:41.904014  4164 net.cpp:198] ReLU15 needs backward computation.
I1101 13:43:41.904016  4164 net.cpp:198] Eltwise7 needs backward computation.
I1101 13:43:41.904018  4164 net.cpp:198] Scale16 needs backward computation.
I1101 13:43:41.904021  4164 net.cpp:198] BatchNorm16 needs backward computation.
I1101 13:43:41.904021  4164 net.cpp:198] Convolution16 needs backward computation.
I1101 13:43:41.904024  4164 net.cpp:198] ReLU14 needs backward computation.
I1101 13:43:41.904026  4164 net.cpp:198] Scale15 needs backward computation.
I1101 13:43:41.904028  4164 net.cpp:198] BatchNorm15 needs backward computation.
I1101 13:43:41.904029  4164 net.cpp:198] Convolution15 needs backward computation.
I1101 13:43:41.904031  4164 net.cpp:198] Eltwise6_ReLU13_0_split needs backward computation.
I1101 13:43:41.904033  4164 net.cpp:198] ReLU13 needs backward computation.
I1101 13:43:41.904036  4164 net.cpp:198] Eltwise6 needs backward computation.
I1101 13:43:41.904038  4164 net.cpp:198] Scale14 needs backward computation.
I1101 13:43:41.904039  4164 net.cpp:198] BatchNorm14 needs backward computation.
I1101 13:43:41.904042  4164 net.cpp:198] Convolution14 needs backward computation.
I1101 13:43:41.904044  4164 net.cpp:198] ReLU12 needs backward computation.
I1101 13:43:41.904045  4164 net.cpp:198] Scale13 needs backward computation.
I1101 13:43:41.904047  4164 net.cpp:198] BatchNorm13 needs backward computation.
I1101 13:43:41.904049  4164 net.cpp:198] Convolution13 needs backward computation.
I1101 13:43:41.904055  4164 net.cpp:198] Eltwise5_ReLU11_0_split needs backward computation.
I1101 13:43:41.904057  4164 net.cpp:198] ReLU11 needs backward computation.
I1101 13:43:41.904059  4164 net.cpp:198] Eltwise5 needs backward computation.
I1101 13:43:41.904062  4164 net.cpp:198] Scale12 needs backward computation.
I1101 13:43:41.904063  4164 net.cpp:198] BatchNorm12 needs backward computation.
I1101 13:43:41.904064  4164 net.cpp:198] Convolution12 needs backward computation.
I1101 13:43:41.904067  4164 net.cpp:198] Scale11 needs backward computation.
I1101 13:43:41.904068  4164 net.cpp:198] BatchNorm11 needs backward computation.
I1101 13:43:41.904070  4164 net.cpp:198] Convolution11 needs backward computation.
I1101 13:43:41.904072  4164 net.cpp:198] ReLU10 needs backward computation.
I1101 13:43:41.904074  4164 net.cpp:198] Scale10 needs backward computation.
I1101 13:43:41.904075  4164 net.cpp:198] BatchNorm10 needs backward computation.
I1101 13:43:41.904078  4164 net.cpp:198] Convolution10 needs backward computation.
I1101 13:43:41.904081  4164 net.cpp:198] Eltwise4_ReLU9_0_split needs backward computation.
I1101 13:43:41.904083  4164 net.cpp:198] ReLU9 needs backward computation.
I1101 13:43:41.904084  4164 net.cpp:198] Eltwise4 needs backward computation.
I1101 13:43:41.904088  4164 net.cpp:198] Scale9 needs backward computation.
I1101 13:43:41.904089  4164 net.cpp:198] BatchNorm9 needs backward computation.
I1101 13:43:41.904090  4164 net.cpp:198] Convolution9 needs backward computation.
I1101 13:43:41.904093  4164 net.cpp:198] ReLU8 needs backward computation.
I1101 13:43:41.904095  4164 net.cpp:198] Scale8 needs backward computation.
I1101 13:43:41.904096  4164 net.cpp:198] BatchNorm8 needs backward computation.
I1101 13:43:41.904098  4164 net.cpp:198] Convolution8 needs backward computation.
I1101 13:43:41.904100  4164 net.cpp:198] Eltwise3_ReLU7_0_split needs backward computation.
I1101 13:43:41.904103  4164 net.cpp:198] ReLU7 needs backward computation.
I1101 13:43:41.904104  4164 net.cpp:198] Eltwise3 needs backward computation.
I1101 13:43:41.904106  4164 net.cpp:198] Scale7 needs backward computation.
I1101 13:43:41.904109  4164 net.cpp:198] BatchNorm7 needs backward computation.
I1101 13:43:41.904110  4164 net.cpp:198] Convolution7 needs backward computation.
I1101 13:43:41.904112  4164 net.cpp:198] ReLU6 needs backward computation.
I1101 13:43:41.904114  4164 net.cpp:198] Scale6 needs backward computation.
I1101 13:43:41.904116  4164 net.cpp:198] BatchNorm6 needs backward computation.
I1101 13:43:41.904119  4164 net.cpp:198] Convolution6 needs backward computation.
I1101 13:43:41.904120  4164 net.cpp:198] Eltwise2_ReLU5_0_split needs backward computation.
I1101 13:43:41.904121  4164 net.cpp:198] ReLU5 needs backward computation.
I1101 13:43:41.904124  4164 net.cpp:198] Eltwise2 needs backward computation.
I1101 13:43:41.904126  4164 net.cpp:198] Scale5 needs backward computation.
I1101 13:43:41.904127  4164 net.cpp:198] BatchNorm5 needs backward computation.
I1101 13:43:41.904129  4164 net.cpp:198] Convolution5 needs backward computation.
I1101 13:43:41.904131  4164 net.cpp:198] ReLU4 needs backward computation.
I1101 13:43:41.904134  4164 net.cpp:198] Scale4 needs backward computation.
I1101 13:43:41.904135  4164 net.cpp:198] BatchNorm4 needs backward computation.
I1101 13:43:41.904136  4164 net.cpp:198] Convolution4 needs backward computation.
I1101 13:43:41.904139  4164 net.cpp:198] Eltwise1_ReLU3_0_split needs backward computation.
I1101 13:43:41.904141  4164 net.cpp:198] ReLU3 needs backward computation.
I1101 13:43:41.904144  4164 net.cpp:198] Eltwise1 needs backward computation.
I1101 13:43:41.904145  4164 net.cpp:198] Scale3 needs backward computation.
I1101 13:43:41.904147  4164 net.cpp:198] BatchNorm3 needs backward computation.
I1101 13:43:41.904150  4164 net.cpp:198] Convolution3 needs backward computation.
I1101 13:43:41.904151  4164 net.cpp:198] ReLU2 needs backward computation.
I1101 13:43:41.904153  4164 net.cpp:198] Scale2 needs backward computation.
I1101 13:43:41.904155  4164 net.cpp:198] BatchNorm2 needs backward computation.
I1101 13:43:41.904160  4164 net.cpp:198] Convolution2 needs backward computation.
I1101 13:43:41.904162  4164 net.cpp:198] Convolution1_ReLU1_0_split needs backward computation.
I1101 13:43:41.904165  4164 net.cpp:198] ReLU1 needs backward computation.
I1101 13:43:41.904166  4164 net.cpp:198] Scale1 needs backward computation.
I1101 13:43:41.904168  4164 net.cpp:198] BatchNorm1 needs backward computation.
I1101 13:43:41.904170  4164 net.cpp:198] Convolution1 needs backward computation.
I1101 13:43:41.904172  4164 net.cpp:200] Data1 does not need backward computation.
I1101 13:43:41.904173  4164 net.cpp:242] This network produces output SoftmaxWithLoss1
I1101 13:43:41.904243  4164 net.cpp:255] Network initialization done.
I1101 13:43:41.905405  4164 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/ljf/caffe-master/examples/ljftest_alphabet_ResNet/test.prototxt
I1101 13:43:41.905414  4164 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1101 13:43:41.905419  4164 solver.cpp:172] Creating test net (#0) specified by test_net file: /home/ljf/caffe-master/examples/ljftest_alphabet_ResNet/test.prototxt
I1101 13:43:41.906092  4164 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  data_param {
    source: "/home/ljf/caffe-master/examples/ljftest_alphabet_ResNet/val_lmdb"
    batch_size: 100
    backend: LMDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution3"
  bottom: "Convolution1"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Convolution5"
  bottom: "Eltwise1"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Convolution7"
  bottom: "Eltwise2"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution9"
  bottom: "Eltwise3"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution12"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Convolution11"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution14"
  bottom: "Eltwise5"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution15"
  top: "Convolution15"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution16"
  bottom: "Eltwise6"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution17"
  top: "Convolution17"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Convolution18"
  bottom: "Eltwise7"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution19"
  top: "Convolution19"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Eltwise8"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution23"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution22"
  bottom: "Convolution23"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution25"
  bottom: "Eltwise10"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution26"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Convolution27"
  bottom: "Eltwise11"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution28"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Convolution29"
  bottom: "Eltwise12"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution30"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution30"
  top: "Convolution30"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Convolution31"
  bottom: "Eltwise13"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution32"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm32"
  type: "BatchNorm"
  bottom: "Convolution32"
  top: "Convolution32"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale32"
  type: "Scale"
  bottom: "Convolution32"
  top: "Convolution32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "Convolution32"
  top: "Convolution32"
}
layer {
  name: "Convolution33"
  type: "Convolution"
  bottom: "Convolution32"
  top: "Convolution33"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm33"
  type: "BatchNorm"
  bottom: "Convolution33"
  top: "Convolution33"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "Scale33"
  type: "Scale"
  bottom: "Convolution33"
  top: "Convolution33"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution34"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution34"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussi
I1101 13:43:41.906522  4164 layer_factory.hpp:77] Creating layer Data1
I1101 13:43:41.906559  4164 db_lmdb.cpp:35] Opened lmdb /home/ljf/caffe-master/examples/ljftest_alphabet_ResNet/val_lmdb
I1101 13:43:41.906570  4164 net.cpp:84] Creating Layer Data1
I1101 13:43:41.906574  4164 net.cpp:380] Data1 -> Data1
I1101 13:43:41.906579  4164 net.cpp:380] Data1 -> Data2
I1101 13:43:41.906664  4164 data_layer.cpp:45] output data size: 100,3,32,32
I1101 13:43:41.910536  4164 net.cpp:122] Setting up Data1
I1101 13:43:41.910557  4164 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1101 13:43:41.910559  4164 net.cpp:129] Top shape: 100 (100)
I1101 13:43:41.910562  4164 net.cpp:137] Memory required for data: 1229200
I1101 13:43:41.910567  4164 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1101 13:43:41.910580  4164 net.cpp:84] Creating Layer Data2_Data1_1_split
I1101 13:43:41.910583  4164 net.cpp:406] Data2_Data1_1_split <- Data2
I1101 13:43:41.910588  4164 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1101 13:43:41.910595  4164 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1101 13:43:41.910660  4164 net.cpp:122] Setting up Data2_Data1_1_split
I1101 13:43:41.910665  4164 net.cpp:129] Top shape: 100 (100)
I1101 13:43:41.910668  4164 net.cpp:129] Top shape: 100 (100)
I1101 13:43:41.910670  4164 net.cpp:137] Memory required for data: 1230000
I1101 13:43:41.910671  4164 layer_factory.hpp:77] Creating layer Convolution1
I1101 13:43:41.910681  4164 net.cpp:84] Creating Layer Convolution1
I1101 13:43:41.910691  4164 net.cpp:406] Convolution1 <- Data1
I1101 13:43:41.910694  4164 net.cpp:380] Convolution1 -> Convolution1
I1101 13:43:41.911818  4164 net.cpp:122] Setting up Convolution1
I1101 13:43:41.911826  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.911828  4164 net.cpp:137] Memory required for data: 7783600
I1101 13:43:41.911835  4164 layer_factory.hpp:77] Creating layer BatchNorm1
I1101 13:43:41.911842  4164 net.cpp:84] Creating Layer BatchNorm1
I1101 13:43:41.911845  4164 net.cpp:406] BatchNorm1 <- Convolution1
I1101 13:43:41.911849  4164 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1101 13:43:41.912010  4164 net.cpp:122] Setting up BatchNorm1
I1101 13:43:41.912015  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.912017  4164 net.cpp:137] Memory required for data: 14337200
I1101 13:43:41.912024  4164 layer_factory.hpp:77] Creating layer Scale1
I1101 13:43:41.912034  4164 net.cpp:84] Creating Layer Scale1
I1101 13:43:41.912036  4164 net.cpp:406] Scale1 <- Convolution1
I1101 13:43:41.912039  4164 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1101 13:43:41.912071  4164 layer_factory.hpp:77] Creating layer Scale1
I1101 13:43:41.912163  4164 net.cpp:122] Setting up Scale1
I1101 13:43:41.912168  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.912170  4164 net.cpp:137] Memory required for data: 20890800
I1101 13:43:41.912174  4164 layer_factory.hpp:77] Creating layer ReLU1
I1101 13:43:41.912178  4164 net.cpp:84] Creating Layer ReLU1
I1101 13:43:41.912179  4164 net.cpp:406] ReLU1 <- Convolution1
I1101 13:43:41.912184  4164 net.cpp:367] ReLU1 -> Convolution1 (in-place)
I1101 13:43:41.912528  4164 net.cpp:122] Setting up ReLU1
I1101 13:43:41.912536  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.912539  4164 net.cpp:137] Memory required for data: 27444400
I1101 13:43:41.912542  4164 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I1101 13:43:41.912545  4164 net.cpp:84] Creating Layer Convolution1_ReLU1_0_split
I1101 13:43:41.912547  4164 net.cpp:406] Convolution1_ReLU1_0_split <- Convolution1
I1101 13:43:41.912551  4164 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I1101 13:43:41.912556  4164 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I1101 13:43:41.912588  4164 net.cpp:122] Setting up Convolution1_ReLU1_0_split
I1101 13:43:41.912593  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.912596  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.912598  4164 net.cpp:137] Memory required for data: 40551600
I1101 13:43:41.912600  4164 layer_factory.hpp:77] Creating layer Convolution2
I1101 13:43:41.912606  4164 net.cpp:84] Creating Layer Convolution2
I1101 13:43:41.912609  4164 net.cpp:406] Convolution2 <- Convolution1_ReLU1_0_split_0
I1101 13:43:41.912613  4164 net.cpp:380] Convolution2 -> Convolution2
I1101 13:43:41.913307  4164 net.cpp:122] Setting up Convolution2
I1101 13:43:41.913314  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.913316  4164 net.cpp:137] Memory required for data: 47105200
I1101 13:43:41.913322  4164 layer_factory.hpp:77] Creating layer BatchNorm2
I1101 13:43:41.913328  4164 net.cpp:84] Creating Layer BatchNorm2
I1101 13:43:41.913331  4164 net.cpp:406] BatchNorm2 <- Convolution2
I1101 13:43:41.913336  4164 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1101 13:43:41.913496  4164 net.cpp:122] Setting up BatchNorm2
I1101 13:43:41.913501  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.913501  4164 net.cpp:137] Memory required for data: 53658800
I1101 13:43:41.913506  4164 layer_factory.hpp:77] Creating layer Scale2
I1101 13:43:41.913511  4164 net.cpp:84] Creating Layer Scale2
I1101 13:43:41.913512  4164 net.cpp:406] Scale2 <- Convolution2
I1101 13:43:41.913517  4164 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1101 13:43:41.913548  4164 layer_factory.hpp:77] Creating layer Scale2
I1101 13:43:41.913645  4164 net.cpp:122] Setting up Scale2
I1101 13:43:41.913650  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.913660  4164 net.cpp:137] Memory required for data: 60212400
I1101 13:43:41.913663  4164 layer_factory.hpp:77] Creating layer ReLU2
I1101 13:43:41.913666  4164 net.cpp:84] Creating Layer ReLU2
I1101 13:43:41.913668  4164 net.cpp:406] ReLU2 <- Convolution2
I1101 13:43:41.913671  4164 net.cpp:367] ReLU2 -> Convolution2 (in-place)
I1101 13:43:41.914119  4164 net.cpp:122] Setting up ReLU2
I1101 13:43:41.914126  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.914129  4164 net.cpp:137] Memory required for data: 66766000
I1101 13:43:41.914131  4164 layer_factory.hpp:77] Creating layer Convolution3
I1101 13:43:41.914137  4164 net.cpp:84] Creating Layer Convolution3
I1101 13:43:41.914141  4164 net.cpp:406] Convolution3 <- Convolution2
I1101 13:43:41.914145  4164 net.cpp:380] Convolution3 -> Convolution3
I1101 13:43:41.914970  4164 net.cpp:122] Setting up Convolution3
I1101 13:43:41.914978  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.914981  4164 net.cpp:137] Memory required for data: 73319600
I1101 13:43:41.914984  4164 layer_factory.hpp:77] Creating layer BatchNorm3
I1101 13:43:41.914989  4164 net.cpp:84] Creating Layer BatchNorm3
I1101 13:43:41.914993  4164 net.cpp:406] BatchNorm3 <- Convolution3
I1101 13:43:41.914995  4164 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1101 13:43:41.915177  4164 net.cpp:122] Setting up BatchNorm3
I1101 13:43:41.915182  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.915184  4164 net.cpp:137] Memory required for data: 79873200
I1101 13:43:41.915191  4164 layer_factory.hpp:77] Creating layer Scale3
I1101 13:43:41.915195  4164 net.cpp:84] Creating Layer Scale3
I1101 13:43:41.915197  4164 net.cpp:406] Scale3 <- Convolution3
I1101 13:43:41.915200  4164 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1101 13:43:41.915313  4164 layer_factory.hpp:77] Creating layer Scale3
I1101 13:43:41.915405  4164 net.cpp:122] Setting up Scale3
I1101 13:43:41.915410  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.915412  4164 net.cpp:137] Memory required for data: 86426800
I1101 13:43:41.915416  4164 layer_factory.hpp:77] Creating layer Eltwise1
I1101 13:43:41.915421  4164 net.cpp:84] Creating Layer Eltwise1
I1101 13:43:41.915423  4164 net.cpp:406] Eltwise1 <- Convolution3
I1101 13:43:41.915426  4164 net.cpp:406] Eltwise1 <- Convolution1_ReLU1_0_split_1
I1101 13:43:41.915431  4164 net.cpp:380] Eltwise1 -> Eltwise1
I1101 13:43:41.915448  4164 net.cpp:122] Setting up Eltwise1
I1101 13:43:41.915453  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.915455  4164 net.cpp:137] Memory required for data: 92980400
I1101 13:43:41.915457  4164 layer_factory.hpp:77] Creating layer ReLU3
I1101 13:43:41.915460  4164 net.cpp:84] Creating Layer ReLU3
I1101 13:43:41.915462  4164 net.cpp:406] ReLU3 <- Eltwise1
I1101 13:43:41.915465  4164 net.cpp:367] ReLU3 -> Eltwise1 (in-place)
I1101 13:43:41.915585  4164 net.cpp:122] Setting up ReLU3
I1101 13:43:41.915591  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.915592  4164 net.cpp:137] Memory required for data: 99534000
I1101 13:43:41.915594  4164 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I1101 13:43:41.915601  4164 net.cpp:84] Creating Layer Eltwise1_ReLU3_0_split
I1101 13:43:41.915602  4164 net.cpp:406] Eltwise1_ReLU3_0_split <- Eltwise1
I1101 13:43:41.915606  4164 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I1101 13:43:41.915616  4164 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I1101 13:43:41.915647  4164 net.cpp:122] Setting up Eltwise1_ReLU3_0_split
I1101 13:43:41.915652  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.915654  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.915655  4164 net.cpp:137] Memory required for data: 112641200
I1101 13:43:41.915657  4164 layer_factory.hpp:77] Creating layer Convolution4
I1101 13:43:41.915663  4164 net.cpp:84] Creating Layer Convolution4
I1101 13:43:41.915666  4164 net.cpp:406] Convolution4 <- Eltwise1_ReLU3_0_split_0
I1101 13:43:41.915678  4164 net.cpp:380] Convolution4 -> Convolution4
I1101 13:43:41.916491  4164 net.cpp:122] Setting up Convolution4
I1101 13:43:41.916498  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.916501  4164 net.cpp:137] Memory required for data: 119194800
I1101 13:43:41.916504  4164 layer_factory.hpp:77] Creating layer BatchNorm4
I1101 13:43:41.916509  4164 net.cpp:84] Creating Layer BatchNorm4
I1101 13:43:41.916512  4164 net.cpp:406] BatchNorm4 <- Convolution4
I1101 13:43:41.916515  4164 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1101 13:43:41.916676  4164 net.cpp:122] Setting up BatchNorm4
I1101 13:43:41.916680  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.916682  4164 net.cpp:137] Memory required for data: 125748400
I1101 13:43:41.916687  4164 layer_factory.hpp:77] Creating layer Scale4
I1101 13:43:41.916690  4164 net.cpp:84] Creating Layer Scale4
I1101 13:43:41.916693  4164 net.cpp:406] Scale4 <- Convolution4
I1101 13:43:41.916695  4164 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1101 13:43:41.916728  4164 layer_factory.hpp:77] Creating layer Scale4
I1101 13:43:41.916817  4164 net.cpp:122] Setting up Scale4
I1101 13:43:41.916822  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.916823  4164 net.cpp:137] Memory required for data: 132302000
I1101 13:43:41.916826  4164 layer_factory.hpp:77] Creating layer ReLU4
I1101 13:43:41.916829  4164 net.cpp:84] Creating Layer ReLU4
I1101 13:43:41.916832  4164 net.cpp:406] ReLU4 <- Convolution4
I1101 13:43:41.916836  4164 net.cpp:367] ReLU4 -> Convolution4 (in-place)
I1101 13:43:41.916954  4164 net.cpp:122] Setting up ReLU4
I1101 13:43:41.916960  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.916961  4164 net.cpp:137] Memory required for data: 138855600
I1101 13:43:41.916963  4164 layer_factory.hpp:77] Creating layer Convolution5
I1101 13:43:41.916968  4164 net.cpp:84] Creating Layer Convolution5
I1101 13:43:41.916971  4164 net.cpp:406] Convolution5 <- Convolution4
I1101 13:43:41.916975  4164 net.cpp:380] Convolution5 -> Convolution5
I1101 13:43:41.917759  4164 net.cpp:122] Setting up Convolution5
I1101 13:43:41.917768  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.917770  4164 net.cpp:137] Memory required for data: 145409200
I1101 13:43:41.917774  4164 layer_factory.hpp:77] Creating layer BatchNorm5
I1101 13:43:41.917778  4164 net.cpp:84] Creating Layer BatchNorm5
I1101 13:43:41.917781  4164 net.cpp:406] BatchNorm5 <- Convolution5
I1101 13:43:41.917784  4164 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1101 13:43:41.917944  4164 net.cpp:122] Setting up BatchNorm5
I1101 13:43:41.917948  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.917950  4164 net.cpp:137] Memory required for data: 151962800
I1101 13:43:41.917958  4164 layer_factory.hpp:77] Creating layer Scale5
I1101 13:43:41.917961  4164 net.cpp:84] Creating Layer Scale5
I1101 13:43:41.917963  4164 net.cpp:406] Scale5 <- Convolution5
I1101 13:43:41.917966  4164 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1101 13:43:41.917996  4164 layer_factory.hpp:77] Creating layer Scale5
I1101 13:43:41.918085  4164 net.cpp:122] Setting up Scale5
I1101 13:43:41.918090  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.918092  4164 net.cpp:137] Memory required for data: 158516400
I1101 13:43:41.918094  4164 layer_factory.hpp:77] Creating layer Eltwise2
I1101 13:43:41.918099  4164 net.cpp:84] Creating Layer Eltwise2
I1101 13:43:41.918102  4164 net.cpp:406] Eltwise2 <- Convolution5
I1101 13:43:41.918104  4164 net.cpp:406] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I1101 13:43:41.918107  4164 net.cpp:380] Eltwise2 -> Eltwise2
I1101 13:43:41.918125  4164 net.cpp:122] Setting up Eltwise2
I1101 13:43:41.918128  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.918130  4164 net.cpp:137] Memory required for data: 165070000
I1101 13:43:41.918133  4164 layer_factory.hpp:77] Creating layer ReLU5
I1101 13:43:41.918135  4164 net.cpp:84] Creating Layer ReLU5
I1101 13:43:41.918144  4164 net.cpp:406] ReLU5 <- Eltwise2
I1101 13:43:41.918148  4164 net.cpp:367] ReLU5 -> Eltwise2 (in-place)
I1101 13:43:41.918267  4164 net.cpp:122] Setting up ReLU5
I1101 13:43:41.918272  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.918274  4164 net.cpp:137] Memory required for data: 171623600
I1101 13:43:41.918277  4164 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I1101 13:43:41.918279  4164 net.cpp:84] Creating Layer Eltwise2_ReLU5_0_split
I1101 13:43:41.918282  4164 net.cpp:406] Eltwise2_ReLU5_0_split <- Eltwise2
I1101 13:43:41.918285  4164 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I1101 13:43:41.918289  4164 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I1101 13:43:41.918321  4164 net.cpp:122] Setting up Eltwise2_ReLU5_0_split
I1101 13:43:41.918325  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.918329  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.918330  4164 net.cpp:137] Memory required for data: 184730800
I1101 13:43:41.918331  4164 layer_factory.hpp:77] Creating layer Convolution6
I1101 13:43:41.918336  4164 net.cpp:84] Creating Layer Convolution6
I1101 13:43:41.918339  4164 net.cpp:406] Convolution6 <- Eltwise2_ReLU5_0_split_0
I1101 13:43:41.918344  4164 net.cpp:380] Convolution6 -> Convolution6
I1101 13:43:41.919153  4164 net.cpp:122] Setting up Convolution6
I1101 13:43:41.919162  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.919165  4164 net.cpp:137] Memory required for data: 191284400
I1101 13:43:41.919169  4164 layer_factory.hpp:77] Creating layer BatchNorm6
I1101 13:43:41.919173  4164 net.cpp:84] Creating Layer BatchNorm6
I1101 13:43:41.919175  4164 net.cpp:406] BatchNorm6 <- Convolution6
I1101 13:43:41.919179  4164 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1101 13:43:41.919342  4164 net.cpp:122] Setting up BatchNorm6
I1101 13:43:41.919345  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.919348  4164 net.cpp:137] Memory required for data: 197838000
I1101 13:43:41.919351  4164 layer_factory.hpp:77] Creating layer Scale6
I1101 13:43:41.919355  4164 net.cpp:84] Creating Layer Scale6
I1101 13:43:41.919358  4164 net.cpp:406] Scale6 <- Convolution6
I1101 13:43:41.919360  4164 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1101 13:43:41.919390  4164 layer_factory.hpp:77] Creating layer Scale6
I1101 13:43:41.919481  4164 net.cpp:122] Setting up Scale6
I1101 13:43:41.919486  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.919486  4164 net.cpp:137] Memory required for data: 204391600
I1101 13:43:41.919490  4164 layer_factory.hpp:77] Creating layer ReLU6
I1101 13:43:41.919493  4164 net.cpp:84] Creating Layer ReLU6
I1101 13:43:41.919495  4164 net.cpp:406] ReLU6 <- Convolution6
I1101 13:43:41.919498  4164 net.cpp:367] ReLU6 -> Convolution6 (in-place)
I1101 13:43:41.919616  4164 net.cpp:122] Setting up ReLU6
I1101 13:43:41.919621  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.919623  4164 net.cpp:137] Memory required for data: 210945200
I1101 13:43:41.919625  4164 layer_factory.hpp:77] Creating layer Convolution7
I1101 13:43:41.919631  4164 net.cpp:84] Creating Layer Convolution7
I1101 13:43:41.919634  4164 net.cpp:406] Convolution7 <- Convolution6
I1101 13:43:41.919637  4164 net.cpp:380] Convolution7 -> Convolution7
I1101 13:43:41.920423  4164 net.cpp:122] Setting up Convolution7
I1101 13:43:41.920431  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.920433  4164 net.cpp:137] Memory required for data: 217498800
I1101 13:43:41.920436  4164 layer_factory.hpp:77] Creating layer BatchNorm7
I1101 13:43:41.920444  4164 net.cpp:84] Creating Layer BatchNorm7
I1101 13:43:41.920449  4164 net.cpp:406] BatchNorm7 <- Convolution7
I1101 13:43:41.920451  4164 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1101 13:43:41.920616  4164 net.cpp:122] Setting up BatchNorm7
I1101 13:43:41.920621  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.920629  4164 net.cpp:137] Memory required for data: 224052400
I1101 13:43:41.920634  4164 layer_factory.hpp:77] Creating layer Scale7
I1101 13:43:41.920639  4164 net.cpp:84] Creating Layer Scale7
I1101 13:43:41.920639  4164 net.cpp:406] Scale7 <- Convolution7
I1101 13:43:41.920644  4164 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1101 13:43:41.920675  4164 layer_factory.hpp:77] Creating layer Scale7
I1101 13:43:41.920768  4164 net.cpp:122] Setting up Scale7
I1101 13:43:41.920771  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.920773  4164 net.cpp:137] Memory required for data: 230606000
I1101 13:43:41.920776  4164 layer_factory.hpp:77] Creating layer Eltwise3
I1101 13:43:41.920780  4164 net.cpp:84] Creating Layer Eltwise3
I1101 13:43:41.920783  4164 net.cpp:406] Eltwise3 <- Convolution7
I1101 13:43:41.920785  4164 net.cpp:406] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I1101 13:43:41.920789  4164 net.cpp:380] Eltwise3 -> Eltwise3
I1101 13:43:41.920806  4164 net.cpp:122] Setting up Eltwise3
I1101 13:43:41.920810  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.920814  4164 net.cpp:137] Memory required for data: 237159600
I1101 13:43:41.920815  4164 layer_factory.hpp:77] Creating layer ReLU7
I1101 13:43:41.920819  4164 net.cpp:84] Creating Layer ReLU7
I1101 13:43:41.920820  4164 net.cpp:406] ReLU7 <- Eltwise3
I1101 13:43:41.920823  4164 net.cpp:367] ReLU7 -> Eltwise3 (in-place)
I1101 13:43:41.921207  4164 net.cpp:122] Setting up ReLU7
I1101 13:43:41.921216  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.921218  4164 net.cpp:137] Memory required for data: 243713200
I1101 13:43:41.921221  4164 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I1101 13:43:41.921224  4164 net.cpp:84] Creating Layer Eltwise3_ReLU7_0_split
I1101 13:43:41.921226  4164 net.cpp:406] Eltwise3_ReLU7_0_split <- Eltwise3
I1101 13:43:41.921231  4164 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I1101 13:43:41.921234  4164 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I1101 13:43:41.921269  4164 net.cpp:122] Setting up Eltwise3_ReLU7_0_split
I1101 13:43:41.921273  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.921275  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.921277  4164 net.cpp:137] Memory required for data: 256820400
I1101 13:43:41.921279  4164 layer_factory.hpp:77] Creating layer Convolution8
I1101 13:43:41.921285  4164 net.cpp:84] Creating Layer Convolution8
I1101 13:43:41.921288  4164 net.cpp:406] Convolution8 <- Eltwise3_ReLU7_0_split_0
I1101 13:43:41.921293  4164 net.cpp:380] Convolution8 -> Convolution8
I1101 13:43:41.922085  4164 net.cpp:122] Setting up Convolution8
I1101 13:43:41.922092  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.922094  4164 net.cpp:137] Memory required for data: 263374000
I1101 13:43:41.922098  4164 layer_factory.hpp:77] Creating layer BatchNorm8
I1101 13:43:41.922103  4164 net.cpp:84] Creating Layer BatchNorm8
I1101 13:43:41.922106  4164 net.cpp:406] BatchNorm8 <- Convolution8
I1101 13:43:41.922111  4164 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1101 13:43:41.922274  4164 net.cpp:122] Setting up BatchNorm8
I1101 13:43:41.922278  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.922281  4164 net.cpp:137] Memory required for data: 269927600
I1101 13:43:41.922284  4164 layer_factory.hpp:77] Creating layer Scale8
I1101 13:43:41.922288  4164 net.cpp:84] Creating Layer Scale8
I1101 13:43:41.922291  4164 net.cpp:406] Scale8 <- Convolution8
I1101 13:43:41.922293  4164 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1101 13:43:41.922323  4164 layer_factory.hpp:77] Creating layer Scale8
I1101 13:43:41.922421  4164 net.cpp:122] Setting up Scale8
I1101 13:43:41.922433  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.922435  4164 net.cpp:137] Memory required for data: 276481200
I1101 13:43:41.922438  4164 layer_factory.hpp:77] Creating layer ReLU8
I1101 13:43:41.922442  4164 net.cpp:84] Creating Layer ReLU8
I1101 13:43:41.922451  4164 net.cpp:406] ReLU8 <- Convolution8
I1101 13:43:41.922454  4164 net.cpp:367] ReLU8 -> Convolution8 (in-place)
I1101 13:43:41.922812  4164 net.cpp:122] Setting up ReLU8
I1101 13:43:41.922821  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.922824  4164 net.cpp:137] Memory required for data: 283034800
I1101 13:43:41.922827  4164 layer_factory.hpp:77] Creating layer Convolution9
I1101 13:43:41.922835  4164 net.cpp:84] Creating Layer Convolution9
I1101 13:43:41.922838  4164 net.cpp:406] Convolution9 <- Convolution8
I1101 13:43:41.922844  4164 net.cpp:380] Convolution9 -> Convolution9
I1101 13:43:41.923923  4164 net.cpp:122] Setting up Convolution9
I1101 13:43:41.923933  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.923934  4164 net.cpp:137] Memory required for data: 289588400
I1101 13:43:41.923938  4164 layer_factory.hpp:77] Creating layer BatchNorm9
I1101 13:43:41.923943  4164 net.cpp:84] Creating Layer BatchNorm9
I1101 13:43:41.923945  4164 net.cpp:406] BatchNorm9 <- Convolution9
I1101 13:43:41.923949  4164 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1101 13:43:41.924142  4164 net.cpp:122] Setting up BatchNorm9
I1101 13:43:41.924146  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.924150  4164 net.cpp:137] Memory required for data: 296142000
I1101 13:43:41.924154  4164 layer_factory.hpp:77] Creating layer Scale9
I1101 13:43:41.924157  4164 net.cpp:84] Creating Layer Scale9
I1101 13:43:41.924160  4164 net.cpp:406] Scale9 <- Convolution9
I1101 13:43:41.924163  4164 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1101 13:43:41.924222  4164 layer_factory.hpp:77] Creating layer Scale9
I1101 13:43:41.924312  4164 net.cpp:122] Setting up Scale9
I1101 13:43:41.924317  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.924319  4164 net.cpp:137] Memory required for data: 302695600
I1101 13:43:41.924322  4164 layer_factory.hpp:77] Creating layer Eltwise4
I1101 13:43:41.924326  4164 net.cpp:84] Creating Layer Eltwise4
I1101 13:43:41.924329  4164 net.cpp:406] Eltwise4 <- Convolution9
I1101 13:43:41.924331  4164 net.cpp:406] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I1101 13:43:41.924335  4164 net.cpp:380] Eltwise4 -> Eltwise4
I1101 13:43:41.924352  4164 net.cpp:122] Setting up Eltwise4
I1101 13:43:41.924357  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.924360  4164 net.cpp:137] Memory required for data: 309249200
I1101 13:43:41.924362  4164 layer_factory.hpp:77] Creating layer ReLU9
I1101 13:43:41.924365  4164 net.cpp:84] Creating Layer ReLU9
I1101 13:43:41.924368  4164 net.cpp:406] ReLU9 <- Eltwise4
I1101 13:43:41.924371  4164 net.cpp:367] ReLU9 -> Eltwise4 (in-place)
I1101 13:43:41.924491  4164 net.cpp:122] Setting up ReLU9
I1101 13:43:41.924496  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.924499  4164 net.cpp:137] Memory required for data: 315802800
I1101 13:43:41.924500  4164 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I1101 13:43:41.924504  4164 net.cpp:84] Creating Layer Eltwise4_ReLU9_0_split
I1101 13:43:41.924506  4164 net.cpp:406] Eltwise4_ReLU9_0_split <- Eltwise4
I1101 13:43:41.924509  4164 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I1101 13:43:41.924513  4164 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I1101 13:43:41.924545  4164 net.cpp:122] Setting up Eltwise4_ReLU9_0_split
I1101 13:43:41.924548  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.924551  4164 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1101 13:43:41.924552  4164 net.cpp:137] Memory required for data: 328910000
I1101 13:43:41.924554  4164 layer_factory.hpp:77] Creating layer Convolution10
I1101 13:43:41.924559  4164 net.cpp:84] Creating Layer Convolution10
I1101 13:43:41.924562  4164 net.cpp:406] Convolution10 <- Eltwise4_ReLU9_0_split_0
I1101 13:43:41.924566  4164 net.cpp:380] Convolution10 -> Convolution10
I1101 13:43:41.925433  4164 net.cpp:122] Setting up Convolution10
I1101 13:43:41.925442  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.925451  4164 net.cpp:137] Memory required for data: 332186800
I1101 13:43:41.925460  4164 layer_factory.hpp:77] Creating layer BatchNorm10
I1101 13:43:41.925467  4164 net.cpp:84] Creating Layer BatchNorm10
I1101 13:43:41.925469  4164 net.cpp:406] BatchNorm10 <- Convolution10
I1101 13:43:41.925473  4164 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1101 13:43:41.925627  4164 net.cpp:122] Setting up BatchNorm10
I1101 13:43:41.925631  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.925634  4164 net.cpp:137] Memory required for data: 335463600
I1101 13:43:41.925638  4164 layer_factory.hpp:77] Creating layer Scale10
I1101 13:43:41.925642  4164 net.cpp:84] Creating Layer Scale10
I1101 13:43:41.925644  4164 net.cpp:406] Scale10 <- Convolution10
I1101 13:43:41.925647  4164 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1101 13:43:41.925678  4164 layer_factory.hpp:77] Creating layer Scale10
I1101 13:43:41.925770  4164 net.cpp:122] Setting up Scale10
I1101 13:43:41.925774  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.925776  4164 net.cpp:137] Memory required for data: 338740400
I1101 13:43:41.925779  4164 layer_factory.hpp:77] Creating layer ReLU10
I1101 13:43:41.925783  4164 net.cpp:84] Creating Layer ReLU10
I1101 13:43:41.925786  4164 net.cpp:406] ReLU10 <- Convolution10
I1101 13:43:41.925788  4164 net.cpp:367] ReLU10 -> Convolution10 (in-place)
I1101 13:43:41.925945  4164 net.cpp:122] Setting up ReLU10
I1101 13:43:41.925950  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.925952  4164 net.cpp:137] Memory required for data: 342017200
I1101 13:43:41.925967  4164 layer_factory.hpp:77] Creating layer Convolution11
I1101 13:43:41.925973  4164 net.cpp:84] Creating Layer Convolution11
I1101 13:43:41.925976  4164 net.cpp:406] Convolution11 <- Convolution10
I1101 13:43:41.925979  4164 net.cpp:380] Convolution11 -> Convolution11
I1101 13:43:41.926864  4164 net.cpp:122] Setting up Convolution11
I1101 13:43:41.926873  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.926875  4164 net.cpp:137] Memory required for data: 345294000
I1101 13:43:41.926878  4164 layer_factory.hpp:77] Creating layer BatchNorm11
I1101 13:43:41.926897  4164 net.cpp:84] Creating Layer BatchNorm11
I1101 13:43:41.926899  4164 net.cpp:406] BatchNorm11 <- Convolution11
I1101 13:43:41.926903  4164 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1101 13:43:41.927072  4164 net.cpp:122] Setting up BatchNorm11
I1101 13:43:41.927075  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.927078  4164 net.cpp:137] Memory required for data: 348570800
I1101 13:43:41.927081  4164 layer_factory.hpp:77] Creating layer Scale11
I1101 13:43:41.927085  4164 net.cpp:84] Creating Layer Scale11
I1101 13:43:41.927088  4164 net.cpp:406] Scale11 <- Convolution11
I1101 13:43:41.927090  4164 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1101 13:43:41.927119  4164 layer_factory.hpp:77] Creating layer Scale11
I1101 13:43:41.927209  4164 net.cpp:122] Setting up Scale11
I1101 13:43:41.927213  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.927215  4164 net.cpp:137] Memory required for data: 351847600
I1101 13:43:41.927218  4164 layer_factory.hpp:77] Creating layer Convolution12
I1101 13:43:41.927223  4164 net.cpp:84] Creating Layer Convolution12
I1101 13:43:41.927239  4164 net.cpp:406] Convolution12 <- Eltwise4_ReLU9_0_split_1
I1101 13:43:41.927244  4164 net.cpp:380] Convolution12 -> Convolution12
I1101 13:43:41.928027  4164 net.cpp:122] Setting up Convolution12
I1101 13:43:41.928035  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.928050  4164 net.cpp:137] Memory required for data: 355124400
I1101 13:43:41.928056  4164 layer_factory.hpp:77] Creating layer BatchNorm12
I1101 13:43:41.928059  4164 net.cpp:84] Creating Layer BatchNorm12
I1101 13:43:41.928061  4164 net.cpp:406] BatchNorm12 <- Convolution12
I1101 13:43:41.928066  4164 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1101 13:43:41.928262  4164 net.cpp:122] Setting up BatchNorm12
I1101 13:43:41.928273  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.928277  4164 net.cpp:137] Memory required for data: 358401200
I1101 13:43:41.928279  4164 layer_factory.hpp:77] Creating layer Scale12
I1101 13:43:41.928284  4164 net.cpp:84] Creating Layer Scale12
I1101 13:43:41.928287  4164 net.cpp:406] Scale12 <- Convolution12
I1101 13:43:41.928290  4164 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1101 13:43:41.928349  4164 layer_factory.hpp:77] Creating layer Scale12
I1101 13:43:41.928464  4164 net.cpp:122] Setting up Scale12
I1101 13:43:41.928469  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.928472  4164 net.cpp:137] Memory required for data: 361678000
I1101 13:43:41.928473  4164 layer_factory.hpp:77] Creating layer Eltwise5
I1101 13:43:41.928478  4164 net.cpp:84] Creating Layer Eltwise5
I1101 13:43:41.928481  4164 net.cpp:406] Eltwise5 <- Convolution11
I1101 13:43:41.928483  4164 net.cpp:406] Eltwise5 <- Convolution12
I1101 13:43:41.928488  4164 net.cpp:380] Eltwise5 -> Eltwise5
I1101 13:43:41.928516  4164 net.cpp:122] Setting up Eltwise5
I1101 13:43:41.928534  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.928535  4164 net.cpp:137] Memory required for data: 364954800
I1101 13:43:41.928537  4164 layer_factory.hpp:77] Creating layer ReLU11
I1101 13:43:41.928541  4164 net.cpp:84] Creating Layer ReLU11
I1101 13:43:41.928556  4164 net.cpp:406] ReLU11 <- Eltwise5
I1101 13:43:41.928560  4164 net.cpp:367] ReLU11 -> Eltwise5 (in-place)
I1101 13:43:41.928722  4164 net.cpp:122] Setting up ReLU11
I1101 13:43:41.928726  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.928730  4164 net.cpp:137] Memory required for data: 368231600
I1101 13:43:41.928730  4164 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I1101 13:43:41.928746  4164 net.cpp:84] Creating Layer Eltwise5_ReLU11_0_split
I1101 13:43:41.928748  4164 net.cpp:406] Eltwise5_ReLU11_0_split <- Eltwise5
I1101 13:43:41.928752  4164 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I1101 13:43:41.928756  4164 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I1101 13:43:41.928818  4164 net.cpp:122] Setting up Eltwise5_ReLU11_0_split
I1101 13:43:41.928822  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.928825  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.928828  4164 net.cpp:137] Memory required for data: 374785200
I1101 13:43:41.928828  4164 layer_factory.hpp:77] Creating layer Convolution13
I1101 13:43:41.928834  4164 net.cpp:84] Creating Layer Convolution13
I1101 13:43:41.928838  4164 net.cpp:406] Convolution13 <- Eltwise5_ReLU11_0_split_0
I1101 13:43:41.928841  4164 net.cpp:380] Convolution13 -> Convolution13
I1101 13:43:41.929677  4164 net.cpp:122] Setting up Convolution13
I1101 13:43:41.929685  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.929688  4164 net.cpp:137] Memory required for data: 378062000
I1101 13:43:41.929692  4164 layer_factory.hpp:77] Creating layer BatchNorm13
I1101 13:43:41.929697  4164 net.cpp:84] Creating Layer BatchNorm13
I1101 13:43:41.929698  4164 net.cpp:406] BatchNorm13 <- Convolution13
I1101 13:43:41.929715  4164 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1101 13:43:41.929898  4164 net.cpp:122] Setting up BatchNorm13
I1101 13:43:41.929901  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.929903  4164 net.cpp:137] Memory required for data: 381338800
I1101 13:43:41.929908  4164 layer_factory.hpp:77] Creating layer Scale13
I1101 13:43:41.929910  4164 net.cpp:84] Creating Layer Scale13
I1101 13:43:41.929913  4164 net.cpp:406] Scale13 <- Convolution13
I1101 13:43:41.929916  4164 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1101 13:43:41.929967  4164 layer_factory.hpp:77] Creating layer Scale13
I1101 13:43:41.930068  4164 net.cpp:122] Setting up Scale13
I1101 13:43:41.930073  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.930074  4164 net.cpp:137] Memory required for data: 384615600
I1101 13:43:41.930078  4164 layer_factory.hpp:77] Creating layer ReLU12
I1101 13:43:41.930088  4164 net.cpp:84] Creating Layer ReLU12
I1101 13:43:41.930090  4164 net.cpp:406] ReLU12 <- Convolution13
I1101 13:43:41.930106  4164 net.cpp:367] ReLU12 -> Convolution13 (in-place)
I1101 13:43:41.930238  4164 net.cpp:122] Setting up ReLU12
I1101 13:43:41.930243  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.930244  4164 net.cpp:137] Memory required for data: 387892400
I1101 13:43:41.930246  4164 layer_factory.hpp:77] Creating layer Convolution14
I1101 13:43:41.930256  4164 net.cpp:84] Creating Layer Convolution14
I1101 13:43:41.930259  4164 net.cpp:406] Convolution14 <- Convolution13
I1101 13:43:41.930263  4164 net.cpp:380] Convolution14 -> Convolution14
I1101 13:43:41.931120  4164 net.cpp:122] Setting up Convolution14
I1101 13:43:41.931129  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.931131  4164 net.cpp:137] Memory required for data: 391169200
I1101 13:43:41.931135  4164 layer_factory.hpp:77] Creating layer BatchNorm14
I1101 13:43:41.931152  4164 net.cpp:84] Creating Layer BatchNorm14
I1101 13:43:41.931155  4164 net.cpp:406] BatchNorm14 <- Convolution14
I1101 13:43:41.931159  4164 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1101 13:43:41.931326  4164 net.cpp:122] Setting up BatchNorm14
I1101 13:43:41.931330  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.931334  4164 net.cpp:137] Memory required for data: 394446000
I1101 13:43:41.931349  4164 layer_factory.hpp:77] Creating layer Scale14
I1101 13:43:41.931354  4164 net.cpp:84] Creating Layer Scale14
I1101 13:43:41.931355  4164 net.cpp:406] Scale14 <- Convolution14
I1101 13:43:41.931360  4164 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1101 13:43:41.931416  4164 layer_factory.hpp:77] Creating layer Scale14
I1101 13:43:41.931545  4164 net.cpp:122] Setting up Scale14
I1101 13:43:41.931548  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.931551  4164 net.cpp:137] Memory required for data: 397722800
I1101 13:43:41.931567  4164 layer_factory.hpp:77] Creating layer Eltwise6
I1101 13:43:41.931571  4164 net.cpp:84] Creating Layer Eltwise6
I1101 13:43:41.931573  4164 net.cpp:406] Eltwise6 <- Convolution14
I1101 13:43:41.931577  4164 net.cpp:406] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I1101 13:43:41.931581  4164 net.cpp:380] Eltwise6 -> Eltwise6
I1101 13:43:41.931596  4164 net.cpp:122] Setting up Eltwise6
I1101 13:43:41.931599  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.931602  4164 net.cpp:137] Memory required for data: 400999600
I1101 13:43:41.931604  4164 layer_factory.hpp:77] Creating layer ReLU13
I1101 13:43:41.931607  4164 net.cpp:84] Creating Layer ReLU13
I1101 13:43:41.931609  4164 net.cpp:406] ReLU13 <- Eltwise6
I1101 13:43:41.931612  4164 net.cpp:367] ReLU13 -> Eltwise6 (in-place)
I1101 13:43:41.931732  4164 net.cpp:122] Setting up ReLU13
I1101 13:43:41.931737  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.931740  4164 net.cpp:137] Memory required for data: 404276400
I1101 13:43:41.931741  4164 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I1101 13:43:41.931746  4164 net.cpp:84] Creating Layer Eltwise6_ReLU13_0_split
I1101 13:43:41.931747  4164 net.cpp:406] Eltwise6_ReLU13_0_split <- Eltwise6
I1101 13:43:41.931751  4164 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I1101 13:43:41.931756  4164 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I1101 13:43:41.931787  4164 net.cpp:122] Setting up Eltwise6_ReLU13_0_split
I1101 13:43:41.931790  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.931792  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.931794  4164 net.cpp:137] Memory required for data: 410830000
I1101 13:43:41.931797  4164 layer_factory.hpp:77] Creating layer Convolution15
I1101 13:43:41.931802  4164 net.cpp:84] Creating Layer Convolution15
I1101 13:43:41.931804  4164 net.cpp:406] Convolution15 <- Eltwise6_ReLU13_0_split_0
I1101 13:43:41.931808  4164 net.cpp:380] Convolution15 -> Convolution15
I1101 13:43:41.932842  4164 net.cpp:122] Setting up Convolution15
I1101 13:43:41.932850  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.932852  4164 net.cpp:137] Memory required for data: 414106800
I1101 13:43:41.932857  4164 layer_factory.hpp:77] Creating layer BatchNorm15
I1101 13:43:41.932862  4164 net.cpp:84] Creating Layer BatchNorm15
I1101 13:43:41.932864  4164 net.cpp:406] BatchNorm15 <- Convolution15
I1101 13:43:41.932868  4164 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1101 13:43:41.933032  4164 net.cpp:122] Setting up BatchNorm15
I1101 13:43:41.933037  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.933037  4164 net.cpp:137] Memory required for data: 417383600
I1101 13:43:41.933042  4164 layer_factory.hpp:77] Creating layer Scale15
I1101 13:43:41.933046  4164 net.cpp:84] Creating Layer Scale15
I1101 13:43:41.933048  4164 net.cpp:406] Scale15 <- Convolution15
I1101 13:43:41.933051  4164 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1101 13:43:41.933082  4164 layer_factory.hpp:77] Creating layer Scale15
I1101 13:43:41.933174  4164 net.cpp:122] Setting up Scale15
I1101 13:43:41.933178  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.933181  4164 net.cpp:137] Memory required for data: 420660400
I1101 13:43:41.933183  4164 layer_factory.hpp:77] Creating layer ReLU14
I1101 13:43:41.933187  4164 net.cpp:84] Creating Layer ReLU14
I1101 13:43:41.933188  4164 net.cpp:406] ReLU14 <- Convolution15
I1101 13:43:41.933192  4164 net.cpp:367] ReLU14 -> Convolution15 (in-place)
I1101 13:43:41.933509  4164 net.cpp:122] Setting up ReLU14
I1101 13:43:41.933518  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.933521  4164 net.cpp:137] Memory required for data: 423937200
I1101 13:43:41.933523  4164 layer_factory.hpp:77] Creating layer Convolution16
I1101 13:43:41.933528  4164 net.cpp:84] Creating Layer Convolution16
I1101 13:43:41.933531  4164 net.cpp:406] Convolution16 <- Convolution15
I1101 13:43:41.933535  4164 net.cpp:380] Convolution16 -> Convolution16
I1101 13:43:41.934617  4164 net.cpp:122] Setting up Convolution16
I1101 13:43:41.934624  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.934641  4164 net.cpp:137] Memory required for data: 427214000
I1101 13:43:41.934644  4164 layer_factory.hpp:77] Creating layer BatchNorm16
I1101 13:43:41.934649  4164 net.cpp:84] Creating Layer BatchNorm16
I1101 13:43:41.934651  4164 net.cpp:406] BatchNorm16 <- Convolution16
I1101 13:43:41.934655  4164 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1101 13:43:41.934823  4164 net.cpp:122] Setting up BatchNorm16
I1101 13:43:41.934828  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.934829  4164 net.cpp:137] Memory required for data: 430490800
I1101 13:43:41.934849  4164 layer_factory.hpp:77] Creating layer Scale16
I1101 13:43:41.934852  4164 net.cpp:84] Creating Layer Scale16
I1101 13:43:41.934854  4164 net.cpp:406] Scale16 <- Convolution16
I1101 13:43:41.934856  4164 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1101 13:43:41.934900  4164 layer_factory.hpp:77] Creating layer Scale16
I1101 13:43:41.935025  4164 net.cpp:122] Setting up Scale16
I1101 13:43:41.935029  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.935030  4164 net.cpp:137] Memory required for data: 433767600
I1101 13:43:41.935034  4164 layer_factory.hpp:77] Creating layer Eltwise7
I1101 13:43:41.935037  4164 net.cpp:84] Creating Layer Eltwise7
I1101 13:43:41.935039  4164 net.cpp:406] Eltwise7 <- Convolution16
I1101 13:43:41.935042  4164 net.cpp:406] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I1101 13:43:41.935045  4164 net.cpp:380] Eltwise7 -> Eltwise7
I1101 13:43:41.935060  4164 net.cpp:122] Setting up Eltwise7
I1101 13:43:41.935063  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.935065  4164 net.cpp:137] Memory required for data: 437044400
I1101 13:43:41.935066  4164 layer_factory.hpp:77] Creating layer ReLU15
I1101 13:43:41.935070  4164 net.cpp:84] Creating Layer ReLU15
I1101 13:43:41.935071  4164 net.cpp:406] ReLU15 <- Eltwise7
I1101 13:43:41.935081  4164 net.cpp:367] ReLU15 -> Eltwise7 (in-place)
I1101 13:43:41.935226  4164 net.cpp:122] Setting up ReLU15
I1101 13:43:41.935231  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.935233  4164 net.cpp:137] Memory required for data: 440321200
I1101 13:43:41.935235  4164 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I1101 13:43:41.935240  4164 net.cpp:84] Creating Layer Eltwise7_ReLU15_0_split
I1101 13:43:41.935240  4164 net.cpp:406] Eltwise7_ReLU15_0_split <- Eltwise7
I1101 13:43:41.935245  4164 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I1101 13:43:41.935248  4164 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I1101 13:43:41.935277  4164 net.cpp:122] Setting up Eltwise7_ReLU15_0_split
I1101 13:43:41.935281  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.935284  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.935286  4164 net.cpp:137] Memory required for data: 446874800
I1101 13:43:41.935287  4164 layer_factory.hpp:77] Creating layer Convolution17
I1101 13:43:41.935292  4164 net.cpp:84] Creating Layer Convolution17
I1101 13:43:41.935293  4164 net.cpp:406] Convolution17 <- Eltwise7_ReLU15_0_split_0
I1101 13:43:41.935298  4164 net.cpp:380] Convolution17 -> Convolution17
I1101 13:43:41.936115  4164 net.cpp:122] Setting up Convolution17
I1101 13:43:41.936123  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.936125  4164 net.cpp:137] Memory required for data: 450151600
I1101 13:43:41.936128  4164 layer_factory.hpp:77] Creating layer BatchNorm17
I1101 13:43:41.936132  4164 net.cpp:84] Creating Layer BatchNorm17
I1101 13:43:41.936136  4164 net.cpp:406] BatchNorm17 <- Convolution17
I1101 13:43:41.936138  4164 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1101 13:43:41.936295  4164 net.cpp:122] Setting up BatchNorm17
I1101 13:43:41.936300  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.936300  4164 net.cpp:137] Memory required for data: 453428400
I1101 13:43:41.936305  4164 layer_factory.hpp:77] Creating layer Scale17
I1101 13:43:41.936307  4164 net.cpp:84] Creating Layer Scale17
I1101 13:43:41.936309  4164 net.cpp:406] Scale17 <- Convolution17
I1101 13:43:41.936312  4164 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1101 13:43:41.936342  4164 layer_factory.hpp:77] Creating layer Scale17
I1101 13:43:41.936465  4164 net.cpp:122] Setting up Scale17
I1101 13:43:41.936470  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.936471  4164 net.cpp:137] Memory required for data: 456705200
I1101 13:43:41.936475  4164 layer_factory.hpp:77] Creating layer ReLU16
I1101 13:43:41.936477  4164 net.cpp:84] Creating Layer ReLU16
I1101 13:43:41.936480  4164 net.cpp:406] ReLU16 <- Convolution17
I1101 13:43:41.936482  4164 net.cpp:367] ReLU16 -> Convolution17 (in-place)
I1101 13:43:41.936599  4164 net.cpp:122] Setting up ReLU16
I1101 13:43:41.936604  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.936606  4164 net.cpp:137] Memory required for data: 459982000
I1101 13:43:41.936609  4164 layer_factory.hpp:77] Creating layer Convolution18
I1101 13:43:41.936614  4164 net.cpp:84] Creating Layer Convolution18
I1101 13:43:41.936615  4164 net.cpp:406] Convolution18 <- Convolution17
I1101 13:43:41.936619  4164 net.cpp:380] Convolution18 -> Convolution18
I1101 13:43:41.937443  4164 net.cpp:122] Setting up Convolution18
I1101 13:43:41.937451  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.937453  4164 net.cpp:137] Memory required for data: 463258800
I1101 13:43:41.937458  4164 layer_factory.hpp:77] Creating layer BatchNorm18
I1101 13:43:41.937461  4164 net.cpp:84] Creating Layer BatchNorm18
I1101 13:43:41.937463  4164 net.cpp:406] BatchNorm18 <- Convolution18
I1101 13:43:41.937466  4164 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1101 13:43:41.937624  4164 net.cpp:122] Setting up BatchNorm18
I1101 13:43:41.937629  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.937630  4164 net.cpp:137] Memory required for data: 466535600
I1101 13:43:41.937639  4164 layer_factory.hpp:77] Creating layer Scale18
I1101 13:43:41.937644  4164 net.cpp:84] Creating Layer Scale18
I1101 13:43:41.937645  4164 net.cpp:406] Scale18 <- Convolution18
I1101 13:43:41.937649  4164 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1101 13:43:41.937680  4164 layer_factory.hpp:77] Creating layer Scale18
I1101 13:43:41.937804  4164 net.cpp:122] Setting up Scale18
I1101 13:43:41.937809  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.937810  4164 net.cpp:137] Memory required for data: 469812400
I1101 13:43:41.937813  4164 layer_factory.hpp:77] Creating layer Eltwise8
I1101 13:43:41.937818  4164 net.cpp:84] Creating Layer Eltwise8
I1101 13:43:41.937819  4164 net.cpp:406] Eltwise8 <- Convolution18
I1101 13:43:41.937822  4164 net.cpp:406] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I1101 13:43:41.937824  4164 net.cpp:380] Eltwise8 -> Eltwise8
I1101 13:43:41.937855  4164 net.cpp:122] Setting up Eltwise8
I1101 13:43:41.937857  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.937860  4164 net.cpp:137] Memory required for data: 473089200
I1101 13:43:41.937861  4164 layer_factory.hpp:77] Creating layer ReLU17
I1101 13:43:41.937865  4164 net.cpp:84] Creating Layer ReLU17
I1101 13:43:41.937866  4164 net.cpp:406] ReLU17 <- Eltwise8
I1101 13:43:41.937870  4164 net.cpp:367] ReLU17 -> Eltwise8 (in-place)
I1101 13:43:41.938001  4164 net.cpp:122] Setting up ReLU17
I1101 13:43:41.938007  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.938009  4164 net.cpp:137] Memory required for data: 476366000
I1101 13:43:41.938010  4164 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I1101 13:43:41.938014  4164 net.cpp:84] Creating Layer Eltwise8_ReLU17_0_split
I1101 13:43:41.938015  4164 net.cpp:406] Eltwise8_ReLU17_0_split <- Eltwise8
I1101 13:43:41.938019  4164 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I1101 13:43:41.938022  4164 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I1101 13:43:41.938067  4164 net.cpp:122] Setting up Eltwise8_ReLU17_0_split
I1101 13:43:41.938071  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.938074  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.938076  4164 net.cpp:137] Memory required for data: 482919600
I1101 13:43:41.938077  4164 layer_factory.hpp:77] Creating layer Convolution19
I1101 13:43:41.938083  4164 net.cpp:84] Creating Layer Convolution19
I1101 13:43:41.938086  4164 net.cpp:406] Convolution19 <- Eltwise8_ReLU17_0_split_0
I1101 13:43:41.938091  4164 net.cpp:380] Convolution19 -> Convolution19
I1101 13:43:41.938937  4164 net.cpp:122] Setting up Convolution19
I1101 13:43:41.938946  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.938947  4164 net.cpp:137] Memory required for data: 486196400
I1101 13:43:41.938966  4164 layer_factory.hpp:77] Creating layer BatchNorm19
I1101 13:43:41.938971  4164 net.cpp:84] Creating Layer BatchNorm19
I1101 13:43:41.938973  4164 net.cpp:406] BatchNorm19 <- Convolution19
I1101 13:43:41.938977  4164 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1101 13:43:41.939149  4164 net.cpp:122] Setting up BatchNorm19
I1101 13:43:41.939153  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.939154  4164 net.cpp:137] Memory required for data: 489473200
I1101 13:43:41.939180  4164 layer_factory.hpp:77] Creating layer Scale19
I1101 13:43:41.939184  4164 net.cpp:84] Creating Layer Scale19
I1101 13:43:41.939187  4164 net.cpp:406] Scale19 <- Convolution19
I1101 13:43:41.939189  4164 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1101 13:43:41.939235  4164 layer_factory.hpp:77] Creating layer Scale19
I1101 13:43:41.939360  4164 net.cpp:122] Setting up Scale19
I1101 13:43:41.939364  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.939366  4164 net.cpp:137] Memory required for data: 492750000
I1101 13:43:41.939383  4164 layer_factory.hpp:77] Creating layer ReLU18
I1101 13:43:41.939386  4164 net.cpp:84] Creating Layer ReLU18
I1101 13:43:41.939395  4164 net.cpp:406] ReLU18 <- Convolution19
I1101 13:43:41.939399  4164 net.cpp:367] ReLU18 -> Convolution19 (in-place)
I1101 13:43:41.939558  4164 net.cpp:122] Setting up ReLU18
I1101 13:43:41.939563  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.939564  4164 net.cpp:137] Memory required for data: 496026800
I1101 13:43:41.939579  4164 layer_factory.hpp:77] Creating layer Convolution20
I1101 13:43:41.939585  4164 net.cpp:84] Creating Layer Convolution20
I1101 13:43:41.939589  4164 net.cpp:406] Convolution20 <- Convolution19
I1101 13:43:41.939592  4164 net.cpp:380] Convolution20 -> Convolution20
I1101 13:43:41.940466  4164 net.cpp:122] Setting up Convolution20
I1101 13:43:41.940474  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.940476  4164 net.cpp:137] Memory required for data: 499303600
I1101 13:43:41.940495  4164 layer_factory.hpp:77] Creating layer BatchNorm20
I1101 13:43:41.940500  4164 net.cpp:84] Creating Layer BatchNorm20
I1101 13:43:41.940501  4164 net.cpp:406] BatchNorm20 <- Convolution20
I1101 13:43:41.940505  4164 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1101 13:43:41.940680  4164 net.cpp:122] Setting up BatchNorm20
I1101 13:43:41.940685  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.940687  4164 net.cpp:137] Memory required for data: 502580400
I1101 13:43:41.940706  4164 layer_factory.hpp:77] Creating layer Scale20
I1101 13:43:41.940709  4164 net.cpp:84] Creating Layer Scale20
I1101 13:43:41.940711  4164 net.cpp:406] Scale20 <- Convolution20
I1101 13:43:41.940726  4164 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1101 13:43:41.940784  4164 layer_factory.hpp:77] Creating layer Scale20
I1101 13:43:41.940902  4164 net.cpp:122] Setting up Scale20
I1101 13:43:41.940907  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.940909  4164 net.cpp:137] Memory required for data: 505857200
I1101 13:43:41.940912  4164 layer_factory.hpp:77] Creating layer Eltwise9
I1101 13:43:41.940917  4164 net.cpp:84] Creating Layer Eltwise9
I1101 13:43:41.940918  4164 net.cpp:406] Eltwise9 <- Convolution20
I1101 13:43:41.940922  4164 net.cpp:406] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I1101 13:43:41.940925  4164 net.cpp:380] Eltwise9 -> Eltwise9
I1101 13:43:41.940958  4164 net.cpp:122] Setting up Eltwise9
I1101 13:43:41.940973  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.940975  4164 net.cpp:137] Memory required for data: 509134000
I1101 13:43:41.940978  4164 layer_factory.hpp:77] Creating layer ReLU19
I1101 13:43:41.940979  4164 net.cpp:84] Creating Layer ReLU19
I1101 13:43:41.940994  4164 net.cpp:406] ReLU19 <- Eltwise9
I1101 13:43:41.940999  4164 net.cpp:367] ReLU19 -> Eltwise9 (in-place)
I1101 13:43:41.941129  4164 net.cpp:122] Setting up ReLU19
I1101 13:43:41.941135  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.941136  4164 net.cpp:137] Memory required for data: 512410800
I1101 13:43:41.941138  4164 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I1101 13:43:41.941141  4164 net.cpp:84] Creating Layer Eltwise9_ReLU19_0_split
I1101 13:43:41.941143  4164 net.cpp:406] Eltwise9_ReLU19_0_split <- Eltwise9
I1101 13:43:41.941146  4164 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I1101 13:43:41.941153  4164 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I1101 13:43:41.941184  4164 net.cpp:122] Setting up Eltwise9_ReLU19_0_split
I1101 13:43:41.941189  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.941190  4164 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1101 13:43:41.941191  4164 net.cpp:137] Memory required for data: 518964400
I1101 13:43:41.941193  4164 layer_factory.hpp:77] Creating layer Convolution21
I1101 13:43:41.941200  4164 net.cpp:84] Creating Layer Convolution21
I1101 13:43:41.941201  4164 net.cpp:406] Convolution21 <- Eltwise9_ReLU19_0_split_0
I1101 13:43:41.941205  4164 net.cpp:380] Convolution21 -> Convolution21
I1101 13:43:41.942101  4164 net.cpp:122] Setting up Convolution21
I1101 13:43:41.942116  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.942118  4164 net.cpp:137] Memory required for data: 520602800
I1101 13:43:41.942122  4164 layer_factory.hpp:77] Creating layer BatchNorm21
I1101 13:43:41.942126  4164 net.cpp:84] Creating Layer BatchNorm21
I1101 13:43:41.942128  4164 net.cpp:406] BatchNorm21 <- Convolution21
I1101 13:43:41.942132  4164 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1101 13:43:41.942314  4164 net.cpp:122] Setting up BatchNorm21
I1101 13:43:41.942319  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.942322  4164 net.cpp:137] Memory required for data: 522241200
I1101 13:43:41.942325  4164 layer_factory.hpp:77] Creating layer Scale21
I1101 13:43:41.942328  4164 net.cpp:84] Creating Layer Scale21
I1101 13:43:41.942332  4164 net.cpp:406] Scale21 <- Convolution21
I1101 13:43:41.942335  4164 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1101 13:43:41.942366  4164 layer_factory.hpp:77] Creating layer Scale21
I1101 13:43:41.942479  4164 net.cpp:122] Setting up Scale21
I1101 13:43:41.942484  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.942487  4164 net.cpp:137] Memory required for data: 523879600
I1101 13:43:41.942489  4164 layer_factory.hpp:77] Creating layer ReLU20
I1101 13:43:41.942493  4164 net.cpp:84] Creating Layer ReLU20
I1101 13:43:41.942495  4164 net.cpp:406] ReLU20 <- Convolution21
I1101 13:43:41.942498  4164 net.cpp:367] ReLU20 -> Convolution21 (in-place)
I1101 13:43:41.942814  4164 net.cpp:122] Setting up ReLU20
I1101 13:43:41.942821  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.942824  4164 net.cpp:137] Memory required for data: 525518000
I1101 13:43:41.942826  4164 layer_factory.hpp:77] Creating layer Convolution22
I1101 13:43:41.942831  4164 net.cpp:84] Creating Layer Convolution22
I1101 13:43:41.942834  4164 net.cpp:406] Convolution22 <- Convolution21
I1101 13:43:41.942839  4164 net.cpp:380] Convolution22 -> Convolution22
I1101 13:43:41.943852  4164 net.cpp:122] Setting up Convolution22
I1101 13:43:41.943861  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.943862  4164 net.cpp:137] Memory required for data: 527156400
I1101 13:43:41.943866  4164 layer_factory.hpp:77] Creating layer BatchNorm22
I1101 13:43:41.943871  4164 net.cpp:84] Creating Layer BatchNorm22
I1101 13:43:41.943873  4164 net.cpp:406] BatchNorm22 <- Convolution22
I1101 13:43:41.943876  4164 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1101 13:43:41.944041  4164 net.cpp:122] Setting up BatchNorm22
I1101 13:43:41.944046  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.944047  4164 net.cpp:137] Memory required for data: 528794800
I1101 13:43:41.944051  4164 layer_factory.hpp:77] Creating layer Scale22
I1101 13:43:41.944054  4164 net.cpp:84] Creating Layer Scale22
I1101 13:43:41.944056  4164 net.cpp:406] Scale22 <- Convolution22
I1101 13:43:41.944059  4164 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1101 13:43:41.944092  4164 layer_factory.hpp:77] Creating layer Scale22
I1101 13:43:41.944187  4164 net.cpp:122] Setting up Scale22
I1101 13:43:41.944191  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.944193  4164 net.cpp:137] Memory required for data: 530433200
I1101 13:43:41.944197  4164 layer_factory.hpp:77] Creating layer Convolution23
I1101 13:43:41.944216  4164 net.cpp:84] Creating Layer Convolution23
I1101 13:43:41.944217  4164 net.cpp:406] Convolution23 <- Eltwise9_ReLU19_0_split_1
I1101 13:43:41.944222  4164 net.cpp:380] Convolution23 -> Convolution23
I1101 13:43:41.944829  4164 net.cpp:122] Setting up Convolution23
I1101 13:43:41.944836  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.944839  4164 net.cpp:137] Memory required for data: 532071600
I1101 13:43:41.944841  4164 layer_factory.hpp:77] Creating layer BatchNorm23
I1101 13:43:41.944844  4164 net.cpp:84] Creating Layer BatchNorm23
I1101 13:43:41.944846  4164 net.cpp:406] BatchNorm23 <- Convolution23
I1101 13:43:41.944850  4164 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1101 13:43:41.945014  4164 net.cpp:122] Setting up BatchNorm23
I1101 13:43:41.945025  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.945027  4164 net.cpp:137] Memory required for data: 533710000
I1101 13:43:41.945031  4164 layer_factory.hpp:77] Creating layer Scale23
I1101 13:43:41.945035  4164 net.cpp:84] Creating Layer Scale23
I1101 13:43:41.945039  4164 net.cpp:406] Scale23 <- Convolution23
I1101 13:43:41.945041  4164 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1101 13:43:41.945071  4164 layer_factory.hpp:77] Creating layer Scale23
I1101 13:43:41.945168  4164 net.cpp:122] Setting up Scale23
I1101 13:43:41.945171  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.945173  4164 net.cpp:137] Memory required for data: 535348400
I1101 13:43:41.945175  4164 layer_factory.hpp:77] Creating layer Eltwise10
I1101 13:43:41.945180  4164 net.cpp:84] Creating Layer Eltwise10
I1101 13:43:41.945183  4164 net.cpp:406] Eltwise10 <- Convolution22
I1101 13:43:41.945185  4164 net.cpp:406] Eltwise10 <- Convolution23
I1101 13:43:41.945189  4164 net.cpp:380] Eltwise10 -> Eltwise10
I1101 13:43:41.945207  4164 net.cpp:122] Setting up Eltwise10
I1101 13:43:41.945211  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.945212  4164 net.cpp:137] Memory required for data: 536986800
I1101 13:43:41.945214  4164 layer_factory.hpp:77] Creating layer ReLU21
I1101 13:43:41.945217  4164 net.cpp:84] Creating Layer ReLU21
I1101 13:43:41.945219  4164 net.cpp:406] ReLU21 <- Eltwise10
I1101 13:43:41.945222  4164 net.cpp:367] ReLU21 -> Eltwise10 (in-place)
I1101 13:43:41.945540  4164 net.cpp:122] Setting up ReLU21
I1101 13:43:41.945547  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.945550  4164 net.cpp:137] Memory required for data: 538625200
I1101 13:43:41.945552  4164 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I1101 13:43:41.945556  4164 net.cpp:84] Creating Layer Eltwise10_ReLU21_0_split
I1101 13:43:41.945570  4164 net.cpp:406] Eltwise10_ReLU21_0_split <- Eltwise10
I1101 13:43:41.945575  4164 net.cpp:380] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I1101 13:43:41.945580  4164 net.cpp:380] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I1101 13:43:41.945626  4164 net.cpp:122] Setting up Eltwise10_ReLU21_0_split
I1101 13:43:41.945629  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.945632  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.945633  4164 net.cpp:137] Memory required for data: 541902000
I1101 13:43:41.945636  4164 layer_factory.hpp:77] Creating layer Convolution24
I1101 13:43:41.945641  4164 net.cpp:84] Creating Layer Convolution24
I1101 13:43:41.945657  4164 net.cpp:406] Convolution24 <- Eltwise10_ReLU21_0_split_0
I1101 13:43:41.945660  4164 net.cpp:380] Convolution24 -> Convolution24
I1101 13:43:41.946710  4164 net.cpp:122] Setting up Convolution24
I1101 13:43:41.946718  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.946722  4164 net.cpp:137] Memory required for data: 543540400
I1101 13:43:41.946725  4164 layer_factory.hpp:77] Creating layer BatchNorm24
I1101 13:43:41.946741  4164 net.cpp:84] Creating Layer BatchNorm24
I1101 13:43:41.946744  4164 net.cpp:406] BatchNorm24 <- Convolution24
I1101 13:43:41.946748  4164 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1101 13:43:41.946954  4164 net.cpp:122] Setting up BatchNorm24
I1101 13:43:41.946957  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.946959  4164 net.cpp:137] Memory required for data: 545178800
I1101 13:43:41.946964  4164 layer_factory.hpp:77] Creating layer Scale24
I1101 13:43:41.946980  4164 net.cpp:84] Creating Layer Scale24
I1101 13:43:41.946983  4164 net.cpp:406] Scale24 <- Convolution24
I1101 13:43:41.946986  4164 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1101 13:43:41.947029  4164 layer_factory.hpp:77] Creating layer Scale24
I1101 13:43:41.947127  4164 net.cpp:122] Setting up Scale24
I1101 13:43:41.947132  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.947134  4164 net.cpp:137] Memory required for data: 546817200
I1101 13:43:41.947144  4164 layer_factory.hpp:77] Creating layer ReLU22
I1101 13:43:41.947147  4164 net.cpp:84] Creating Layer ReLU22
I1101 13:43:41.947149  4164 net.cpp:406] ReLU22 <- Convolution24
I1101 13:43:41.947152  4164 net.cpp:367] ReLU22 -> Convolution24 (in-place)
I1101 13:43:41.947273  4164 net.cpp:122] Setting up ReLU22
I1101 13:43:41.947278  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.947280  4164 net.cpp:137] Memory required for data: 548455600
I1101 13:43:41.947281  4164 layer_factory.hpp:77] Creating layer Convolution25
I1101 13:43:41.947286  4164 net.cpp:84] Creating Layer Convolution25
I1101 13:43:41.947288  4164 net.cpp:406] Convolution25 <- Convolution24
I1101 13:43:41.947293  4164 net.cpp:380] Convolution25 -> Convolution25
I1101 13:43:41.948303  4164 net.cpp:122] Setting up Convolution25
I1101 13:43:41.948312  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.948313  4164 net.cpp:137] Memory required for data: 550094000
I1101 13:43:41.948318  4164 layer_factory.hpp:77] Creating layer BatchNorm25
I1101 13:43:41.948334  4164 net.cpp:84] Creating Layer BatchNorm25
I1101 13:43:41.948338  4164 net.cpp:406] BatchNorm25 <- Convolution25
I1101 13:43:41.948341  4164 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1101 13:43:41.948551  4164 net.cpp:122] Setting up BatchNorm25
I1101 13:43:41.948556  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.948557  4164 net.cpp:137] Memory required for data: 551732400
I1101 13:43:41.948561  4164 layer_factory.hpp:77] Creating layer Scale25
I1101 13:43:41.948566  4164 net.cpp:84] Creating Layer Scale25
I1101 13:43:41.948570  4164 net.cpp:406] Scale25 <- Convolution25
I1101 13:43:41.948571  4164 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1101 13:43:41.948633  4164 layer_factory.hpp:77] Creating layer Scale25
I1101 13:43:41.948756  4164 net.cpp:122] Setting up Scale25
I1101 13:43:41.948760  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.948762  4164 net.cpp:137] Memory required for data: 553370800
I1101 13:43:41.948765  4164 layer_factory.hpp:77] Creating layer Eltwise11
I1101 13:43:41.948768  4164 net.cpp:84] Creating Layer Eltwise11
I1101 13:43:41.948770  4164 net.cpp:406] Eltwise11 <- Convolution25
I1101 13:43:41.948772  4164 net.cpp:406] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I1101 13:43:41.948776  4164 net.cpp:380] Eltwise11 -> Eltwise11
I1101 13:43:41.948794  4164 net.cpp:122] Setting up Eltwise11
I1101 13:43:41.948798  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.948799  4164 net.cpp:137] Memory required for data: 555009200
I1101 13:43:41.948801  4164 layer_factory.hpp:77] Creating layer ReLU23
I1101 13:43:41.948804  4164 net.cpp:84] Creating Layer ReLU23
I1101 13:43:41.948807  4164 net.cpp:406] ReLU23 <- Eltwise11
I1101 13:43:41.948808  4164 net.cpp:367] ReLU23 -> Eltwise11 (in-place)
I1101 13:43:41.948961  4164 net.cpp:122] Setting up ReLU23
I1101 13:43:41.948967  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.948971  4164 net.cpp:137] Memory required for data: 556647600
I1101 13:43:41.948971  4164 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I1101 13:43:41.948974  4164 net.cpp:84] Creating Layer Eltwise11_ReLU23_0_split
I1101 13:43:41.948976  4164 net.cpp:406] Eltwise11_ReLU23_0_split <- Eltwise11
I1101 13:43:41.948979  4164 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I1101 13:43:41.948983  4164 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I1101 13:43:41.949028  4164 net.cpp:122] Setting up Eltwise11_ReLU23_0_split
I1101 13:43:41.949031  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.949046  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.949048  4164 net.cpp:137] Memory required for data: 559924400
I1101 13:43:41.949049  4164 layer_factory.hpp:77] Creating layer Convolution26
I1101 13:43:41.949055  4164 net.cpp:84] Creating Layer Convolution26
I1101 13:43:41.949057  4164 net.cpp:406] Convolution26 <- Eltwise11_ReLU23_0_split_0
I1101 13:43:41.949067  4164 net.cpp:380] Convolution26 -> Convolution26
I1101 13:43:41.950676  4164 net.cpp:122] Setting up Convolution26
I1101 13:43:41.950685  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.950687  4164 net.cpp:137] Memory required for data: 561562800
I1101 13:43:41.950691  4164 layer_factory.hpp:77] Creating layer BatchNorm26
I1101 13:43:41.950697  4164 net.cpp:84] Creating Layer BatchNorm26
I1101 13:43:41.950700  4164 net.cpp:406] BatchNorm26 <- Convolution26
I1101 13:43:41.950703  4164 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1101 13:43:41.950901  4164 net.cpp:122] Setting up BatchNorm26
I1101 13:43:41.950906  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.950906  4164 net.cpp:137] Memory required for data: 563201200
I1101 13:43:41.950911  4164 layer_factory.hpp:77] Creating layer Scale26
I1101 13:43:41.950914  4164 net.cpp:84] Creating Layer Scale26
I1101 13:43:41.950917  4164 net.cpp:406] Scale26 <- Convolution26
I1101 13:43:41.950918  4164 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1101 13:43:41.950965  4164 layer_factory.hpp:77] Creating layer Scale26
I1101 13:43:41.951076  4164 net.cpp:122] Setting up Scale26
I1101 13:43:41.951081  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.951082  4164 net.cpp:137] Memory required for data: 564839600
I1101 13:43:41.951086  4164 layer_factory.hpp:77] Creating layer ReLU24
I1101 13:43:41.951089  4164 net.cpp:84] Creating Layer ReLU24
I1101 13:43:41.951092  4164 net.cpp:406] ReLU24 <- Convolution26
I1101 13:43:41.951094  4164 net.cpp:367] ReLU24 -> Convolution26 (in-place)
I1101 13:43:41.951242  4164 net.cpp:122] Setting up ReLU24
I1101 13:43:41.951247  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.951249  4164 net.cpp:137] Memory required for data: 566478000
I1101 13:43:41.951251  4164 layer_factory.hpp:77] Creating layer Convolution27
I1101 13:43:41.951272  4164 net.cpp:84] Creating Layer Convolution27
I1101 13:43:41.951275  4164 net.cpp:406] Convolution27 <- Convolution26
I1101 13:43:41.951278  4164 net.cpp:380] Convolution27 -> Convolution27
I1101 13:43:41.952337  4164 net.cpp:122] Setting up Convolution27
I1101 13:43:41.952345  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.952363  4164 net.cpp:137] Memory required for data: 568116400
I1101 13:43:41.952366  4164 layer_factory.hpp:77] Creating layer BatchNorm27
I1101 13:43:41.952381  4164 net.cpp:84] Creating Layer BatchNorm27
I1101 13:43:41.952384  4164 net.cpp:406] BatchNorm27 <- Convolution27
I1101 13:43:41.952389  4164 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1101 13:43:41.952601  4164 net.cpp:122] Setting up BatchNorm27
I1101 13:43:41.952605  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.952607  4164 net.cpp:137] Memory required for data: 569754800
I1101 13:43:41.952625  4164 layer_factory.hpp:77] Creating layer Scale27
I1101 13:43:41.952630  4164 net.cpp:84] Creating Layer Scale27
I1101 13:43:41.952631  4164 net.cpp:406] Scale27 <- Convolution27
I1101 13:43:41.952636  4164 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1101 13:43:41.952695  4164 layer_factory.hpp:77] Creating layer Scale27
I1101 13:43:41.952818  4164 net.cpp:122] Setting up Scale27
I1101 13:43:41.952823  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.952824  4164 net.cpp:137] Memory required for data: 571393200
I1101 13:43:41.952828  4164 layer_factory.hpp:77] Creating layer Eltwise12
I1101 13:43:41.952833  4164 net.cpp:84] Creating Layer Eltwise12
I1101 13:43:41.952836  4164 net.cpp:406] Eltwise12 <- Convolution27
I1101 13:43:41.952838  4164 net.cpp:406] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I1101 13:43:41.952841  4164 net.cpp:380] Eltwise12 -> Eltwise12
I1101 13:43:41.952862  4164 net.cpp:122] Setting up Eltwise12
I1101 13:43:41.952865  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.952867  4164 net.cpp:137] Memory required for data: 573031600
I1101 13:43:41.952869  4164 layer_factory.hpp:77] Creating layer ReLU25
I1101 13:43:41.952872  4164 net.cpp:84] Creating Layer ReLU25
I1101 13:43:41.952881  4164 net.cpp:406] ReLU25 <- Eltwise12
I1101 13:43:41.952885  4164 net.cpp:367] ReLU25 -> Eltwise12 (in-place)
I1101 13:43:41.953009  4164 net.cpp:122] Setting up ReLU25
I1101 13:43:41.953014  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.953016  4164 net.cpp:137] Memory required for data: 574670000
I1101 13:43:41.953017  4164 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I1101 13:43:41.953022  4164 net.cpp:84] Creating Layer Eltwise12_ReLU25_0_split
I1101 13:43:41.953023  4164 net.cpp:406] Eltwise12_ReLU25_0_split <- Eltwise12
I1101 13:43:41.953027  4164 net.cpp:380] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I1101 13:43:41.953030  4164 net.cpp:380] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I1101 13:43:41.953064  4164 net.cpp:122] Setting up Eltwise12_ReLU25_0_split
I1101 13:43:41.953068  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.953070  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.953073  4164 net.cpp:137] Memory required for data: 577946800
I1101 13:43:41.953074  4164 layer_factory.hpp:77] Creating layer Convolution28
I1101 13:43:41.953080  4164 net.cpp:84] Creating Layer Convolution28
I1101 13:43:41.953083  4164 net.cpp:406] Convolution28 <- Eltwise12_ReLU25_0_split_0
I1101 13:43:41.953086  4164 net.cpp:380] Convolution28 -> Convolution28
I1101 13:43:41.954119  4164 net.cpp:122] Setting up Convolution28
I1101 13:43:41.954128  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.954131  4164 net.cpp:137] Memory required for data: 579585200
I1101 13:43:41.954135  4164 layer_factory.hpp:77] Creating layer BatchNorm28
I1101 13:43:41.954140  4164 net.cpp:84] Creating Layer BatchNorm28
I1101 13:43:41.954143  4164 net.cpp:406] BatchNorm28 <- Convolution28
I1101 13:43:41.954147  4164 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1101 13:43:41.954324  4164 net.cpp:122] Setting up BatchNorm28
I1101 13:43:41.954327  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.954329  4164 net.cpp:137] Memory required for data: 581223600
I1101 13:43:41.954334  4164 layer_factory.hpp:77] Creating layer Scale28
I1101 13:43:41.954337  4164 net.cpp:84] Creating Layer Scale28
I1101 13:43:41.954340  4164 net.cpp:406] Scale28 <- Convolution28
I1101 13:43:41.954342  4164 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1101 13:43:41.954376  4164 layer_factory.hpp:77] Creating layer Scale28
I1101 13:43:41.954484  4164 net.cpp:122] Setting up Scale28
I1101 13:43:41.954489  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.954491  4164 net.cpp:137] Memory required for data: 582862000
I1101 13:43:41.954494  4164 layer_factory.hpp:77] Creating layer ReLU26
I1101 13:43:41.954499  4164 net.cpp:84] Creating Layer ReLU26
I1101 13:43:41.954501  4164 net.cpp:406] ReLU26 <- Convolution28
I1101 13:43:41.954504  4164 net.cpp:367] ReLU26 -> Convolution28 (in-place)
I1101 13:43:41.954835  4164 net.cpp:122] Setting up ReLU26
I1101 13:43:41.954843  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.954844  4164 net.cpp:137] Memory required for data: 584500400
I1101 13:43:41.954846  4164 layer_factory.hpp:77] Creating layer Convolution29
I1101 13:43:41.954852  4164 net.cpp:84] Creating Layer Convolution29
I1101 13:43:41.954855  4164 net.cpp:406] Convolution29 <- Convolution28
I1101 13:43:41.954859  4164 net.cpp:380] Convolution29 -> Convolution29
I1101 13:43:41.955740  4164 net.cpp:122] Setting up Convolution29
I1101 13:43:41.955750  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.955754  4164 net.cpp:137] Memory required for data: 586138800
I1101 13:43:41.955759  4164 layer_factory.hpp:77] Creating layer BatchNorm29
I1101 13:43:41.955765  4164 net.cpp:84] Creating Layer BatchNorm29
I1101 13:43:41.955768  4164 net.cpp:406] BatchNorm29 <- Convolution29
I1101 13:43:41.955773  4164 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1101 13:43:41.955963  4164 net.cpp:122] Setting up BatchNorm29
I1101 13:43:41.955970  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.955978  4164 net.cpp:137] Memory required for data: 587777200
I1101 13:43:41.955983  4164 layer_factory.hpp:77] Creating layer Scale29
I1101 13:43:41.955987  4164 net.cpp:84] Creating Layer Scale29
I1101 13:43:41.955989  4164 net.cpp:406] Scale29 <- Convolution29
I1101 13:43:41.955992  4164 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1101 13:43:41.956027  4164 layer_factory.hpp:77] Creating layer Scale29
I1101 13:43:41.956130  4164 net.cpp:122] Setting up Scale29
I1101 13:43:41.956135  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.956135  4164 net.cpp:137] Memory required for data: 589415600
I1101 13:43:41.956138  4164 layer_factory.hpp:77] Creating layer Eltwise13
I1101 13:43:41.956142  4164 net.cpp:84] Creating Layer Eltwise13
I1101 13:43:41.956146  4164 net.cpp:406] Eltwise13 <- Convolution29
I1101 13:43:41.956148  4164 net.cpp:406] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I1101 13:43:41.956151  4164 net.cpp:380] Eltwise13 -> Eltwise13
I1101 13:43:41.956171  4164 net.cpp:122] Setting up Eltwise13
I1101 13:43:41.956176  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.956177  4164 net.cpp:137] Memory required for data: 591054000
I1101 13:43:41.956178  4164 layer_factory.hpp:77] Creating layer ReLU27
I1101 13:43:41.956182  4164 net.cpp:84] Creating Layer ReLU27
I1101 13:43:41.956183  4164 net.cpp:406] ReLU27 <- Eltwise13
I1101 13:43:41.956187  4164 net.cpp:367] ReLU27 -> Eltwise13 (in-place)
I1101 13:43:41.956547  4164 net.cpp:122] Setting up ReLU27
I1101 13:43:41.956555  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.956557  4164 net.cpp:137] Memory required for data: 592692400
I1101 13:43:41.956559  4164 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I1101 13:43:41.956564  4164 net.cpp:84] Creating Layer Eltwise13_ReLU27_0_split
I1101 13:43:41.956567  4164 net.cpp:406] Eltwise13_ReLU27_0_split <- Eltwise13
I1101 13:43:41.956569  4164 net.cpp:380] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I1101 13:43:41.956575  4164 net.cpp:380] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I1101 13:43:41.956611  4164 net.cpp:122] Setting up Eltwise13_ReLU27_0_split
I1101 13:43:41.956615  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.956619  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.956620  4164 net.cpp:137] Memory required for data: 595969200
I1101 13:43:41.956621  4164 layer_factory.hpp:77] Creating layer Convolution30
I1101 13:43:41.956627  4164 net.cpp:84] Creating Layer Convolution30
I1101 13:43:41.956630  4164 net.cpp:406] Convolution30 <- Eltwise13_ReLU27_0_split_0
I1101 13:43:41.956635  4164 net.cpp:380] Convolution30 -> Convolution30
I1101 13:43:41.957831  4164 net.cpp:122] Setting up Convolution30
I1101 13:43:41.957844  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.957847  4164 net.cpp:137] Memory required for data: 597607600
I1101 13:43:41.957854  4164 layer_factory.hpp:77] Creating layer BatchNorm30
I1101 13:43:41.957861  4164 net.cpp:84] Creating Layer BatchNorm30
I1101 13:43:41.957865  4164 net.cpp:406] BatchNorm30 <- Convolution30
I1101 13:43:41.957871  4164 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1101 13:43:41.958149  4164 net.cpp:122] Setting up BatchNorm30
I1101 13:43:41.958159  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.958161  4164 net.cpp:137] Memory required for data: 599246000
I1101 13:43:41.958166  4164 layer_factory.hpp:77] Creating layer Scale30
I1101 13:43:41.958173  4164 net.cpp:84] Creating Layer Scale30
I1101 13:43:41.958178  4164 net.cpp:406] Scale30 <- Convolution30
I1101 13:43:41.958181  4164 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1101 13:43:41.958231  4164 layer_factory.hpp:77] Creating layer Scale30
I1101 13:43:41.958385  4164 net.cpp:122] Setting up Scale30
I1101 13:43:41.958395  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.958398  4164 net.cpp:137] Memory required for data: 600884400
I1101 13:43:41.958405  4164 layer_factory.hpp:77] Creating layer ReLU28
I1101 13:43:41.958410  4164 net.cpp:84] Creating Layer ReLU28
I1101 13:43:41.958444  4164 net.cpp:406] ReLU28 <- Convolution30
I1101 13:43:41.958451  4164 net.cpp:367] ReLU28 -> Convolution30 (in-place)
I1101 13:43:41.958597  4164 net.cpp:122] Setting up ReLU28
I1101 13:43:41.958604  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.958606  4164 net.cpp:137] Memory required for data: 602522800
I1101 13:43:41.958608  4164 layer_factory.hpp:77] Creating layer Convolution31
I1101 13:43:41.958616  4164 net.cpp:84] Creating Layer Convolution31
I1101 13:43:41.958617  4164 net.cpp:406] Convolution31 <- Convolution30
I1101 13:43:41.958621  4164 net.cpp:380] Convolution31 -> Convolution31
I1101 13:43:41.959694  4164 net.cpp:122] Setting up Convolution31
I1101 13:43:41.959703  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.959707  4164 net.cpp:137] Memory required for data: 604161200
I1101 13:43:41.959709  4164 layer_factory.hpp:77] Creating layer BatchNorm31
I1101 13:43:41.959714  4164 net.cpp:84] Creating Layer BatchNorm31
I1101 13:43:41.959717  4164 net.cpp:406] BatchNorm31 <- Convolution31
I1101 13:43:41.959720  4164 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1101 13:43:41.959897  4164 net.cpp:122] Setting up BatchNorm31
I1101 13:43:41.959903  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.959904  4164 net.cpp:137] Memory required for data: 605799600
I1101 13:43:41.959908  4164 layer_factory.hpp:77] Creating layer Scale31
I1101 13:43:41.959911  4164 net.cpp:84] Creating Layer Scale31
I1101 13:43:41.959913  4164 net.cpp:406] Scale31 <- Convolution31
I1101 13:43:41.959918  4164 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1101 13:43:41.959950  4164 layer_factory.hpp:77] Creating layer Scale31
I1101 13:43:41.960053  4164 net.cpp:122] Setting up Scale31
I1101 13:43:41.960057  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.960059  4164 net.cpp:137] Memory required for data: 607438000
I1101 13:43:41.960062  4164 layer_factory.hpp:77] Creating layer Eltwise14
I1101 13:43:41.960067  4164 net.cpp:84] Creating Layer Eltwise14
I1101 13:43:41.960068  4164 net.cpp:406] Eltwise14 <- Convolution31
I1101 13:43:41.960070  4164 net.cpp:406] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I1101 13:43:41.960074  4164 net.cpp:380] Eltwise14 -> Eltwise14
I1101 13:43:41.960094  4164 net.cpp:122] Setting up Eltwise14
I1101 13:43:41.960098  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.960099  4164 net.cpp:137] Memory required for data: 609076400
I1101 13:43:41.960101  4164 layer_factory.hpp:77] Creating layer ReLU29
I1101 13:43:41.960104  4164 net.cpp:84] Creating Layer ReLU29
I1101 13:43:41.960106  4164 net.cpp:406] ReLU29 <- Eltwise14
I1101 13:43:41.960108  4164 net.cpp:367] ReLU29 -> Eltwise14 (in-place)
I1101 13:43:41.960232  4164 net.cpp:122] Setting up ReLU29
I1101 13:43:41.960237  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.960238  4164 net.cpp:137] Memory required for data: 610714800
I1101 13:43:41.960240  4164 layer_factory.hpp:77] Creating layer Eltwise14_ReLU29_0_split
I1101 13:43:41.960244  4164 net.cpp:84] Creating Layer Eltwise14_ReLU29_0_split
I1101 13:43:41.960247  4164 net.cpp:406] Eltwise14_ReLU29_0_split <- Eltwise14
I1101 13:43:41.960250  4164 net.cpp:380] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_0
I1101 13:43:41.960254  4164 net.cpp:380] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_1
I1101 13:43:41.960289  4164 net.cpp:122] Setting up Eltwise14_ReLU29_0_split
I1101 13:43:41.960292  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.960294  4164 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1101 13:43:41.960296  4164 net.cpp:137] Memory required for data: 613991600
I1101 13:43:41.960299  4164 layer_factory.hpp:77] Creating layer Convolution32
I1101 13:43:41.960304  4164 net.cpp:84] Creating Layer Convolution32
I1101 13:43:41.960306  4164 net.cpp:406] Convolution32 <- Eltwise14_ReLU29_0_split_0
I1101 13:43:41.960309  4164 net.cpp:380] Convolution32 -> Convolution32
I1101 13:43:41.961800  4164 net.cpp:122] Setting up Convolution32
I1101 13:43:41.961815  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.961817  4164 net.cpp:137] Memory required for data: 614810800
I1101 13:43:41.961822  4164 layer_factory.hpp:77] Creating layer BatchNorm32
I1101 13:43:41.961827  4164 net.cpp:84] Creating Layer BatchNorm32
I1101 13:43:41.961829  4164 net.cpp:406] BatchNorm32 <- Convolution32
I1101 13:43:41.961833  4164 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1101 13:43:41.962009  4164 net.cpp:122] Setting up BatchNorm32
I1101 13:43:41.962013  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.962016  4164 net.cpp:137] Memory required for data: 615630000
I1101 13:43:41.962019  4164 layer_factory.hpp:77] Creating layer Scale32
I1101 13:43:41.962023  4164 net.cpp:84] Creating Layer Scale32
I1101 13:43:41.962025  4164 net.cpp:406] Scale32 <- Convolution32
I1101 13:43:41.962028  4164 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1101 13:43:41.962061  4164 layer_factory.hpp:77] Creating layer Scale32
I1101 13:43:41.962158  4164 net.cpp:122] Setting up Scale32
I1101 13:43:41.962162  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.962164  4164 net.cpp:137] Memory required for data: 616449200
I1101 13:43:41.962167  4164 layer_factory.hpp:77] Creating layer ReLU30
I1101 13:43:41.962172  4164 net.cpp:84] Creating Layer ReLU30
I1101 13:43:41.962174  4164 net.cpp:406] ReLU30 <- Convolution32
I1101 13:43:41.962178  4164 net.cpp:367] ReLU30 -> Convolution32 (in-place)
I1101 13:43:41.962306  4164 net.cpp:122] Setting up ReLU30
I1101 13:43:41.962311  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.962312  4164 net.cpp:137] Memory required for data: 617268400
I1101 13:43:41.962316  4164 layer_factory.hpp:77] Creating layer Convolution33
I1101 13:43:41.962321  4164 net.cpp:84] Creating Layer Convolution33
I1101 13:43:41.962323  4164 net.cpp:406] Convolution33 <- Convolution32
I1101 13:43:41.962327  4164 net.cpp:380] Convolution33 -> Convolution33
I1101 13:43:41.964288  4164 net.cpp:122] Setting up Convolution33
I1101 13:43:41.964298  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.964299  4164 net.cpp:137] Memory required for data: 618087600
I1101 13:43:41.964303  4164 layer_factory.hpp:77] Creating layer BatchNorm33
I1101 13:43:41.964308  4164 net.cpp:84] Creating Layer BatchNorm33
I1101 13:43:41.964310  4164 net.cpp:406] BatchNorm33 <- Convolution33
I1101 13:43:41.964314  4164 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1101 13:43:41.964490  4164 net.cpp:122] Setting up BatchNorm33
I1101 13:43:41.964495  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.964498  4164 net.cpp:137] Memory required for data: 618906800
I1101 13:43:41.964501  4164 layer_factory.hpp:77] Creating layer Scale33
I1101 13:43:41.964505  4164 net.cpp:84] Creating Layer Scale33
I1101 13:43:41.964506  4164 net.cpp:406] Scale33 <- Convolution33
I1101 13:43:41.964510  4164 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1101 13:43:41.964542  4164 layer_factory.hpp:77] Creating layer Scale33
I1101 13:43:41.964640  4164 net.cpp:122] Setting up Scale33
I1101 13:43:41.964644  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.964646  4164 net.cpp:137] Memory required for data: 619726000
I1101 13:43:41.964649  4164 layer_factory.hpp:77] Creating layer Convolution34
I1101 13:43:41.964655  4164 net.cpp:84] Creating Layer Convolution34
I1101 13:43:41.964658  4164 net.cpp:406] Convolution34 <- Eltwise14_ReLU29_0_split_1
I1101 13:43:41.964663  4164 net.cpp:380] Convolution34 -> Convolution34
I1101 13:43:41.965534  4164 net.cpp:122] Setting up Convolution34
I1101 13:43:41.965543  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.965546  4164 net.cpp:137] Memory required for data: 620545200
I1101 13:43:41.965550  4164 layer_factory.hpp:77] Creating layer BatchNorm34
I1101 13:43:41.965554  4164 net.cpp:84] Creating Layer BatchNorm34
I1101 13:43:41.965556  4164 net.cpp:406] BatchNorm34 <- Convolution34
I1101 13:43:41.965560  4164 net.cpp:367] BatchNorm34 -> Convolution34 (in-place)
I1101 13:43:41.965741  4164 net.cpp:122] Setting up BatchNorm34
I1101 13:43:41.965746  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.965747  4164 net.cpp:137] Memory required for data: 621364400
I1101 13:43:41.965751  4164 layer_factory.hpp:77] Creating layer Scale34
I1101 13:43:41.965755  4164 net.cpp:84] Creating Layer Scale34
I1101 13:43:41.965757  4164 net.cpp:406] Scale34 <- Convolution34
I1101 13:43:41.965760  4164 net.cpp:367] Scale34 -> Convolution34 (in-place)
I1101 13:43:41.965792  4164 layer_factory.hpp:77] Creating layer Scale34
I1101 13:43:41.965888  4164 net.cpp:122] Setting up Scale34
I1101 13:43:41.965893  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.965893  4164 net.cpp:137] Memory required for data: 622183600
I1101 13:43:41.965896  4164 layer_factory.hpp:77] Creating layer Eltwise15
I1101 13:43:41.965901  4164 net.cpp:84] Creating Layer Eltwise15
I1101 13:43:41.965903  4164 net.cpp:406] Eltwise15 <- Convolution33
I1101 13:43:41.965905  4164 net.cpp:406] Eltwise15 <- Convolution34
I1101 13:43:41.965909  4164 net.cpp:380] Eltwise15 -> Eltwise15
I1101 13:43:41.965927  4164 net.cpp:122] Setting up Eltwise15
I1101 13:43:41.965931  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.965934  4164 net.cpp:137] Memory required for data: 623002800
I1101 13:43:41.965934  4164 layer_factory.hpp:77] Creating layer ReLU31
I1101 13:43:41.965939  4164 net.cpp:84] Creating Layer ReLU31
I1101 13:43:41.965940  4164 net.cpp:406] ReLU31 <- Eltwise15
I1101 13:43:41.965945  4164 net.cpp:367] ReLU31 -> Eltwise15 (in-place)
I1101 13:43:41.966068  4164 net.cpp:122] Setting up ReLU31
I1101 13:43:41.966073  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.966075  4164 net.cpp:137] Memory required for data: 623822000
I1101 13:43:41.966076  4164 layer_factory.hpp:77] Creating layer Eltwise15_ReLU31_0_split
I1101 13:43:41.966079  4164 net.cpp:84] Creating Layer Eltwise15_ReLU31_0_split
I1101 13:43:41.966081  4164 net.cpp:406] Eltwise15_ReLU31_0_split <- Eltwise15
I1101 13:43:41.966086  4164 net.cpp:380] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_0
I1101 13:43:41.966091  4164 net.cpp:380] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_1
I1101 13:43:41.966125  4164 net.cpp:122] Setting up Eltwise15_ReLU31_0_split
I1101 13:43:41.966128  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.966131  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.966133  4164 net.cpp:137] Memory required for data: 625460400
I1101 13:43:41.966135  4164 layer_factory.hpp:77] Creating layer Convolution35
I1101 13:43:41.966140  4164 net.cpp:84] Creating Layer Convolution35
I1101 13:43:41.966143  4164 net.cpp:406] Convolution35 <- Eltwise15_ReLU31_0_split_0
I1101 13:43:41.966147  4164 net.cpp:380] Convolution35 -> Convolution35
I1101 13:43:41.968093  4164 net.cpp:122] Setting up Convolution35
I1101 13:43:41.968101  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.968104  4164 net.cpp:137] Memory required for data: 626279600
I1101 13:43:41.968108  4164 layer_factory.hpp:77] Creating layer BatchNorm35
I1101 13:43:41.968112  4164 net.cpp:84] Creating Layer BatchNorm35
I1101 13:43:41.968116  4164 net.cpp:406] BatchNorm35 <- Convolution35
I1101 13:43:41.968119  4164 net.cpp:367] BatchNorm35 -> Convolution35 (in-place)
I1101 13:43:41.968297  4164 net.cpp:122] Setting up BatchNorm35
I1101 13:43:41.968302  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.968303  4164 net.cpp:137] Memory required for data: 627098800
I1101 13:43:41.968308  4164 layer_factory.hpp:77] Creating layer Scale35
I1101 13:43:41.968312  4164 net.cpp:84] Creating Layer Scale35
I1101 13:43:41.968315  4164 net.cpp:406] Scale35 <- Convolution35
I1101 13:43:41.968318  4164 net.cpp:367] Scale35 -> Convolution35 (in-place)
I1101 13:43:41.968351  4164 layer_factory.hpp:77] Creating layer Scale35
I1101 13:43:41.968447  4164 net.cpp:122] Setting up Scale35
I1101 13:43:41.968452  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.968461  4164 net.cpp:137] Memory required for data: 627918000
I1101 13:43:41.968464  4164 layer_factory.hpp:77] Creating layer ReLU32
I1101 13:43:41.968467  4164 net.cpp:84] Creating Layer ReLU32
I1101 13:43:41.968469  4164 net.cpp:406] ReLU32 <- Convolution35
I1101 13:43:41.968473  4164 net.cpp:367] ReLU32 -> Convolution35 (in-place)
I1101 13:43:41.968605  4164 net.cpp:122] Setting up ReLU32
I1101 13:43:41.968610  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.968611  4164 net.cpp:137] Memory required for data: 628737200
I1101 13:43:41.968613  4164 layer_factory.hpp:77] Creating layer Convolution36
I1101 13:43:41.968619  4164 net.cpp:84] Creating Layer Convolution36
I1101 13:43:41.968622  4164 net.cpp:406] Convolution36 <- Convolution35
I1101 13:43:41.968626  4164 net.cpp:380] Convolution36 -> Convolution36
I1101 13:43:41.970602  4164 net.cpp:122] Setting up Convolution36
I1101 13:43:41.970610  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.970613  4164 net.cpp:137] Memory required for data: 629556400
I1101 13:43:41.970631  4164 layer_factory.hpp:77] Creating layer BatchNorm36
I1101 13:43:41.970635  4164 net.cpp:84] Creating Layer BatchNorm36
I1101 13:43:41.970638  4164 net.cpp:406] BatchNorm36 <- Convolution36
I1101 13:43:41.970643  4164 net.cpp:367] BatchNorm36 -> Convolution36 (in-place)
I1101 13:43:41.970844  4164 net.cpp:122] Setting up BatchNorm36
I1101 13:43:41.970849  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.970865  4164 net.cpp:137] Memory required for data: 630375600
I1101 13:43:41.970870  4164 layer_factory.hpp:77] Creating layer Scale36
I1101 13:43:41.970872  4164 net.cpp:84] Creating Layer Scale36
I1101 13:43:41.970875  4164 net.cpp:406] Scale36 <- Convolution36
I1101 13:43:41.970877  4164 net.cpp:367] Scale36 -> Convolution36 (in-place)
I1101 13:43:41.970909  4164 layer_factory.hpp:77] Creating layer Scale36
I1101 13:43:41.971035  4164 net.cpp:122] Setting up Scale36
I1101 13:43:41.971052  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.971053  4164 net.cpp:137] Memory required for data: 631194800
I1101 13:43:41.971056  4164 layer_factory.hpp:77] Creating layer Eltwise16
I1101 13:43:41.971060  4164 net.cpp:84] Creating Layer Eltwise16
I1101 13:43:41.971076  4164 net.cpp:406] Eltwise16 <- Convolution36
I1101 13:43:41.971079  4164 net.cpp:406] Eltwise16 <- Eltwise15_ReLU31_0_split_1
I1101 13:43:41.971082  4164 net.cpp:380] Eltwise16 -> Eltwise16
I1101 13:43:41.971101  4164 net.cpp:122] Setting up Eltwise16
I1101 13:43:41.971105  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.971107  4164 net.cpp:137] Memory required for data: 632014000
I1101 13:43:41.971108  4164 layer_factory.hpp:77] Creating layer ReLU33
I1101 13:43:41.971112  4164 net.cpp:84] Creating Layer ReLU33
I1101 13:43:41.971113  4164 net.cpp:406] ReLU33 <- Eltwise16
I1101 13:43:41.971117  4164 net.cpp:367] ReLU33 -> Eltwise16 (in-place)
I1101 13:43:41.971508  4164 net.cpp:122] Setting up ReLU33
I1101 13:43:41.971515  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.971530  4164 net.cpp:137] Memory required for data: 632833200
I1101 13:43:41.971532  4164 layer_factory.hpp:77] Creating layer Eltwise16_ReLU33_0_split
I1101 13:43:41.971535  4164 net.cpp:84] Creating Layer Eltwise16_ReLU33_0_split
I1101 13:43:41.971537  4164 net.cpp:406] Eltwise16_ReLU33_0_split <- Eltwise16
I1101 13:43:41.971542  4164 net.cpp:380] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_0
I1101 13:43:41.971547  4164 net.cpp:380] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_1
I1101 13:43:41.971582  4164 net.cpp:122] Setting up Eltwise16_ReLU33_0_split
I1101 13:43:41.971586  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.971588  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.971590  4164 net.cpp:137] Memory required for data: 634471600
I1101 13:43:41.971591  4164 layer_factory.hpp:77] Creating layer Convolution37
I1101 13:43:41.971597  4164 net.cpp:84] Creating Layer Convolution37
I1101 13:43:41.971599  4164 net.cpp:406] Convolution37 <- Eltwise16_ReLU33_0_split_0
I1101 13:43:41.971624  4164 net.cpp:380] Convolution37 -> Convolution37
I1101 13:43:41.974108  4164 net.cpp:122] Setting up Convolution37
I1101 13:43:41.974117  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.974120  4164 net.cpp:137] Memory required for data: 635290800
I1101 13:43:41.974124  4164 layer_factory.hpp:77] Creating layer BatchNorm37
I1101 13:43:41.974128  4164 net.cpp:84] Creating Layer BatchNorm37
I1101 13:43:41.974130  4164 net.cpp:406] BatchNorm37 <- Convolution37
I1101 13:43:41.974134  4164 net.cpp:367] BatchNorm37 -> Convolution37 (in-place)
I1101 13:43:41.974314  4164 net.cpp:122] Setting up BatchNorm37
I1101 13:43:41.974319  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.974321  4164 net.cpp:137] Memory required for data: 636110000
I1101 13:43:41.974339  4164 layer_factory.hpp:77] Creating layer Scale37
I1101 13:43:41.974344  4164 net.cpp:84] Creating Layer Scale37
I1101 13:43:41.974346  4164 net.cpp:406] Scale37 <- Convolution37
I1101 13:43:41.974349  4164 net.cpp:367] Scale37 -> Convolution37 (in-place)
I1101 13:43:41.974381  4164 layer_factory.hpp:77] Creating layer Scale37
I1101 13:43:41.974519  4164 net.cpp:122] Setting up Scale37
I1101 13:43:41.974524  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.974526  4164 net.cpp:137] Memory required for data: 636929200
I1101 13:43:41.974529  4164 layer_factory.hpp:77] Creating layer ReLU34
I1101 13:43:41.974532  4164 net.cpp:84] Creating Layer ReLU34
I1101 13:43:41.974535  4164 net.cpp:406] ReLU34 <- Convolution37
I1101 13:43:41.974539  4164 net.cpp:367] ReLU34 -> Convolution37 (in-place)
I1101 13:43:41.974668  4164 net.cpp:122] Setting up ReLU34
I1101 13:43:41.974673  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.974676  4164 net.cpp:137] Memory required for data: 637748400
I1101 13:43:41.974678  4164 layer_factory.hpp:77] Creating layer Convolution38
I1101 13:43:41.974683  4164 net.cpp:84] Creating Layer Convolution38
I1101 13:43:41.974685  4164 net.cpp:406] Convolution38 <- Convolution37
I1101 13:43:41.974690  4164 net.cpp:380] Convolution38 -> Convolution38
I1101 13:43:41.976611  4164 net.cpp:122] Setting up Convolution38
I1101 13:43:41.976619  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.976621  4164 net.cpp:137] Memory required for data: 638567600
I1101 13:43:41.976625  4164 layer_factory.hpp:77] Creating layer BatchNorm38
I1101 13:43:41.976630  4164 net.cpp:84] Creating Layer BatchNorm38
I1101 13:43:41.976632  4164 net.cpp:406] BatchNorm38 <- Convolution38
I1101 13:43:41.976636  4164 net.cpp:367] BatchNorm38 -> Convolution38 (in-place)
I1101 13:43:41.976816  4164 net.cpp:122] Setting up BatchNorm38
I1101 13:43:41.976820  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.976822  4164 net.cpp:137] Memory required for data: 639386800
I1101 13:43:41.976826  4164 layer_factory.hpp:77] Creating layer Scale38
I1101 13:43:41.976830  4164 net.cpp:84] Creating Layer Scale38
I1101 13:43:41.976832  4164 net.cpp:406] Scale38 <- Convolution38
I1101 13:43:41.976835  4164 net.cpp:367] Scale38 -> Convolution38 (in-place)
I1101 13:43:41.976867  4164 layer_factory.hpp:77] Creating layer Scale38
I1101 13:43:41.976964  4164 net.cpp:122] Setting up Scale38
I1101 13:43:41.976969  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.976971  4164 net.cpp:137] Memory required for data: 640206000
I1101 13:43:41.976974  4164 layer_factory.hpp:77] Creating layer Eltwise17
I1101 13:43:41.976977  4164 net.cpp:84] Creating Layer Eltwise17
I1101 13:43:41.976979  4164 net.cpp:406] Eltwise17 <- Convolution38
I1101 13:43:41.976982  4164 net.cpp:406] Eltwise17 <- Eltwise16_ReLU33_0_split_1
I1101 13:43:41.976985  4164 net.cpp:380] Eltwise17 -> Eltwise17
I1101 13:43:41.977005  4164 net.cpp:122] Setting up Eltwise17
I1101 13:43:41.977008  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.977010  4164 net.cpp:137] Memory required for data: 641025200
I1101 13:43:41.977011  4164 layer_factory.hpp:77] Creating layer ReLU35
I1101 13:43:41.977021  4164 net.cpp:84] Creating Layer ReLU35
I1101 13:43:41.977025  4164 net.cpp:406] ReLU35 <- Eltwise17
I1101 13:43:41.977028  4164 net.cpp:367] ReLU35 -> Eltwise17 (in-place)
I1101 13:43:41.977156  4164 net.cpp:122] Setting up ReLU35
I1101 13:43:41.977162  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.977164  4164 net.cpp:137] Memory required for data: 641844400
I1101 13:43:41.977166  4164 layer_factory.hpp:77] Creating layer Eltwise17_ReLU35_0_split
I1101 13:43:41.977169  4164 net.cpp:84] Creating Layer Eltwise17_ReLU35_0_split
I1101 13:43:41.977171  4164 net.cpp:406] Eltwise17_ReLU35_0_split <- Eltwise17
I1101 13:43:41.977175  4164 net.cpp:380] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_0
I1101 13:43:41.977180  4164 net.cpp:380] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_1
I1101 13:43:41.977214  4164 net.cpp:122] Setting up Eltwise17_ReLU35_0_split
I1101 13:43:41.977218  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.977221  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.977222  4164 net.cpp:137] Memory required for data: 643482800
I1101 13:43:41.977223  4164 layer_factory.hpp:77] Creating layer Convolution39
I1101 13:43:41.977228  4164 net.cpp:84] Creating Layer Convolution39
I1101 13:43:41.977231  4164 net.cpp:406] Convolution39 <- Eltwise17_ReLU35_0_split_0
I1101 13:43:41.977236  4164 net.cpp:380] Convolution39 -> Convolution39
I1101 13:43:41.979161  4164 net.cpp:122] Setting up Convolution39
I1101 13:43:41.979171  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.979173  4164 net.cpp:137] Memory required for data: 644302000
I1101 13:43:41.979177  4164 layer_factory.hpp:77] Creating layer BatchNorm39
I1101 13:43:41.979180  4164 net.cpp:84] Creating Layer BatchNorm39
I1101 13:43:41.979183  4164 net.cpp:406] BatchNorm39 <- Convolution39
I1101 13:43:41.979187  4164 net.cpp:367] BatchNorm39 -> Convolution39 (in-place)
I1101 13:43:41.979362  4164 net.cpp:122] Setting up BatchNorm39
I1101 13:43:41.979367  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.979368  4164 net.cpp:137] Memory required for data: 645121200
I1101 13:43:41.979372  4164 layer_factory.hpp:77] Creating layer Scale39
I1101 13:43:41.979377  4164 net.cpp:84] Creating Layer Scale39
I1101 13:43:41.979379  4164 net.cpp:406] Scale39 <- Convolution39
I1101 13:43:41.979382  4164 net.cpp:367] Scale39 -> Convolution39 (in-place)
I1101 13:43:41.979414  4164 layer_factory.hpp:77] Creating layer Scale39
I1101 13:43:41.979512  4164 net.cpp:122] Setting up Scale39
I1101 13:43:41.979516  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.979518  4164 net.cpp:137] Memory required for data: 645940400
I1101 13:43:41.979521  4164 layer_factory.hpp:77] Creating layer ReLU36
I1101 13:43:41.979524  4164 net.cpp:84] Creating Layer ReLU36
I1101 13:43:41.979526  4164 net.cpp:406] ReLU36 <- Convolution39
I1101 13:43:41.979529  4164 net.cpp:367] ReLU36 -> Convolution39 (in-place)
I1101 13:43:41.979656  4164 net.cpp:122] Setting up ReLU36
I1101 13:43:41.979661  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.979663  4164 net.cpp:137] Memory required for data: 646759600
I1101 13:43:41.979665  4164 layer_factory.hpp:77] Creating layer Convolution40
I1101 13:43:41.979671  4164 net.cpp:84] Creating Layer Convolution40
I1101 13:43:41.979672  4164 net.cpp:406] Convolution40 <- Convolution39
I1101 13:43:41.979676  4164 net.cpp:380] Convolution40 -> Convolution40
I1101 13:43:41.982110  4164 net.cpp:122] Setting up Convolution40
I1101 13:43:41.982120  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.982121  4164 net.cpp:137] Memory required for data: 647578800
I1101 13:43:41.982125  4164 layer_factory.hpp:77] Creating layer BatchNorm40
I1101 13:43:41.982131  4164 net.cpp:84] Creating Layer BatchNorm40
I1101 13:43:41.982133  4164 net.cpp:406] BatchNorm40 <- Convolution40
I1101 13:43:41.982136  4164 net.cpp:367] BatchNorm40 -> Convolution40 (in-place)
I1101 13:43:41.982316  4164 net.cpp:122] Setting up BatchNorm40
I1101 13:43:41.982327  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.982329  4164 net.cpp:137] Memory required for data: 648398000
I1101 13:43:41.982334  4164 layer_factory.hpp:77] Creating layer Scale40
I1101 13:43:41.982337  4164 net.cpp:84] Creating Layer Scale40
I1101 13:43:41.982340  4164 net.cpp:406] Scale40 <- Convolution40
I1101 13:43:41.982343  4164 net.cpp:367] Scale40 -> Convolution40 (in-place)
I1101 13:43:41.982378  4164 layer_factory.hpp:77] Creating layer Scale40
I1101 13:43:41.982511  4164 net.cpp:122] Setting up Scale40
I1101 13:43:41.982517  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.982518  4164 net.cpp:137] Memory required for data: 649217200
I1101 13:43:41.982522  4164 layer_factory.hpp:77] Creating layer Eltwise18
I1101 13:43:41.982524  4164 net.cpp:84] Creating Layer Eltwise18
I1101 13:43:41.982527  4164 net.cpp:406] Eltwise18 <- Convolution40
I1101 13:43:41.982529  4164 net.cpp:406] Eltwise18 <- Eltwise17_ReLU35_0_split_1
I1101 13:43:41.982532  4164 net.cpp:380] Eltwise18 -> Eltwise18
I1101 13:43:41.982553  4164 net.cpp:122] Setting up Eltwise18
I1101 13:43:41.982558  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.982559  4164 net.cpp:137] Memory required for data: 650036400
I1101 13:43:41.982561  4164 layer_factory.hpp:77] Creating layer ReLU37
I1101 13:43:41.982564  4164 net.cpp:84] Creating Layer ReLU37
I1101 13:43:41.982566  4164 net.cpp:406] ReLU37 <- Eltwise18
I1101 13:43:41.982568  4164 net.cpp:367] ReLU37 -> Eltwise18 (in-place)
I1101 13:43:41.982723  4164 net.cpp:122] Setting up ReLU37
I1101 13:43:41.982728  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.982730  4164 net.cpp:137] Memory required for data: 650855600
I1101 13:43:41.982733  4164 layer_factory.hpp:77] Creating layer Eltwise18_ReLU37_0_split
I1101 13:43:41.982735  4164 net.cpp:84] Creating Layer Eltwise18_ReLU37_0_split
I1101 13:43:41.982738  4164 net.cpp:406] Eltwise18_ReLU37_0_split <- Eltwise18
I1101 13:43:41.982741  4164 net.cpp:380] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_0
I1101 13:43:41.982746  4164 net.cpp:380] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_1
I1101 13:43:41.982811  4164 net.cpp:122] Setting up Eltwise18_ReLU37_0_split
I1101 13:43:41.982815  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.982817  4164 net.cpp:129] Top shape: 100 128 4 4 (204800)
I1101 13:43:41.982834  4164 net.cpp:137] Memory required for data: 652494000
I1101 13:43:41.982836  4164 layer_factory.hpp:77] Creating layer Convolution41
I1101 13:43:41.982841  4164 net.cpp:84] Creating Layer Convolution41
I1101 13:43:41.982857  4164 net.cpp:406] Convolution41 <- Eltwise18_ReLU37_0_split_0
I1101 13:43:41.982862  4164 net.cpp:380] Convolution41 -> Convolution41
I1101 13:43:41.986143  4164 net.cpp:122] Setting up Convolution41
I1101 13:43:41.986157  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:41.986160  4164 net.cpp:137] Memory required for data: 652903600
I1101 13:43:41.986165  4164 layer_factory.hpp:77] Creating layer BatchNorm41
I1101 13:43:41.986171  4164 net.cpp:84] Creating Layer BatchNorm41
I1101 13:43:41.986173  4164 net.cpp:406] BatchNorm41 <- Convolution41
I1101 13:43:41.986177  4164 net.cpp:367] BatchNorm41 -> Convolution41 (in-place)
I1101 13:43:41.986371  4164 net.cpp:122] Setting up BatchNorm41
I1101 13:43:41.986377  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:41.986378  4164 net.cpp:137] Memory required for data: 653313200
I1101 13:43:41.986383  4164 layer_factory.hpp:77] Creating layer Scale41
I1101 13:43:41.986387  4164 net.cpp:84] Creating Layer Scale41
I1101 13:43:41.986390  4164 net.cpp:406] Scale41 <- Convolution41
I1101 13:43:41.986394  4164 net.cpp:367] Scale41 -> Convolution41 (in-place)
I1101 13:43:41.986470  4164 layer_factory.hpp:77] Creating layer Scale41
I1101 13:43:41.986588  4164 net.cpp:122] Setting up Scale41
I1101 13:43:41.986593  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:41.986595  4164 net.cpp:137] Memory required for data: 653722800
I1101 13:43:41.986608  4164 layer_factory.hpp:77] Creating layer ReLU38
I1101 13:43:41.986613  4164 net.cpp:84] Creating Layer ReLU38
I1101 13:43:41.986615  4164 net.cpp:406] ReLU38 <- Convolution41
I1101 13:43:41.986618  4164 net.cpp:367] ReLU38 -> Convolution41 (in-place)
I1101 13:43:41.986747  4164 net.cpp:122] Setting up ReLU38
I1101 13:43:41.986752  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:41.986754  4164 net.cpp:137] Memory required for data: 654132400
I1101 13:43:41.986755  4164 layer_factory.hpp:77] Creating layer Convolution42
I1101 13:43:41.986763  4164 net.cpp:84] Creating Layer Convolution42
I1101 13:43:41.986765  4164 net.cpp:406] Convolution42 <- Convolution41
I1101 13:43:41.986769  4164 net.cpp:380] Convolution42 -> Convolution42
I1101 13:43:41.992753  4164 net.cpp:122] Setting up Convolution42
I1101 13:43:41.992769  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:41.992770  4164 net.cpp:137] Memory required for data: 654542000
I1101 13:43:41.992776  4164 layer_factory.hpp:77] Creating layer BatchNorm42
I1101 13:43:41.992799  4164 net.cpp:84] Creating Layer BatchNorm42
I1101 13:43:41.992802  4164 net.cpp:406] BatchNorm42 <- Convolution42
I1101 13:43:41.992806  4164 net.cpp:367] BatchNorm42 -> Convolution42 (in-place)
I1101 13:43:41.992938  4164 net.cpp:122] Setting up BatchNorm42
I1101 13:43:41.992943  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:41.992944  4164 net.cpp:137] Memory required for data: 654951600
I1101 13:43:41.992949  4164 layer_factory.hpp:77] Creating layer Scale42
I1101 13:43:41.992952  4164 net.cpp:84] Creating Layer Scale42
I1101 13:43:41.992954  4164 net.cpp:406] Scale42 <- Convolution42
I1101 13:43:41.992957  4164 net.cpp:367] Scale42 -> Convolution42 (in-place)
I1101 13:43:41.992997  4164 layer_factory.hpp:77] Creating layer Scale42
I1101 13:43:41.993108  4164 net.cpp:122] Setting up Scale42
I1101 13:43:41.993111  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:41.993113  4164 net.cpp:137] Memory required for data: 655361200
I1101 13:43:41.993115  4164 layer_factory.hpp:77] Creating layer Convolution43
I1101 13:43:41.993121  4164 net.cpp:84] Creating Layer Convolution43
I1101 13:43:41.993124  4164 net.cpp:406] Convolution43 <- Eltwise18_ReLU37_0_split_1
I1101 13:43:41.993129  4164 net.cpp:380] Convolution43 -> Convolution43
I1101 13:43:41.994127  4164 net.cpp:122] Setting up Convolution43
I1101 13:43:41.994134  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:41.994137  4164 net.cpp:137] Memory required for data: 655770800
I1101 13:43:41.994140  4164 layer_factory.hpp:77] Creating layer BatchNorm43
I1101 13:43:41.994144  4164 net.cpp:84] Creating Layer BatchNorm43
I1101 13:43:41.994146  4164 net.cpp:406] BatchNorm43 <- Convolution43
I1101 13:43:41.994150  4164 net.cpp:367] BatchNorm43 -> Convolution43 (in-place)
I1101 13:43:41.994290  4164 net.cpp:122] Setting up BatchNorm43
I1101 13:43:41.994294  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:41.994297  4164 net.cpp:137] Memory required for data: 656180400
I1101 13:43:41.994313  4164 layer_factory.hpp:77] Creating layer Scale43
I1101 13:43:41.994316  4164 net.cpp:84] Creating Layer Scale43
I1101 13:43:41.994318  4164 net.cpp:406] Scale43 <- Convolution43
I1101 13:43:41.994321  4164 net.cpp:367] Scale43 -> Convolution43 (in-place)
I1101 13:43:41.994346  4164 layer_factory.hpp:77] Creating layer Scale43
I1101 13:43:41.994411  4164 net.cpp:122] Setting up Scale43
I1101 13:43:41.994426  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:41.994428  4164 net.cpp:137] Memory required for data: 656590000
I1101 13:43:41.994434  4164 layer_factory.hpp:77] Creating layer Eltwise19
I1101 13:43:41.994438  4164 net.cpp:84] Creating Layer Eltwise19
I1101 13:43:41.994453  4164 net.cpp:406] Eltwise19 <- Convolution42
I1101 13:43:41.994455  4164 net.cpp:406] Eltwise19 <- Convolution43
I1101 13:43:41.994459  4164 net.cpp:380] Eltwise19 -> Eltwise19
I1101 13:43:41.994475  4164 net.cpp:122] Setting up Eltwise19
I1101 13:43:41.994479  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:41.994488  4164 net.cpp:137] Memory required for data: 656999600
I1101 13:43:41.994491  4164 layer_factory.hpp:77] Creating layer ReLU39
I1101 13:43:41.994494  4164 net.cpp:84] Creating Layer ReLU39
I1101 13:43:41.994496  4164 net.cpp:406] ReLU39 <- Eltwise19
I1101 13:43:41.994498  4164 net.cpp:367] ReLU39 -> Eltwise19 (in-place)
I1101 13:43:41.994832  4164 net.cpp:122] Setting up ReLU39
I1101 13:43:41.994839  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:41.994843  4164 net.cpp:137] Memory required for data: 657409200
I1101 13:43:41.994844  4164 layer_factory.hpp:77] Creating layer Eltwise19_ReLU39_0_split
I1101 13:43:41.994848  4164 net.cpp:84] Creating Layer Eltwise19_ReLU39_0_split
I1101 13:43:41.994850  4164 net.cpp:406] Eltwise19_ReLU39_0_split <- Eltwise19
I1101 13:43:41.994853  4164 net.cpp:380] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_0
I1101 13:43:41.994858  4164 net.cpp:380] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_1
I1101 13:43:41.994899  4164 net.cpp:122] Setting up Eltwise19_ReLU39_0_split
I1101 13:43:41.994904  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:41.994906  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:41.994907  4164 net.cpp:137] Memory required for data: 658228400
I1101 13:43:41.994922  4164 layer_factory.hpp:77] Creating layer Convolution44
I1101 13:43:41.994928  4164 net.cpp:84] Creating Layer Convolution44
I1101 13:43:41.994946  4164 net.cpp:406] Convolution44 <- Eltwise19_ReLU39_0_split_0
I1101 13:43:41.994951  4164 net.cpp:380] Convolution44 -> Convolution44
I1101 13:43:41.999986  4164 net.cpp:122] Setting up Convolution44
I1101 13:43:41.999994  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:41.999996  4164 net.cpp:137] Memory required for data: 658638000
I1101 13:43:42.000000  4164 layer_factory.hpp:77] Creating layer BatchNorm44
I1101 13:43:42.000006  4164 net.cpp:84] Creating Layer BatchNorm44
I1101 13:43:42.000010  4164 net.cpp:406] BatchNorm44 <- Convolution44
I1101 13:43:42.000013  4164 net.cpp:367] BatchNorm44 -> Convolution44 (in-place)
I1101 13:43:42.000162  4164 net.cpp:122] Setting up BatchNorm44
I1101 13:43:42.000169  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.000169  4164 net.cpp:137] Memory required for data: 659047600
I1101 13:43:42.000174  4164 layer_factory.hpp:77] Creating layer Scale44
I1101 13:43:42.000176  4164 net.cpp:84] Creating Layer Scale44
I1101 13:43:42.000180  4164 net.cpp:406] Scale44 <- Convolution44
I1101 13:43:42.000182  4164 net.cpp:367] Scale44 -> Convolution44 (in-place)
I1101 13:43:42.000222  4164 layer_factory.hpp:77] Creating layer Scale44
I1101 13:43:42.000299  4164 net.cpp:122] Setting up Scale44
I1101 13:43:42.000304  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.000305  4164 net.cpp:137] Memory required for data: 659457200
I1101 13:43:42.000309  4164 layer_factory.hpp:77] Creating layer ReLU40
I1101 13:43:42.000311  4164 net.cpp:84] Creating Layer ReLU40
I1101 13:43:42.000314  4164 net.cpp:406] ReLU40 <- Convolution44
I1101 13:43:42.000318  4164 net.cpp:367] ReLU40 -> Convolution44 (in-place)
I1101 13:43:42.000686  4164 net.cpp:122] Setting up ReLU40
I1101 13:43:42.000694  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.000697  4164 net.cpp:137] Memory required for data: 659866800
I1101 13:43:42.000699  4164 layer_factory.hpp:77] Creating layer Convolution45
I1101 13:43:42.000704  4164 net.cpp:84] Creating Layer Convolution45
I1101 13:43:42.000706  4164 net.cpp:406] Convolution45 <- Convolution44
I1101 13:43:42.000711  4164 net.cpp:380] Convolution45 -> Convolution45
I1101 13:43:42.006428  4164 net.cpp:122] Setting up Convolution45
I1101 13:43:42.006443  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.006444  4164 net.cpp:137] Memory required for data: 660276400
I1101 13:43:42.006450  4164 layer_factory.hpp:77] Creating layer BatchNorm45
I1101 13:43:42.006458  4164 net.cpp:84] Creating Layer BatchNorm45
I1101 13:43:42.006461  4164 net.cpp:406] BatchNorm45 <- Convolution45
I1101 13:43:42.006479  4164 net.cpp:367] BatchNorm45 -> Convolution45 (in-place)
I1101 13:43:42.006638  4164 net.cpp:122] Setting up BatchNorm45
I1101 13:43:42.006641  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.006644  4164 net.cpp:137] Memory required for data: 660686000
I1101 13:43:42.006647  4164 layer_factory.hpp:77] Creating layer Scale45
I1101 13:43:42.006651  4164 net.cpp:84] Creating Layer Scale45
I1101 13:43:42.006654  4164 net.cpp:406] Scale45 <- Convolution45
I1101 13:43:42.006661  4164 net.cpp:367] Scale45 -> Convolution45 (in-place)
I1101 13:43:42.006688  4164 layer_factory.hpp:77] Creating layer Scale45
I1101 13:43:42.006819  4164 net.cpp:122] Setting up Scale45
I1101 13:43:42.006822  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.006824  4164 net.cpp:137] Memory required for data: 661095600
I1101 13:43:42.006827  4164 layer_factory.hpp:77] Creating layer Eltwise20
I1101 13:43:42.006831  4164 net.cpp:84] Creating Layer Eltwise20
I1101 13:43:42.006834  4164 net.cpp:406] Eltwise20 <- Convolution45
I1101 13:43:42.006836  4164 net.cpp:406] Eltwise20 <- Eltwise19_ReLU39_0_split_1
I1101 13:43:42.006839  4164 net.cpp:380] Eltwise20 -> Eltwise20
I1101 13:43:42.006855  4164 net.cpp:122] Setting up Eltwise20
I1101 13:43:42.006858  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.006860  4164 net.cpp:137] Memory required for data: 661505200
I1101 13:43:42.006861  4164 layer_factory.hpp:77] Creating layer ReLU41
I1101 13:43:42.006865  4164 net.cpp:84] Creating Layer ReLU41
I1101 13:43:42.006867  4164 net.cpp:406] ReLU41 <- Eltwise20
I1101 13:43:42.006870  4164 net.cpp:367] ReLU41 -> Eltwise20 (in-place)
I1101 13:43:42.007006  4164 net.cpp:122] Setting up ReLU41
I1101 13:43:42.007012  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.007014  4164 net.cpp:137] Memory required for data: 661914800
I1101 13:43:42.007015  4164 layer_factory.hpp:77] Creating layer Eltwise20_ReLU41_0_split
I1101 13:43:42.007019  4164 net.cpp:84] Creating Layer Eltwise20_ReLU41_0_split
I1101 13:43:42.007021  4164 net.cpp:406] Eltwise20_ReLU41_0_split <- Eltwise20
I1101 13:43:42.007025  4164 net.cpp:380] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_0
I1101 13:43:42.007030  4164 net.cpp:380] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_1
I1101 13:43:42.007052  4164 net.cpp:122] Setting up Eltwise20_ReLU41_0_split
I1101 13:43:42.007056  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.007058  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.007061  4164 net.cpp:137] Memory required for data: 662734000
I1101 13:43:42.007062  4164 layer_factory.hpp:77] Creating layer Convolution46
I1101 13:43:42.007068  4164 net.cpp:84] Creating Layer Convolution46
I1101 13:43:42.007071  4164 net.cpp:406] Convolution46 <- Eltwise20_ReLU41_0_split_0
I1101 13:43:42.007076  4164 net.cpp:380] Convolution46 -> Convolution46
I1101 13:43:42.012328  4164 net.cpp:122] Setting up Convolution46
I1101 13:43:42.012337  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.012339  4164 net.cpp:137] Memory required for data: 663143600
I1101 13:43:42.012343  4164 layer_factory.hpp:77] Creating layer BatchNorm46
I1101 13:43:42.012349  4164 net.cpp:84] Creating Layer BatchNorm46
I1101 13:43:42.012351  4164 net.cpp:406] BatchNorm46 <- Convolution46
I1101 13:43:42.012354  4164 net.cpp:367] BatchNorm46 -> Convolution46 (in-place)
I1101 13:43:42.012473  4164 net.cpp:122] Setting up BatchNorm46
I1101 13:43:42.012478  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.012480  4164 net.cpp:137] Memory required for data: 663553200
I1101 13:43:42.012483  4164 layer_factory.hpp:77] Creating layer Scale46
I1101 13:43:42.012487  4164 net.cpp:84] Creating Layer Scale46
I1101 13:43:42.012490  4164 net.cpp:406] Scale46 <- Convolution46
I1101 13:43:42.012492  4164 net.cpp:367] Scale46 -> Convolution46 (in-place)
I1101 13:43:42.012516  4164 layer_factory.hpp:77] Creating layer Scale46
I1101 13:43:42.012583  4164 net.cpp:122] Setting up Scale46
I1101 13:43:42.012594  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.012595  4164 net.cpp:137] Memory required for data: 663962800
I1101 13:43:42.012599  4164 layer_factory.hpp:77] Creating layer ReLU42
I1101 13:43:42.012603  4164 net.cpp:84] Creating Layer ReLU42
I1101 13:43:42.012604  4164 net.cpp:406] ReLU42 <- Convolution46
I1101 13:43:42.012606  4164 net.cpp:367] ReLU42 -> Convolution46 (in-place)
I1101 13:43:42.012768  4164 net.cpp:122] Setting up ReLU42
I1101 13:43:42.012773  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.012774  4164 net.cpp:137] Memory required for data: 664372400
I1101 13:43:42.012776  4164 layer_factory.hpp:77] Creating layer Convolution47
I1101 13:43:42.012783  4164 net.cpp:84] Creating Layer Convolution47
I1101 13:43:42.012785  4164 net.cpp:406] Convolution47 <- Convolution46
I1101 13:43:42.012789  4164 net.cpp:380] Convolution47 -> Convolution47
I1101 13:43:42.018046  4164 net.cpp:122] Setting up Convolution47
I1101 13:43:42.018056  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.018059  4164 net.cpp:137] Memory required for data: 664782000
I1101 13:43:42.018064  4164 layer_factory.hpp:77] Creating layer BatchNorm47
I1101 13:43:42.018067  4164 net.cpp:84] Creating Layer BatchNorm47
I1101 13:43:42.018070  4164 net.cpp:406] BatchNorm47 <- Convolution47
I1101 13:43:42.018074  4164 net.cpp:367] BatchNorm47 -> Convolution47 (in-place)
I1101 13:43:42.018232  4164 net.cpp:122] Setting up BatchNorm47
I1101 13:43:42.018236  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.018239  4164 net.cpp:137] Memory required for data: 665191600
I1101 13:43:42.018242  4164 layer_factory.hpp:77] Creating layer Scale47
I1101 13:43:42.018246  4164 net.cpp:84] Creating Layer Scale47
I1101 13:43:42.018249  4164 net.cpp:406] Scale47 <- Convolution47
I1101 13:43:42.018251  4164 net.cpp:367] Scale47 -> Convolution47 (in-place)
I1101 13:43:42.018293  4164 layer_factory.hpp:77] Creating layer Scale47
I1101 13:43:42.018374  4164 net.cpp:122] Setting up Scale47
I1101 13:43:42.018378  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.018380  4164 net.cpp:137] Memory required for data: 665601200
I1101 13:43:42.018383  4164 layer_factory.hpp:77] Creating layer Eltwise21
I1101 13:43:42.018402  4164 net.cpp:84] Creating Layer Eltwise21
I1101 13:43:42.018404  4164 net.cpp:406] Eltwise21 <- Convolution47
I1101 13:43:42.018409  4164 net.cpp:406] Eltwise21 <- Eltwise20_ReLU41_0_split_1
I1101 13:43:42.018412  4164 net.cpp:380] Eltwise21 -> Eltwise21
I1101 13:43:42.018436  4164 net.cpp:122] Setting up Eltwise21
I1101 13:43:42.018440  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.018442  4164 net.cpp:137] Memory required for data: 666010800
I1101 13:43:42.018445  4164 layer_factory.hpp:77] Creating layer ReLU43
I1101 13:43:42.018448  4164 net.cpp:84] Creating Layer ReLU43
I1101 13:43:42.018450  4164 net.cpp:406] ReLU43 <- Eltwise21
I1101 13:43:42.018465  4164 net.cpp:367] ReLU43 -> Eltwise21 (in-place)
I1101 13:43:42.018623  4164 net.cpp:122] Setting up ReLU43
I1101 13:43:42.018628  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.018630  4164 net.cpp:137] Memory required for data: 666420400
I1101 13:43:42.018632  4164 layer_factory.hpp:77] Creating layer Eltwise21_ReLU43_0_split
I1101 13:43:42.018636  4164 net.cpp:84] Creating Layer Eltwise21_ReLU43_0_split
I1101 13:43:42.018638  4164 net.cpp:406] Eltwise21_ReLU43_0_split <- Eltwise21
I1101 13:43:42.018641  4164 net.cpp:380] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_0
I1101 13:43:42.018646  4164 net.cpp:380] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_1
I1101 13:43:42.018683  4164 net.cpp:122] Setting up Eltwise21_ReLU43_0_split
I1101 13:43:42.018687  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.018689  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.018690  4164 net.cpp:137] Memory required for data: 667239600
I1101 13:43:42.018692  4164 layer_factory.hpp:77] Creating layer Convolution48
I1101 13:43:42.018698  4164 net.cpp:84] Creating Layer Convolution48
I1101 13:43:42.018720  4164 net.cpp:406] Convolution48 <- Eltwise21_ReLU43_0_split_0
I1101 13:43:42.018724  4164 net.cpp:380] Convolution48 -> Convolution48
I1101 13:43:42.024508  4164 net.cpp:122] Setting up Convolution48
I1101 13:43:42.024525  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.024528  4164 net.cpp:137] Memory required for data: 667649200
I1101 13:43:42.024533  4164 layer_factory.hpp:77] Creating layer BatchNorm48
I1101 13:43:42.024541  4164 net.cpp:84] Creating Layer BatchNorm48
I1101 13:43:42.024544  4164 net.cpp:406] BatchNorm48 <- Convolution48
I1101 13:43:42.024549  4164 net.cpp:367] BatchNorm48 -> Convolution48 (in-place)
I1101 13:43:42.024713  4164 net.cpp:122] Setting up BatchNorm48
I1101 13:43:42.024718  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.024719  4164 net.cpp:137] Memory required for data: 668058800
I1101 13:43:42.024724  4164 layer_factory.hpp:77] Creating layer Scale48
I1101 13:43:42.024729  4164 net.cpp:84] Creating Layer Scale48
I1101 13:43:42.024730  4164 net.cpp:406] Scale48 <- Convolution48
I1101 13:43:42.024734  4164 net.cpp:367] Scale48 -> Convolution48 (in-place)
I1101 13:43:42.024760  4164 layer_factory.hpp:77] Creating layer Scale48
I1101 13:43:42.024853  4164 net.cpp:122] Setting up Scale48
I1101 13:43:42.024857  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.024859  4164 net.cpp:137] Memory required for data: 668468400
I1101 13:43:42.024874  4164 layer_factory.hpp:77] Creating layer ReLU44
I1101 13:43:42.024878  4164 net.cpp:84] Creating Layer ReLU44
I1101 13:43:42.024879  4164 net.cpp:406] ReLU44 <- Convolution48
I1101 13:43:42.024883  4164 net.cpp:367] ReLU44 -> Convolution48 (in-place)
I1101 13:43:42.025223  4164 net.cpp:122] Setting up ReLU44
I1101 13:43:42.025231  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.025233  4164 net.cpp:137] Memory required for data: 668878000
I1101 13:43:42.025235  4164 layer_factory.hpp:77] Creating layer Convolution49
I1101 13:43:42.025241  4164 net.cpp:84] Creating Layer Convolution49
I1101 13:43:42.025243  4164 net.cpp:406] Convolution49 <- Convolution48
I1101 13:43:42.025249  4164 net.cpp:380] Convolution49 -> Convolution49
I1101 13:43:42.030503  4164 net.cpp:122] Setting up Convolution49
I1101 13:43:42.030514  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.030515  4164 net.cpp:137] Memory required for data: 669287600
I1101 13:43:42.030519  4164 layer_factory.hpp:77] Creating layer BatchNorm49
I1101 13:43:42.030524  4164 net.cpp:84] Creating Layer BatchNorm49
I1101 13:43:42.030526  4164 net.cpp:406] BatchNorm49 <- Convolution49
I1101 13:43:42.030529  4164 net.cpp:367] BatchNorm49 -> Convolution49 (in-place)
I1101 13:43:42.030652  4164 net.cpp:122] Setting up BatchNorm49
I1101 13:43:42.030656  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.030658  4164 net.cpp:137] Memory required for data: 669697200
I1101 13:43:42.030661  4164 layer_factory.hpp:77] Creating layer Scale49
I1101 13:43:42.030665  4164 net.cpp:84] Creating Layer Scale49
I1101 13:43:42.030668  4164 net.cpp:406] Scale49 <- Convolution49
I1101 13:43:42.030670  4164 net.cpp:367] Scale49 -> Convolution49 (in-place)
I1101 13:43:42.030695  4164 layer_factory.hpp:77] Creating layer Scale49
I1101 13:43:42.030762  4164 net.cpp:122] Setting up Scale49
I1101 13:43:42.030766  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.030768  4164 net.cpp:137] Memory required for data: 670106800
I1101 13:43:42.030771  4164 layer_factory.hpp:77] Creating layer Eltwise22
I1101 13:43:42.030776  4164 net.cpp:84] Creating Layer Eltwise22
I1101 13:43:42.030778  4164 net.cpp:406] Eltwise22 <- Convolution49
I1101 13:43:42.030781  4164 net.cpp:406] Eltwise22 <- Eltwise21_ReLU43_0_split_1
I1101 13:43:42.030783  4164 net.cpp:380] Eltwise22 -> Eltwise22
I1101 13:43:42.030800  4164 net.cpp:122] Setting up Eltwise22
I1101 13:43:42.030803  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.030805  4164 net.cpp:137] Memory required for data: 670516400
I1101 13:43:42.030815  4164 layer_factory.hpp:77] Creating layer ReLU45
I1101 13:43:42.030819  4164 net.cpp:84] Creating Layer ReLU45
I1101 13:43:42.030822  4164 net.cpp:406] ReLU45 <- Eltwise22
I1101 13:43:42.030825  4164 net.cpp:367] ReLU45 -> Eltwise22 (in-place)
I1101 13:43:42.031203  4164 net.cpp:122] Setting up ReLU45
I1101 13:43:42.031210  4164 net.cpp:129] Top shape: 100 256 2 2 (102400)
I1101 13:43:42.031213  4164 net.cpp:137] Memory required for data: 670926000
I1101 13:43:42.031214  4164 layer_factory.hpp:77] Creating layer Pooling1
I1101 13:43:42.031219  4164 net.cpp:84] Creating Layer Pooling1
I1101 13:43:42.031220  4164 net.cpp:406] Pooling1 <- Eltwise22
I1101 13:43:42.031224  4164 net.cpp:380] Pooling1 -> Pooling1
I1101 13:43:42.031360  4164 net.cpp:122] Setting up Pooling1
I1101 13:43:42.031365  4164 net.cpp:129] Top shape: 100 256 1 1 (25600)
I1101 13:43:42.031368  4164 net.cpp:137] Memory required for data: 671028400
I1101 13:43:42.031369  4164 layer_factory.hpp:77] Creating layer InnerProduct1
I1101 13:43:42.031373  4164 net.cpp:84] Creating Layer InnerProduct1
I1101 13:43:42.031375  4164 net.cpp:406] InnerProduct1 <- Pooling1
I1101 13:43:42.031378  4164 net.cpp:380] InnerProduct1 -> InnerProduct1
I1101 13:43:42.031599  4164 net.cpp:122] Setting up InnerProduct1
I1101 13:43:42.031602  4164 net.cpp:129] Top shape: 100 62 (6200)
I1101 13:43:42.031605  4164 net.cpp:137] Memory required for data: 671053200
I1101 13:43:42.031607  4164 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1101 13:43:42.031611  4164 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1101 13:43:42.031613  4164 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1101 13:43:42.031616  4164 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1101 13:43:42.031620  4164 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1101 13:43:42.031643  4164 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1101 13:43:42.031647  4164 net.cpp:129] Top shape: 100 62 (6200)
I1101 13:43:42.031649  4164 net.cpp:129] Top shape: 100 62 (6200)
I1101 13:43:42.031651  4164 net.cpp:137] Memory required for data: 671102800
I1101 13:43:42.031652  4164 layer_factory.hpp:77] Creating layer Accuracy1
I1101 13:43:42.031656  4164 net.cpp:84] Creating Layer Accuracy1
I1101 13:43:42.031657  4164 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_0
I1101 13:43:42.031661  4164 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_0
I1101 13:43:42.031663  4164 net.cpp:380] Accuracy1 -> Accuracy1
I1101 13:43:42.031668  4164 net.cpp:122] Setting up Accuracy1
I1101 13:43:42.031671  4164 net.cpp:129] Top shape: (1)
I1101 13:43:42.031672  4164 net.cpp:137] Memory required for data: 671102804
I1101 13:43:42.031673  4164 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1101 13:43:42.031677  4164 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1101 13:43:42.031678  4164 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_1
I1101 13:43:42.031680  4164 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_1
I1101 13:43:42.031683  4164 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1101 13:43:42.031688  4164 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1101 13:43:42.031909  4164 net.cpp:122] Setting up SoftmaxWithLoss1
I1101 13:43:42.031915  4164 net.cpp:129] Top shape: (1)
I1101 13:43:42.031916  4164 net.cpp:132]     with loss weight 1
I1101 13:43:42.031924  4164 net.cpp:137] Memory required for data: 671102808
I1101 13:43:42.031925  4164 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1101 13:43:42.031927  4164 net.cpp:200] Accuracy1 does not need backward computation.
I1101 13:43:42.031930  4164 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1101 13:43:42.031932  4164 net.cpp:198] InnerProduct1 needs backward computation.
I1101 13:43:42.031934  4164 net.cpp:198] Pooling1 needs backward computation.
I1101 13:43:42.031935  4164 net.cpp:198] ReLU45 needs backward computation.
I1101 13:43:42.031942  4164 net.cpp:198] Eltwise22 needs backward computation.
I1101 13:43:42.031945  4164 net.cpp:198] Scale49 needs backward computation.
I1101 13:43:42.031947  4164 net.cpp:198] BatchNorm49 needs backward computation.
I1101 13:43:42.031949  4164 net.cpp:198] Convolution49 needs backward computation.
I1101 13:43:42.031950  4164 net.cpp:198] ReLU44 needs backward computation.
I1101 13:43:42.031952  4164 net.cpp:198] Scale48 needs backward computation.
I1101 13:43:42.031955  4164 net.cpp:198] BatchNorm48 needs backward computation.
I1101 13:43:42.031955  4164 net.cpp:198] Convolution48 needs backward computation.
I1101 13:43:42.031957  4164 net.cpp:198] Eltwise21_ReLU43_0_split needs backward computation.
I1101 13:43:42.031960  4164 net.cpp:198] ReLU43 needs backward computation.
I1101 13:43:42.031962  4164 net.cpp:198] Eltwise21 needs backward computation.
I1101 13:43:42.031965  4164 net.cpp:198] Scale47 needs backward computation.
I1101 13:43:42.031966  4164 net.cpp:198] BatchNorm47 needs backward computation.
I1101 13:43:42.031970  4164 net.cpp:198] Convolution47 needs backward computation.
I1101 13:43:42.031971  4164 net.cpp:198] ReLU42 needs backward computation.
I1101 13:43:42.031973  4164 net.cpp:198] Scale46 needs backward computation.
I1101 13:43:42.031975  4164 net.cpp:198] BatchNorm46 needs backward computation.
I1101 13:43:42.031977  4164 net.cpp:198] Convolution46 needs backward computation.
I1101 13:43:42.031994  4164 net.cpp:198] Eltwise20_ReLU41_0_split needs backward computation.
I1101 13:43:42.031996  4164 net.cpp:198] ReLU41 needs backward computation.
I1101 13:43:42.031998  4164 net.cpp:198] Eltwise20 needs backward computation.
I1101 13:43:42.032001  4164 net.cpp:198] Scale45 needs backward computation.
I1101 13:43:42.032002  4164 net.cpp:198] BatchNorm45 needs backward computation.
I1101 13:43:42.032004  4164 net.cpp:198] Convolution45 needs backward computation.
I1101 13:43:42.032006  4164 net.cpp:198] ReLU40 needs backward computation.
I1101 13:43:42.032008  4164 net.cpp:198] Scale44 needs backward computation.
I1101 13:43:42.032011  4164 net.cpp:198] BatchNorm44 needs backward computation.
I1101 13:43:42.032024  4164 net.cpp:198] Convolution44 needs backward computation.
I1101 13:43:42.032027  4164 net.cpp:198] Eltwise19_ReLU39_0_split needs backward computation.
I1101 13:43:42.032029  4164 net.cpp:198] ReLU39 needs backward computation.
I1101 13:43:42.032032  4164 net.cpp:198] Eltwise19 needs backward computation.
I1101 13:43:42.032047  4164 net.cpp:198] Scale43 needs backward computation.
I1101 13:43:42.032049  4164 net.cpp:198] BatchNorm43 needs backward computation.
I1101 13:43:42.032052  4164 net.cpp:198] Convolution43 needs backward computation.
I1101 13:43:42.032054  4164 net.cpp:198] Scale42 needs backward computation.
I1101 13:43:42.032057  4164 net.cpp:198] BatchNorm42 needs backward computation.
I1101 13:43:42.032058  4164 net.cpp:198] Convolution42 needs backward computation.
I1101 13:43:42.032060  4164 net.cpp:198] ReLU38 needs backward computation.
I1101 13:43:42.032063  4164 net.cpp:198] Scale41 needs backward computation.
I1101 13:43:42.032063  4164 net.cpp:198] BatchNorm41 needs backward computation.
I1101 13:43:42.032065  4164 net.cpp:198] Convolution41 needs backward computation.
I1101 13:43:42.032068  4164 net.cpp:198] Eltwise18_ReLU37_0_split needs backward computation.
I1101 13:43:42.032069  4164 net.cpp:198] ReLU37 needs backward computation.
I1101 13:43:42.032071  4164 net.cpp:198] Eltwise18 needs backward computation.
I1101 13:43:42.032073  4164 net.cpp:198] Scale40 needs backward computation.
I1101 13:43:42.032076  4164 net.cpp:198] BatchNorm40 needs backward computation.
I1101 13:43:42.032078  4164 net.cpp:198] Convolution40 needs backward computation.
I1101 13:43:42.032080  4164 net.cpp:198] ReLU36 needs backward computation.
I1101 13:43:42.032083  4164 net.cpp:198] Scale39 needs backward computation.
I1101 13:43:42.032084  4164 net.cpp:198] BatchNorm39 needs backward computation.
I1101 13:43:42.032086  4164 net.cpp:198] Convolution39 needs backward computation.
I1101 13:43:42.032091  4164 net.cpp:198] Eltwise17_ReLU35_0_split needs backward computation.
I1101 13:43:42.032094  4164 net.cpp:198] ReLU35 needs backward computation.
I1101 13:43:42.032109  4164 net.cpp:198] Eltwise17 needs backward computation.
I1101 13:43:42.032110  4164 net.cpp:198] Scale38 needs backward computation.
I1101 13:43:42.032112  4164 net.cpp:198] BatchNorm38 needs backward computation.
I1101 13:43:42.032114  4164 net.cpp:198] Convolution38 needs backward computation.
I1101 13:43:42.032116  4164 net.cpp:198] ReLU34 needs backward computation.
I1101 13:43:42.032133  4164 net.cpp:198] Scale37 needs backward computation.
I1101 13:43:42.032135  4164 net.cpp:198] BatchNorm37 needs backward computation.
I1101 13:43:42.032136  4164 net.cpp:198] Convolution37 needs backward computation.
I1101 13:43:42.032140  4164 net.cpp:198] Eltwise16_ReLU33_0_split needs backward computation.
I1101 13:43:42.032141  4164 net.cpp:198] ReLU33 needs backward computation.
I1101 13:43:42.032142  4164 net.cpp:198] Eltwise16 needs backward computation.
I1101 13:43:42.032145  4164 net.cpp:198] Scale36 needs backward computation.
I1101 13:43:42.032147  4164 net.cpp:198] BatchNorm36 needs backward computation.
I1101 13:43:42.032148  4164 net.cpp:198] Convolution36 needs backward computation.
I1101 13:43:42.032150  4164 net.cpp:198] ReLU32 needs backward computation.
I1101 13:43:42.032152  4164 net.cpp:198] Scale35 needs backward computation.
I1101 13:43:42.032155  4164 net.cpp:198] BatchNorm35 needs backward computation.
I1101 13:43:42.032155  4164 net.cpp:198] Convolution35 needs backward computation.
I1101 13:43:42.032171  4164 net.cpp:198] Eltwise15_ReLU31_0_split needs backward computation.
I1101 13:43:42.032172  4164 net.cpp:198] ReLU31 needs backward computation.
I1101 13:43:42.032174  4164 net.cpp:198] Eltwise15 needs backward computation.
I1101 13:43:42.032176  4164 net.cpp:198] Scale34 needs backward computation.
I1101 13:43:42.032178  4164 net.cpp:198] BatchNorm34 needs backward computation.
I1101 13:43:42.032194  4164 net.cpp:198] Convolution34 needs backward computation.
I1101 13:43:42.032197  4164 net.cpp:198] Scale33 needs backward computation.
I1101 13:43:42.032199  4164 net.cpp:198] BatchNorm33 needs backward computation.
I1101 13:43:42.032200  4164 net.cpp:198] Convolution33 needs backward computation.
I1101 13:43:42.032202  4164 net.cpp:198] ReLU30 needs backward computation.
I1101 13:43:42.032204  4164 net.cpp:198] Scale32 needs backward computation.
I1101 13:43:42.032207  4164 net.cpp:198] BatchNorm32 needs backward computation.
I1101 13:43:42.032208  4164 net.cpp:198] Convolution32 needs backward computation.
I1101 13:43:42.032210  4164 net.cpp:198] Eltwise14_ReLU29_0_split needs backward computation.
I1101 13:43:42.032213  4164 net.cpp:198] ReLU29 needs backward computation.
I1101 13:43:42.032215  4164 net.cpp:198] Eltwise14 needs backward computation.
I1101 13:43:42.032217  4164 net.cpp:198] Scale31 needs backward computation.
I1101 13:43:42.032218  4164 net.cpp:198] BatchNorm31 needs backward computation.
I1101 13:43:42.032222  4164 net.cpp:198] Convolution31 needs backward computation.
I1101 13:43:42.032223  4164 net.cpp:198] ReLU28 needs backward computation.
I1101 13:43:42.032224  4164 net.cpp:198] Scale30 needs backward computation.
I1101 13:43:42.032227  4164 net.cpp:198] BatchNorm30 needs backward computation.
I1101 13:43:42.032241  4164 net.cpp:198] Convolution30 needs backward computation.
I1101 13:43:42.032243  4164 net.cpp:198] Eltwise13_ReLU27_0_split needs backward computation.
I1101 13:43:42.032245  4164 net.cpp:198] ReLU27 needs backward computation.
I1101 13:43:42.032246  4164 net.cpp:198] Eltwise13 needs backward computation.
I1101 13:43:42.032263  4164 net.cpp:198] Scale29 needs backward computation.
I1101 13:43:42.032264  4164 net.cpp:198] BatchNorm29 needs backward computation.
I1101 13:43:42.032265  4164 net.cpp:198] Convolution29 needs backward computation.
I1101 13:43:42.032268  4164 net.cpp:198] ReLU26 needs backward computation.
I1101 13:43:42.032274  4164 net.cpp:198] Scale28 needs backward computation.
I1101 13:43:42.032276  4164 net.cpp:198] BatchNorm28 needs backward computation.
I1101 13:43:42.032277  4164 net.cpp:198] Convolution28 needs backward computation.
I1101 13:43:42.032279  4164 net.cpp:198] Eltwise12_ReLU25_0_split needs backward computation.
I1101 13:43:42.032281  4164 net.cpp:198] ReLU25 needs backward computation.
I1101 13:43:42.032284  4164 net.cpp:198] Eltwise12 needs backward computation.
I1101 13:43:42.032285  4164 net.cpp:198] Scale27 needs backward computation.
I1101 13:43:42.032287  4164 net.cpp:198] BatchNorm27 needs backward computation.
I1101 13:43:42.032289  4164 net.cpp:198] Convolution27 needs backward computation.
I1101 13:43:42.032291  4164 net.cpp:198] ReLU24 needs backward computation.
I1101 13:43:42.032294  4164 net.cpp:198] Scale26 needs backward computation.
I1101 13:43:42.032295  4164 net.cpp:198] BatchNorm26 needs backward computation.
I1101 13:43:42.032297  4164 net.cpp:198] Convolution26 needs backward computation.
I1101 13:43:42.032299  4164 net.cpp:198] Eltwise11_ReLU23_0_split needs backward computation.
I1101 13:43:42.032301  4164 net.cpp:198] ReLU23 needs backward computation.
I1101 13:43:42.032304  4164 net.cpp:198] Eltwise11 needs backward computation.
I1101 13:43:42.032305  4164 net.cpp:198] Scale25 needs backward computation.
I1101 13:43:42.032307  4164 net.cpp:198] BatchNorm25 needs backward computation.
I1101 13:43:42.032308  4164 net.cpp:198] Convolution25 needs backward computation.
I1101 13:43:42.032310  4164 net.cpp:198] ReLU22 needs backward computation.
I1101 13:43:42.032312  4164 net.cpp:198] Scale24 needs backward computation.
I1101 13:43:42.032315  4164 net.cpp:198] BatchNorm24 needs backward computation.
I1101 13:43:42.032316  4164 net.cpp:198] Convolution24 needs backward computation.
I1101 13:43:42.032318  4164 net.cpp:198] Eltwise10_ReLU21_0_split needs backward computation.
I1101 13:43:42.032320  4164 net.cpp:198] ReLU21 needs backward computation.
I1101 13:43:42.032322  4164 net.cpp:198] Eltwise10 needs backward computation.
I1101 13:43:42.032325  4164 net.cpp:198] Scale23 needs backward computation.
I1101 13:43:42.032326  4164 net.cpp:198] BatchNorm23 needs backward computation.
I1101 13:43:42.032328  4164 net.cpp:198] Convolution23 needs backward computation.
I1101 13:43:42.032331  4164 net.cpp:198] Scale22 needs backward computation.
I1101 13:43:42.032333  4164 net.cpp:198] BatchNorm22 needs backward computation.
I1101 13:43:42.032335  4164 net.cpp:198] Convolution22 needs backward computation.
I1101 13:43:42.032336  4164 net.cpp:198] ReLU20 needs backward computation.
I1101 13:43:42.032340  4164 net.cpp:198] Scale21 needs backward computation.
I1101 13:43:42.032341  4164 net.cpp:198] BatchNorm21 needs backward computation.
I1101 13:43:42.032342  4164 net.cpp:198] Convolution21 needs backward computation.
I1101 13:43:42.032346  4164 net.cpp:198] Eltwise9_ReLU19_0_split needs backward computation.
I1101 13:43:42.032347  4164 net.cpp:198] ReLU19 needs backward computation.
I1101 13:43:42.032349  4164 net.cpp:198] Eltwise9 needs backward computation.
I1101 13:43:42.032351  4164 net.cpp:198] Scale20 needs backward computation.
I1101 13:43:42.032353  4164 net.cpp:198] BatchNorm20 needs backward computation.
I1101 13:43:42.032356  4164 net.cpp:198] Convolution20 needs backward computation.
I1101 13:43:42.032357  4164 net.cpp:198] ReLU18 needs backward computation.
I1101 13:43:42.032359  4164 net.cpp:198] Scale19 needs backward computation.
I1101 13:43:42.032361  4164 net.cpp:198] BatchNorm19 needs backward computation.
I1101 13:43:42.032363  4164 net.cpp:198] Convolution19 needs backward computation.
I1101 13:43:42.032366  4164 net.cpp:198] Eltwise8_ReLU17_0_split needs backward computation.
I1101 13:43:42.032367  4164 net.cpp:198] ReLU17 needs backward computation.
I1101 13:43:42.032369  4164 net.cpp:198] Eltwise8 needs backward computation.
I1101 13:43:42.032371  4164 net.cpp:198] Scale18 needs backward computation.
I1101 13:43:42.032374  4164 net.cpp:198] BatchNorm18 needs backward computation.
I1101 13:43:42.032379  4164 net.cpp:198] Convolution18 needs backward computation.
I1101 13:43:42.032382  4164 net.cpp:198] ReLU16 needs backward computation.
I1101 13:43:42.032384  4164 net.cpp:198] Scale17 needs backward computation.
I1101 13:43:42.032385  4164 net.cpp:198] BatchNorm17 needs backward computation.
I1101 13:43:42.032387  4164 net.cpp:198] Convolution17 needs backward computation.
I1101 13:43:42.032389  4164 net.cpp:198] Eltwise7_ReLU15_0_split needs backward computation.
I1101 13:43:42.032392  4164 net.cpp:198] ReLU15 needs backward computation.
I1101 13:43:42.032393  4164 net.cpp:198] Eltwise7 needs backward computation.
I1101 13:43:42.032397  4164 net.cpp:198] Scale16 needs backward computation.
I1101 13:43:42.032398  4164 net.cpp:198] BatchNorm16 needs backward computation.
I1101 13:43:42.032400  4164 net.cpp:198] Convolution16 needs backward computation.
I1101 13:43:42.032402  4164 net.cpp:198] ReLU14 needs backward computation.
I1101 13:43:42.032403  4164 net.cpp:198] Scale15 needs backward computation.
I1101 13:43:42.032405  4164 net.cpp:198] BatchNorm15 needs backward computation.
I1101 13:43:42.032407  4164 net.cpp:198] Convolution15 needs backward computation.
I1101 13:43:42.032409  4164 net.cpp:198] Eltwise6_ReLU13_0_split needs backward computation.
I1101 13:43:42.032411  4164 net.cpp:198] ReLU13 needs backward computation.
I1101 13:43:42.032414  4164 net.cpp:198] Eltwise6 needs backward computation.
I1101 13:43:42.032416  4164 net.cpp:198] Scale14 needs backward computation.
I1101 13:43:42.032418  4164 net.cpp:198] BatchNorm14 needs backward computation.
I1101 13:43:42.032420  4164 net.cpp:198] Convolution14 needs backward computation.
I1101 13:43:42.032423  4164 net.cpp:198] ReLU12 needs backward computation.
I1101 13:43:42.032424  4164 net.cpp:198] Scale13 needs backward computation.
I1101 13:43:42.032426  4164 net.cpp:198] BatchNorm13 needs backward computation.
I1101 13:43:42.032428  4164 net.cpp:198] Convolution13 needs backward computation.
I1101 13:43:42.032430  4164 net.cpp:198] Eltwise5_ReLU11_0_split needs backward computation.
I1101 13:43:42.032433  4164 net.cpp:198] ReLU11 needs backward computation.
I1101 13:43:42.032434  4164 net.cpp:198] Eltwise5 needs backward computation.
I1101 13:43:42.032436  4164 net.cpp:198] Scale12 needs backward computation.
I1101 13:43:42.032438  4164 net.cpp:198] BatchNorm12 needs backward computation.
I1101 13:43:42.032440  4164 net.cpp:198] Convolution12 needs backward computation.
I1101 13:43:42.032443  4164 net.cpp:198] Scale11 needs backward computation.
I1101 13:43:42.032444  4164 net.cpp:198] BatchNorm11 needs backward computation.
I1101 13:43:42.032446  4164 net.cpp:198] Convolution11 needs backward computation.
I1101 13:43:42.032449  4164 net.cpp:198] ReLU10 needs backward computation.
I1101 13:43:42.032450  4164 net.cpp:198] Scale10 needs backward computation.
I1101 13:43:42.032452  4164 net.cpp:198] BatchNorm10 needs backward computation.
I1101 13:43:42.032454  4164 net.cpp:198] Convolution10 needs backward computation.
I1101 13:43:42.032456  4164 net.cpp:198] Eltwise4_ReLU9_0_split needs backward computation.
I1101 13:43:42.032459  4164 net.cpp:198] ReLU9 needs backward computation.
I1101 13:43:42.032460  4164 net.cpp:198] Eltwise4 needs backward computation.
I1101 13:43:42.032462  4164 net.cpp:198] Scale9 needs backward computation.
I1101 13:43:42.032464  4164 net.cpp:198] BatchNorm9 needs backward computation.
I1101 13:43:42.032466  4164 net.cpp:198] Convolution9 needs backward computation.
I1101 13:43:42.032469  4164 net.cpp:198] ReLU8 needs backward computation.
I1101 13:43:42.032470  4164 net.cpp:198] Scale8 needs backward computation.
I1101 13:43:42.032472  4164 net.cpp:198] BatchNorm8 needs backward computation.
I1101 13:43:42.032474  4164 net.cpp:198] Convolution8 needs backward computation.
I1101 13:43:42.032476  4164 net.cpp:198] Eltwise3_ReLU7_0_split needs backward computation.
I1101 13:43:42.032479  4164 net.cpp:198] ReLU7 needs backward computation.
I1101 13:43:42.032480  4164 net.cpp:198] Eltwise3 needs backward computation.
I1101 13:43:42.032485  4164 net.cpp:198] Scale7 needs backward computation.
I1101 13:43:42.032487  4164 net.cpp:198] BatchNorm7 needs backward computation.
I1101 13:43:42.032490  4164 net.cpp:198] Convolution7 needs backward computation.
I1101 13:43:42.032491  4164 net.cpp:198] ReLU6 needs backward computation.
I1101 13:43:42.032493  4164 net.cpp:198] Scale6 needs backward computation.
I1101 13:43:42.032495  4164 net.cpp:198] BatchNorm6 needs backward computation.
I1101 13:43:42.032497  4164 net.cpp:198] Convolution6 needs backward computation.
I1101 13:43:42.032500  4164 net.cpp:198] Eltwise2_ReLU5_0_split needs backward computation.
I1101 13:43:42.032501  4164 net.cpp:198] ReLU5 needs backward computation.
I1101 13:43:42.032503  4164 net.cpp:198] Eltwise2 needs backward computation.
I1101 13:43:42.032505  4164 net.cpp:198] Scale5 needs backward computation.
I1101 13:43:42.032507  4164 net.cpp:198] BatchNorm5 needs backward computation.
I1101 13:43:42.032510  4164 net.cpp:198] Convolution5 needs backward computation.
I1101 13:43:42.032512  4164 net.cpp:198] ReLU4 needs backward computation.
I1101 13:43:42.032515  4164 net.cpp:198] Scale4 needs backward computation.
I1101 13:43:42.032516  4164 net.cpp:198] BatchNorm4 needs backward computation.
I1101 13:43:42.032517  4164 net.cpp:198] Convolution4 needs backward computation.
I1101 13:43:42.032521  4164 net.cpp:198] Eltwise1_ReLU3_0_split needs backward computation.
I1101 13:43:42.032522  4164 net.cpp:198] ReLU3 needs backward computation.
I1101 13:43:42.032524  4164 net.cpp:198] Eltwise1 needs backward computation.
I1101 13:43:42.032526  4164 net.cpp:198] Scale3 needs backward computation.
I1101 13:43:42.032528  4164 net.cpp:198] BatchNorm3 needs backward computation.
I1101 13:43:42.032531  4164 net.cpp:198] Convolution3 needs backward computation.
I1101 13:43:42.032531  4164 net.cpp:198] ReLU2 needs backward computation.
I1101 13:43:42.032533  4164 net.cpp:198] Scale2 needs backward computation.
I1101 13:43:42.032536  4164 net.cpp:198] BatchNorm2 needs backward computation.
I1101 13:43:42.032537  4164 net.cpp:198] Convolution2 needs backward computation.
I1101 13:43:42.032539  4164 net.cpp:198] Convolution1_ReLU1_0_split needs backward computation.
I1101 13:43:42.032541  4164 net.cpp:198] ReLU1 needs backward computation.
I1101 13:43:42.032543  4164 net.cpp:198] Scale1 needs backward computation.
I1101 13:43:42.032546  4164 net.cpp:198] BatchNorm1 needs backward computation.
I1101 13:43:42.032547  4164 net.cpp:198] Convolution1 needs backward computation.
I1101 13:43:42.032549  4164 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1101 13:43:42.032552  4164 net.cpp:200] Data1 does not need backward computation.
I1101 13:43:42.032553  4164 net.cpp:242] This network produces output Accuracy1
I1101 13:43:42.032555  4164 net.cpp:242] This network produces output SoftmaxWithLoss1
I1101 13:43:42.032626  4164 net.cpp:255] Network initialization done.
I1101 13:43:42.032934  4164 solver.cpp:56] Solver scaffolding done.
I1101 13:43:42.040683  4164 caffe.cpp:248] Starting Optimization
I1101 13:43:42.040688  4164 solver.cpp:272] Solving 
I1101 13:43:42.040689  4164 solver.cpp:273] Learning Rate Policy: multistep
I1101 13:43:42.418579  4164 solver.cpp:218] Iteration 0 (-8888.33 iter/s, 0.377798s/20 iters), loss = 6.07032
I1101 13:43:42.418619  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 6.07032 (* 1 = 6.07032 loss)
I1101 13:43:42.418632  4164 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1101 13:43:49.452596  4164 solver.cpp:218] Iteration 20 (2.84341 iter/s, 7.03382s/20 iters), loss = 5.06234
I1101 13:43:49.452621  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 4.45338 (* 1 = 4.45338 loss)
I1101 13:43:49.452626  4164 sgd_solver.cpp:105] Iteration 20, lr = 0.1
I1101 13:43:56.482254  4164 solver.cpp:218] Iteration 40 (2.84517 iter/s, 7.02946s/20 iters), loss = 4.46168
I1101 13:43:56.482283  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.82037 (* 1 = 2.82037 loss)
I1101 13:43:56.482288  4164 sgd_solver.cpp:105] Iteration 40, lr = 0.1
I1101 13:44:03.583142  4164 solver.cpp:218] Iteration 60 (2.81663 iter/s, 7.10069s/20 iters), loss = 3.71813
I1101 13:44:03.583168  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.60075 (* 1 = 1.60075 loss)
I1101 13:44:03.583173  4164 sgd_solver.cpp:105] Iteration 60, lr = 0.1
I1101 13:44:10.961714  4164 solver.cpp:218] Iteration 80 (2.71062 iter/s, 7.37837s/20 iters), loss = 3.11178
I1101 13:44:10.961760  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.989501 (* 1 = 0.989501 loss)
I1101 13:44:10.961766  4164 sgd_solver.cpp:105] Iteration 80, lr = 0.1
I1101 13:44:17.764343  4164 solver.cpp:330] Iteration 100, Testing net (#0)
I1101 13:44:21.148340  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1101 13:44:21.286895  4164 solver.cpp:397]     Test net output #0: Accuracy1 = 0.0222
I1101 13:44:21.286916  4164 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 48.5506 (* 1 = 48.5506 loss)
I1101 13:44:21.636308  4164 solver.cpp:218] Iteration 100 (1.87366 iter/s, 10.6743s/20 iters), loss = 2.63735
I1101 13:44:21.636334  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.726027 (* 1 = 0.726027 loss)
I1101 13:44:21.636354  4164 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1101 13:44:28.688715  4164 solver.cpp:218] Iteration 120 (2.83599 iter/s, 7.05221s/20 iters), loss = 1.76228
I1101 13:44:28.688753  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.555243 (* 1 = 0.555243 loss)
I1101 13:44:28.688758  4164 sgd_solver.cpp:105] Iteration 120, lr = 0.1
I1101 13:44:35.717447  4164 solver.cpp:218] Iteration 140 (2.84554 iter/s, 7.02854s/20 iters), loss = 1.09344
I1101 13:44:35.717486  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.423106 (* 1 = 0.423106 loss)
I1101 13:44:35.717492  4164 sgd_solver.cpp:105] Iteration 140, lr = 0.1
I1101 13:44:42.740866  4164 solver.cpp:218] Iteration 160 (2.84769 iter/s, 7.02323s/20 iters), loss = 0.73215
I1101 13:44:42.740903  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.396425 (* 1 = 0.396425 loss)
I1101 13:44:42.740909  4164 sgd_solver.cpp:105] Iteration 160, lr = 0.1
I1101 13:44:49.839576  4164 solver.cpp:218] Iteration 180 (2.81749 iter/s, 7.09852s/20 iters), loss = 0.545031
I1101 13:44:49.839716  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257621 (* 1 = 0.257621 loss)
I1101 13:44:49.839738  4164 sgd_solver.cpp:105] Iteration 180, lr = 0.1
I1101 13:44:56.606884  4164 solver.cpp:330] Iteration 200, Testing net (#0)
I1101 13:44:59.961486  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1101 13:45:00.103143  4164 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1237
I1101 13:45:00.103164  4164 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.95701 (* 1 = 3.95701 loss)
I1101 13:45:00.453984  4164 solver.cpp:218] Iteration 200 (1.8843 iter/s, 10.614s/20 iters), loss = 0.420768
I1101 13:45:00.454012  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16641 (* 1 = 0.16641 loss)
I1101 13:45:00.454017  4164 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1101 13:45:07.511847  4164 solver.cpp:218] Iteration 220 (2.8338 iter/s, 7.05767s/20 iters), loss = 0.343585
I1101 13:45:07.511890  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235815 (* 1 = 0.235815 loss)
I1101 13:45:07.511896  4164 sgd_solver.cpp:105] Iteration 220, lr = 0.1
I1101 13:45:14.567299  4164 solver.cpp:218] Iteration 240 (2.83476 iter/s, 7.05526s/20 iters), loss = 0.289243
I1101 13:45:14.567337  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231616 (* 1 = 0.231616 loss)
I1101 13:45:14.567343  4164 sgd_solver.cpp:105] Iteration 240, lr = 0.1
I1101 13:45:21.620142  4164 solver.cpp:218] Iteration 260 (2.83581 iter/s, 7.05266s/20 iters), loss = 0.254
I1101 13:45:21.620266  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253554 (* 1 = 0.253554 loss)
I1101 13:45:21.620273  4164 sgd_solver.cpp:105] Iteration 260, lr = 0.1
I1101 13:45:28.784271  4164 solver.cpp:218] Iteration 280 (2.7918 iter/s, 7.16384s/20 iters), loss = 0.229251
I1101 13:45:28.784303  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275438 (* 1 = 0.275438 loss)
I1101 13:45:28.784309  4164 sgd_solver.cpp:105] Iteration 280, lr = 0.1
I1101 13:45:35.546890  4164 solver.cpp:330] Iteration 300, Testing net (#0)
I1101 13:45:38.970228  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1101 13:45:39.113991  4164 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3545
I1101 13:45:39.114014  4164 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.31574 (* 1 = 2.31574 loss)
I1101 13:45:39.475647  4164 solver.cpp:218] Iteration 300 (1.87073 iter/s, 10.691s/20 iters), loss = 0.212129
I1101 13:45:39.475682  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171855 (* 1 = 0.171855 loss)
I1101 13:45:39.475689  4164 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1101 13:45:46.648586  4164 solver.cpp:218] Iteration 320 (2.78833 iter/s, 7.17274s/20 iters), loss = 0.19625
I1101 13:45:46.648617  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160776 (* 1 = 0.160776 loss)
I1101 13:45:46.648624  4164 sgd_solver.cpp:105] Iteration 320, lr = 0.1
I1101 13:45:53.831384  4164 solver.cpp:218] Iteration 340 (2.7845 iter/s, 7.18261s/20 iters), loss = 0.186718
I1101 13:45:53.831544  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143063 (* 1 = 0.143063 loss)
I1101 13:45:53.831555  4164 sgd_solver.cpp:105] Iteration 340, lr = 0.1
I1101 13:46:00.969538  4164 solver.cpp:218] Iteration 360 (2.80197 iter/s, 7.13784s/20 iters), loss = 0.175734
I1101 13:46:00.969568  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144334 (* 1 = 0.144334 loss)
I1101 13:46:00.969574  4164 sgd_solver.cpp:105] Iteration 360, lr = 0.1
I1101 13:46:08.152663  4164 solver.cpp:218] Iteration 380 (2.78438 iter/s, 7.18294s/20 iters), loss = 0.169249
I1101 13:46:08.152693  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213917 (* 1 = 0.213917 loss)
I1101 13:46:08.152700  4164 sgd_solver.cpp:105] Iteration 380, lr = 0.1
I1101 13:46:10.315147  4171 data_layer.cpp:73] Restarting data prefetching from start.
I1101 13:46:14.927450  4164 solver.cpp:330] Iteration 400, Testing net (#0)
I1101 13:46:18.347929  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1101 13:46:18.492810  4164 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2895
I1101 13:46:18.492832  4164 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.71937 (* 1 = 2.71937 loss)
I1101 13:46:18.851781  4164 solver.cpp:218] Iteration 400 (1.86936 iter/s, 10.6989s/20 iters), loss = 0.16566
I1101 13:46:18.851824  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120958 (* 1 = 0.120958 loss)
I1101 13:46:18.851830  4164 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1101 13:46:26.118482  4164 solver.cpp:218] Iteration 420 (2.75236 iter/s, 7.2665s/20 iters), loss = 0.159208
I1101 13:46:26.118630  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0938316 (* 1 = 0.0938316 loss)
I1101 13:46:26.118638  4164 sgd_solver.cpp:105] Iteration 420, lr = 0.1
I1101 13:46:33.297981  4164 solver.cpp:218] Iteration 440 (2.78584 iter/s, 7.17916s/20 iters), loss = 0.154613
I1101 13:46:33.298024  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14 (* 1 = 0.14 loss)
I1101 13:46:33.298030  4164 sgd_solver.cpp:105] Iteration 440, lr = 0.1
I1101 13:46:40.392338  4164 solver.cpp:218] Iteration 460 (2.81922 iter/s, 7.09415s/20 iters), loss = 0.151968
I1101 13:46:40.392376  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189352 (* 1 = 0.189352 loss)
I1101 13:46:40.392382  4164 sgd_solver.cpp:105] Iteration 460, lr = 0.1
I1101 13:46:47.637523  4164 solver.cpp:218] Iteration 480 (2.76053 iter/s, 7.24499s/20 iters), loss = 0.143531
I1101 13:46:47.637548  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0754882 (* 1 = 0.0754882 loss)
I1101 13:46:47.637554  4164 sgd_solver.cpp:105] Iteration 480, lr = 0.1
I1101 13:46:54.481784  4164 solver.cpp:330] Iteration 500, Testing net (#0)
I1101 13:46:57.930560  4172 data_layer.cpp:73] Restarting data prefetching from start.
I1101 13:46:58.072643  4164 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2046
I1101 13:46:58.072669  4164 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.43009 (* 1 = 3.43009 loss)
I1101 13:46:58.435721  4164 solver.cpp:218] Iteration 500 (1.85221 iter/s, 10.7979s/20 iters), loss = 0.132489
I1101 13:46:58.435751  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0631767 (* 1 = 0.0631767 loss)
I1101 13:46:58.435771  4164 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1101 13:47:05.712262  4164 solver.cpp:218] Iteration 520 (2.74863 iter/s, 7.27635s/20 iters), loss = 0.126484
I1101 13:47:05.712306  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128102 (* 1 = 0.128102 loss)
I1101 13:47:05.712312  4164 sgd_solver.cpp:105] Iteration 520, lr = 0.1
I1101 13:47:12.875591  4164 solver.cpp:218] Iteration 540 (2.79208 iter/s, 7.16313s/20 iters), loss = 0.120015
I1101 13:47:12.875634  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0957179 (* 1 = 0.0957179 loss)
I1101 13:47:12.875640  4164 sgd_solver.cpp:105] Iteration 540, lr = 0.1
I1101 13:47:20.068187  4164 solver.cpp:218] Iteration 560 (2.78071 iter/s, 7.19241s/20 iters), loss = 0.111904
I1101 13:47:20.068233  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11661 (* 1 = 0.11661 loss)
I1101 13:47:20.068239  4164 sgd_solver.cpp:105] Iteration 560, lr = 0.1
I1101 13:47:27.319733  4164 solver.cpp:218] Iteration 580 (2.75811 iter/s, 7.25134s/20 iters), loss = 0.106014
I1101 13:47:27.319763  4164 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0942973 (* 1 = 0.0942973 loss)
I1101 13:47:27.319782  4164 sgd_solver.cpp:105] Iteration 580, lr = 0.1
