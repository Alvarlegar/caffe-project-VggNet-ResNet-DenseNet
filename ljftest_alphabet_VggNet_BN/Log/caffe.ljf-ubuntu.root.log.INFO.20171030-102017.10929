Log file created at: 2017/10/30 10:20:17
Running on machine: ljf-ubuntu
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I1030 10:20:17.181272 10929 caffe.cpp:218] Using GPUs 0
I1030 10:20:17.202116 10929 caffe.cpp:223] GPU 0: GeForce GTX 1060 6GB
I1030 10:20:17.405336 10929 solver.cpp:44] Initializing solver from parameters: 
train_net: "/home/ljf/caffe-master/examples/ljftest_alphabet_VggNet/train.prototxt"
test_net: "/home/ljf/caffe-master/examples/ljftest_alphabet_VggNet/test.prototxt"
test_iter: 10
test_interval: 100
base_lr: 0.003
display: 20
max_iter: 200000
lr_policy: "inv"
gamma: 0.0002
power: 0.95
momentum: 0.9
weight_decay: 0.005
stepsize: 100000
snapshot: 10000
snapshot_prefix: "/home/ljf/caffe-master/examples/ljftest_alphabet_VggNet/caffe_ljftest_train"
solver_mode: GPU
device_id: 0
train_state {
  level: 0
  stage: ""
}
I1030 10:20:17.405481 10929 solver.cpp:77] Creating training net from train_net file: /home/ljf/caffe-master/examples/ljftest_alphabet_VggNet/train.prototxt
I1030 10:20:17.405777 10929 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/ljf/caffe-master/examples/ljftest_alphabet_VggNet/train.prototxt
I1030 10:20:17.405784 10929 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1030 10:20:17.406002 10929 net.cpp:51] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "face"
  type: "Data"
  top: "data"
  top: "label"
  data_param {
    source: "/home/ljf/caffe-master/examples/ljftest_alphabet_VggNet/train_lmdb"
    batch_size: 128
    backend: LMDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BN1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "BN2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BN3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BN4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BN5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BN6"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "conv6"
  top: "conv6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BN7"
  type: "BatchNorm"
  bottom: "conv7"
  top: "conv7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "conv7"
  top: "conv7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "conv7"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "fc65"
  type: "InnerProduct"
  bottom: "pool7"
  top: "fc65"
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.00390625
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu65"
  type: "ReLU"
  bottom: "fc65"
  top: "fc65"
}
layer {
  name: "drop65"
  type: "Dropout"
  bottom: "fc65"
  top: "fc65"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "fc66"
  type: "InnerProduct"
  bottom: "fc65"
  top: "fc66"
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.00390625
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu66"
  type: "ReLU"
  bottom: "fc66"
  top: "fc66"
}
layer {
  name: "drop66"
  type: "Dropout"
  bottom: "fc66"
  top: "fc66"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc100"
  type: "InnerProduct"
  bottom: "fc66"
  top: "fc100"
  inner_product_param {
    num_output: 62
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc100"
  bottom: "label"
  top: "loss"
}
I1030 10:20:17.406132 10929 layer_factory.hpp:77] Creating layer face
I1030 10:20:17.406214 10929 db_lmdb.cpp:35] Opened lmdb /home/ljf/caffe-master/examples/ljftest_alphabet_VggNet/train_lmdb
I1030 10:20:17.406236 10929 net.cpp:84] Creating Layer face
I1030 10:20:17.406241 10929 net.cpp:380] face -> data
I1030 10:20:17.406257 10929 net.cpp:380] face -> label
I1030 10:20:17.406939 10929 data_layer.cpp:45] output data size: 128,3,32,32
I1030 10:20:17.411151 10929 net.cpp:122] Setting up face
I1030 10:20:17.411192 10929 net.cpp:129] Top shape: 128 3 32 32 (393216)
I1030 10:20:17.411195 10929 net.cpp:129] Top shape: 128 (128)
I1030 10:20:17.411197 10929 net.cpp:137] Memory required for data: 1573376
I1030 10:20:17.411206 10929 layer_factory.hpp:77] Creating layer conv1
I1030 10:20:17.411224 10929 net.cpp:84] Creating Layer conv1
I1030 10:20:17.411229 10929 net.cpp:406] conv1 <- data
I1030 10:20:17.411239 10929 net.cpp:380] conv1 -> conv1
I1030 10:20:17.630695 10929 net.cpp:122] Setting up conv1
I1030 10:20:17.630730 10929 net.cpp:129] Top shape: 128 64 32 32 (8388608)
I1030 10:20:17.630733 10929 net.cpp:137] Memory required for data: 35127808
I1030 10:20:17.630754 10929 layer_factory.hpp:77] Creating layer BN1
I1030 10:20:17.630765 10929 net.cpp:84] Creating Layer BN1
I1030 10:20:17.630769 10929 net.cpp:406] BN1 <- conv1
I1030 10:20:17.630772 10929 net.cpp:367] BN1 -> conv1 (in-place)
I1030 10:20:17.630937 10929 net.cpp:122] Setting up BN1
I1030 10:20:17.630942 10929 net.cpp:129] Top shape: 128 64 32 32 (8388608)
I1030 10:20:17.630957 10929 net.cpp:137] Memory required for data: 68682240
I1030 10:20:17.630964 10929 layer_factory.hpp:77] Creating layer scale1
I1030 10:20:17.630969 10929 net.cpp:84] Creating Layer scale1
I1030 10:20:17.630971 10929 net.cpp:406] scale1 <- conv1
I1030 10:20:17.630975 10929 net.cpp:367] scale1 -> conv1 (in-place)
I1030 10:20:17.631000 10929 layer_factory.hpp:77] Creating layer scale1
I1030 10:20:17.631093 10929 net.cpp:122] Setting up scale1
I1030 10:20:17.631098 10929 net.cpp:129] Top shape: 128 64 32 32 (8388608)
I1030 10:20:17.631099 10929 net.cpp:137] Memory required for data: 102236672
I1030 10:20:17.631103 10929 layer_factory.hpp:77] Creating layer relu1
I1030 10:20:17.631106 10929 net.cpp:84] Creating Layer relu1
I1030 10:20:17.631108 10929 net.cpp:406] relu1 <- conv1
I1030 10:20:17.631110 10929 net.cpp:367] relu1 -> conv1 (in-place)
I1030 10:20:17.631222 10929 net.cpp:122] Setting up relu1
I1030 10:20:17.631239 10929 net.cpp:129] Top shape: 128 64 32 32 (8388608)
I1030 10:20:17.631242 10929 net.cpp:137] Memory required for data: 135791104
I1030 10:20:17.631243 10929 layer_factory.hpp:77] Creating layer conv2
I1030 10:20:17.631263 10929 net.cpp:84] Creating Layer conv2
I1030 10:20:17.631265 10929 net.cpp:406] conv2 <- conv1
I1030 10:20:17.631268 10929 net.cpp:380] conv2 -> conv2
I1030 10:20:17.633016 10929 net.cpp:122] Setting up conv2
I1030 10:20:17.633024 10929 net.cpp:129] Top shape: 128 64 32 32 (8388608)
I1030 10:20:17.633026 10929 net.cpp:137] Memory required for data: 169345536
I1030 10:20:17.633031 10929 layer_factory.hpp:77] Creating layer BN2
I1030 10:20:17.633036 10929 net.cpp:84] Creating Layer BN2
I1030 10:20:17.633038 10929 net.cpp:406] BN2 <- conv2
I1030 10:20:17.633041 10929 net.cpp:367] BN2 -> conv2 (in-place)
I1030 10:20:17.633178 10929 net.cpp:122] Setting up BN2
I1030 10:20:17.633191 10929 net.cpp:129] Top shape: 128 64 32 32 (8388608)
I1030 10:20:17.633193 10929 net.cpp:137] Memory required for data: 202899968
I1030 10:20:17.633198 10929 layer_factory.hpp:77] Creating layer scale2
I1030 10:20:17.633200 10929 net.cpp:84] Creating Layer scale2
I1030 10:20:17.633203 10929 net.cpp:406] scale2 <- conv2
I1030 10:20:17.633205 10929 net.cpp:367] scale2 -> conv2 (in-place)
I1030 10:20:17.633239 10929 layer_factory.hpp:77] Creating layer scale2
I1030 10:20:17.633312 10929 net.cpp:122] Setting up scale2
I1030 10:20:17.633316 10929 net.cpp:129] Top shape: 128 64 32 32 (8388608)
I1030 10:20:17.633318 10929 net.cpp:137] Memory required for data: 236454400
I1030 10:20:17.633322 10929 layer_factory.hpp:77] Creating layer relu2
I1030 10:20:17.633324 10929 net.cpp:84] Creating Layer relu2
I1030 10:20:17.633327 10929 net.cpp:406] relu2 <- conv2
I1030 10:20:17.633328 10929 net.cpp:367] relu2 -> conv2 (in-place)
I1030 10:20:17.633479 10929 net.cpp:122] Setting up relu2
I1030 10:20:17.633484 10929 net.cpp:129] Top shape: 128 64 32 32 (8388608)
I1030 10:20:17.633500 10929 net.cpp:137] Memory required for data: 270008832
I1030 10:20:17.633502 10929 layer_factory.hpp:77] Creating layer pool2
I1030 10:20:17.633505 10929 net.cpp:84] Creating Layer pool2
I1030 10:20:17.633507 10929 net.cpp:406] pool2 <- conv2
I1030 10:20:17.633512 10929 net.cpp:380] pool2 -> pool2
I1030 10:20:17.633543 10929 net.cpp:122] Setting up pool2
I1030 10:20:17.633546 10929 net.cpp:129] Top shape: 128 64 16 16 (2097152)
I1030 10:20:17.633549 10929 net.cpp:137] Memory required for data: 278397440
I1030 10:20:17.633551 10929 layer_factory.hpp:77] Creating layer conv3
I1030 10:20:17.633555 10929 net.cpp:84] Creating Layer conv3
I1030 10:20:17.633556 10929 net.cpp:406] conv3 <- pool2
I1030 10:20:17.633560 10929 net.cpp:380] conv3 -> conv3
I1030 10:20:17.634899 10929 net.cpp:122] Setting up conv3
I1030 10:20:17.634907 10929 net.cpp:129] Top shape: 128 128 16 16 (4194304)
I1030 10:20:17.634909 10929 net.cpp:137] Memory required for data: 295174656
I1030 10:20:17.634912 10929 layer_factory.hpp:77] Creating layer BN3
I1030 10:20:17.634917 10929 net.cpp:84] Creating Layer BN3
I1030 10:20:17.634919 10929 net.cpp:406] BN3 <- conv3
I1030 10:20:17.634922 10929 net.cpp:367] BN3 -> conv3 (in-place)
I1030 10:20:17.635025 10929 net.cpp:122] Setting up BN3
I1030 10:20:17.635030 10929 net.cpp:129] Top shape: 128 128 16 16 (4194304)
I1030 10:20:17.635031 10929 net.cpp:137] Memory required for data: 311951872
I1030 10:20:17.635038 10929 layer_factory.hpp:77] Creating layer scale3
I1030 10:20:17.635041 10929 net.cpp:84] Creating Layer scale3
I1030 10:20:17.635042 10929 net.cpp:406] scale3 <- conv3
I1030 10:20:17.635046 10929 net.cpp:367] scale3 -> conv3 (in-place)
I1030 10:20:17.635066 10929 layer_factory.hpp:77] Creating layer scale3
I1030 10:20:17.635126 10929 net.cpp:122] Setting up scale3
I1030 10:20:17.635129 10929 net.cpp:129] Top shape: 128 128 16 16 (4194304)
I1030 10:20:17.635131 10929 net.cpp:137] Memory required for data: 328729088
I1030 10:20:17.635134 10929 layer_factory.hpp:77] Creating layer relu3
I1030 10:20:17.635138 10929 net.cpp:84] Creating Layer relu3
I1030 10:20:17.635138 10929 net.cpp:406] relu3 <- conv3
I1030 10:20:17.635143 10929 net.cpp:367] relu3 -> conv3 (in-place)
I1030 10:20:17.635246 10929 net.cpp:122] Setting up relu3
I1030 10:20:17.635251 10929 net.cpp:129] Top shape: 128 128 16 16 (4194304)
I1030 10:20:17.635252 10929 net.cpp:137] Memory required for data: 345506304
I1030 10:20:17.635254 10929 layer_factory.hpp:77] Creating layer conv4
I1030 10:20:17.635259 10929 net.cpp:84] Creating Layer conv4
I1030 10:20:17.635262 10929 net.cpp:406] conv4 <- conv3
I1030 10:20:17.635265 10929 net.cpp:380] conv4 -> conv4
I1030 10:20:17.637537 10929 net.cpp:122] Setting up conv4
I1030 10:20:17.637544 10929 net.cpp:129] Top shape: 128 128 16 16 (4194304)
I1030 10:20:17.637547 10929 net.cpp:137] Memory required for data: 362283520
I1030 10:20:17.637550 10929 layer_factory.hpp:77] Creating layer BN4
I1030 10:20:17.637554 10929 net.cpp:84] Creating Layer BN4
I1030 10:20:17.637564 10929 net.cpp:406] BN4 <- conv4
I1030 10:20:17.637568 10929 net.cpp:367] BN4 -> conv4 (in-place)
I1030 10:20:17.637676 10929 net.cpp:122] Setting up BN4
I1030 10:20:17.637679 10929 net.cpp:129] Top shape: 128 128 16 16 (4194304)
I1030 10:20:17.637681 10929 net.cpp:137] Memory required for data: 379060736
I1030 10:20:17.637686 10929 layer_factory.hpp:77] Creating layer scale4
I1030 10:20:17.637689 10929 net.cpp:84] Creating Layer scale4
I1030 10:20:17.637691 10929 net.cpp:406] scale4 <- conv4
I1030 10:20:17.637693 10929 net.cpp:367] scale4 -> conv4 (in-place)
I1030 10:20:17.637712 10929 layer_factory.hpp:77] Creating layer scale4
I1030 10:20:17.637799 10929 net.cpp:122] Setting up scale4
I1030 10:20:17.637804 10929 net.cpp:129] Top shape: 128 128 16 16 (4194304)
I1030 10:20:17.637805 10929 net.cpp:137] Memory required for data: 395837952
I1030 10:20:17.637809 10929 layer_factory.hpp:77] Creating layer relu4
I1030 10:20:17.637812 10929 net.cpp:84] Creating Layer relu4
I1030 10:20:17.637814 10929 net.cpp:406] relu4 <- conv4
I1030 10:20:17.637817 10929 net.cpp:367] relu4 -> conv4 (in-place)
I1030 10:20:17.637959 10929 net.cpp:122] Setting up relu4
I1030 10:20:17.637964 10929 net.cpp:129] Top shape: 128 128 16 16 (4194304)
I1030 10:20:17.637966 10929 net.cpp:137] Memory required for data: 412615168
I1030 10:20:17.637969 10929 layer_factory.hpp:77] Creating layer pool4
I1030 10:20:17.637984 10929 net.cpp:84] Creating Layer pool4
I1030 10:20:17.637986 10929 net.cpp:406] pool4 <- conv4
I1030 10:20:17.637989 10929 net.cpp:380] pool4 -> pool4
I1030 10:20:17.638011 10929 net.cpp:122] Setting up pool4
I1030 10:20:17.638015 10929 net.cpp:129] Top shape: 128 128 8 8 (1048576)
I1030 10:20:17.638017 10929 net.cpp:137] Memory required for data: 416809472
I1030 10:20:17.638020 10929 layer_factory.hpp:77] Creating layer conv5
I1030 10:20:17.638025 10929 net.cpp:84] Creating Layer conv5
I1030 10:20:17.638027 10929 net.cpp:406] conv5 <- pool4
I1030 10:20:17.638031 10929 net.cpp:380] conv5 -> conv5
I1030 10:20:17.640741 10929 net.cpp:122] Setting up conv5
I1030 10:20:17.640750 10929 net.cpp:129] Top shape: 128 256 8 8 (2097152)
I1030 10:20:17.640753 10929 net.cpp:137] Memory required for data: 425198080
I1030 10:20:17.640756 10929 layer_factory.hpp:77] Creating layer BN5
I1030 10:20:17.640763 10929 net.cpp:84] Creating Layer BN5
I1030 10:20:17.640764 10929 net.cpp:406] BN5 <- conv5
I1030 10:20:17.640767 10929 net.cpp:367] BN5 -> conv5 (in-place)
I1030 10:20:17.640882 10929 net.cpp:122] Setting up BN5
I1030 10:20:17.640887 10929 net.cpp:129] Top shape: 128 256 8 8 (2097152)
I1030 10:20:17.640889 10929 net.cpp:137] Memory required for data: 433586688
I1030 10:20:17.640895 10929 layer_factory.hpp:77] Creating layer scale5
I1030 10:20:17.640899 10929 net.cpp:84] Creating Layer scale5
I1030 10:20:17.640902 10929 net.cpp:406] scale5 <- conv5
I1030 10:20:17.640905 10929 net.cpp:367] scale5 -> conv5 (in-place)
I1030 10:20:17.640926 10929 layer_factory.hpp:77] Creating layer scale5
I1030 10:20:17.640990 10929 net.cpp:122] Setting up scale5
I1030 10:20:17.640995 10929 net.cpp:129] Top shape: 128 256 8 8 (2097152)
I1030 10:20:17.640996 10929 net.cpp:137] Memory required for data: 441975296
I1030 10:20:17.641000 10929 layer_factory.hpp:77] Creating layer relu5
I1030 10:20:17.641003 10929 net.cpp:84] Creating Layer relu5
I1030 10:20:17.641006 10929 net.cpp:406] relu5 <- conv5
I1030 10:20:17.641010 10929 net.cpp:367] relu5 -> conv5 (in-place)
I1030 10:20:17.641291 10929 net.cpp:122] Setting up relu5
I1030 10:20:17.641299 10929 net.cpp:129] Top shape: 128 256 8 8 (2097152)
I1030 10:20:17.641301 10929 net.cpp:137] Memory required for data: 450363904
I1030 10:20:17.641304 10929 layer_factory.hpp:77] Creating layer conv6
I1030 10:20:17.641309 10929 net.cpp:84] Creating Layer conv6
I1030 10:20:17.641312 10929 net.cpp:406] conv6 <- conv5
I1030 10:20:17.641317 10929 net.cpp:380] conv6 -> conv6
I1030 10:20:17.646545 10929 net.cpp:122] Setting up conv6
I1030 10:20:17.646561 10929 net.cpp:129] Top shape: 128 256 8 8 (2097152)
I1030 10:20:17.646595 10929 net.cpp:137] Memory required for data: 458752512
I1030 10:20:17.646603 10929 layer_factory.hpp:77] Creating layer BN6
I1030 10:20:17.646610 10929 net.cpp:84] Creating Layer BN6
I1030 10:20:17.646612 10929 net.cpp:406] BN6 <- conv6
I1030 10:20:17.646617 10929 net.cpp:367] BN6 -> conv6 (in-place)
I1030 10:20:17.646780 10929 net.cpp:122] Setting up BN6
I1030 10:20:17.646785 10929 net.cpp:129] Top shape: 128 256 8 8 (2097152)
I1030 10:20:17.646786 10929 net.cpp:137] Memory required for data: 467141120
I1030 10:20:17.646805 10929 layer_factory.hpp:77] Creating layer scale6
I1030 10:20:17.646809 10929 net.cpp:84] Creating Layer scale6
I1030 10:20:17.646811 10929 net.cpp:406] scale6 <- conv6
I1030 10:20:17.646814 10929 net.cpp:367] scale6 -> conv6 (in-place)
I1030 10:20:17.646836 10929 layer_factory.hpp:77] Creating layer scale6
I1030 10:20:17.646939 10929 net.cpp:122] Setting up scale6
I1030 10:20:17.646942 10929 net.cpp:129] Top shape: 128 256 8 8 (2097152)
I1030 10:20:17.646944 10929 net.cpp:137] Memory required for data: 475529728
I1030 10:20:17.646946 10929 layer_factory.hpp:77] Creating layer relu6
I1030 10:20:17.646950 10929 net.cpp:84] Creating Layer relu6
I1030 10:20:17.646952 10929 net.cpp:406] relu6 <- conv6
I1030 10:20:17.646955 10929 net.cpp:367] relu6 -> conv6 (in-place)
I1030 10:20:17.647263 10929 net.cpp:122] Setting up relu6
I1030 10:20:17.647270 10929 net.cpp:129] Top shape: 128 256 8 8 (2097152)
I1030 10:20:17.647272 10929 net.cpp:137] Memory required for data: 483918336
I1030 10:20:17.647274 10929 layer_factory.hpp:77] Creating layer conv7
I1030 10:20:17.647280 10929 net.cpp:84] Creating Layer conv7
I1030 10:20:17.647282 10929 net.cpp:406] conv7 <- conv6
I1030 10:20:17.647286 10929 net.cpp:380] conv7 -> conv7
I1030 10:20:17.652398 10929 net.cpp:122] Setting up conv7
I1030 10:20:17.652407 10929 net.cpp:129] Top shape: 128 256 8 8 (2097152)
I1030 10:20:17.652410 10929 net.cpp:137] Memory required for data: 492306944
I1030 10:20:17.652415 10929 layer_factory.hpp:77] Creating layer BN7
I1030 10:20:17.652417 10929 net.cpp:84] Creating Layer BN7
I1030 10:20:17.652420 10929 net.cpp:406] BN7 <- conv7
I1030 10:20:17.652423 10929 net.cpp:367] BN7 -> conv7 (in-place)
I1030 10:20:17.652568 10929 net.cpp:122] Setting up BN7
I1030 10:20:17.652573 10929 net.cpp:129] Top shape: 128 256 8 8 (2097152)
I1030 10:20:17.652575 10929 net.cpp:137] Memory required for data: 500695552
I1030 10:20:17.652578 10929 layer_factory.hpp:77] Creating layer scale7
I1030 10:20:17.652581 10929 net.cpp:84] Creating Layer scale7
I1030 10:20:17.652583 10929 net.cpp:406] scale7 <- conv7
I1030 10:20:17.652585 10929 net.cpp:367] scale7 -> conv7 (in-place)
I1030 10:20:17.652621 10929 layer_factory.hpp:77] Creating layer scale7
I1030 10:20:17.652699 10929 net.cpp:122] Setting up scale7
I1030 10:20:17.652704 10929 net.cpp:129] Top shape: 128 256 8 8 (2097152)
I1030 10:20:17.652705 10929 net.cpp:137] Memory required for data: 509084160
I1030 10:20:17.652709 10929 layer_factory.hpp:77] Creating layer relu7
I1030 10:20:17.652711 10929 net.cpp:84] Creating Layer relu7
I1030 10:20:17.652712 10929 net.cpp:406] relu7 <- conv7
I1030 10:20:17.652715 10929 net.cpp:367] relu7 -> conv7 (in-place)
I1030 10:20:17.652853 10929 net.cpp:122] Setting up relu7
I1030 10:20:17.652858 10929 net.cpp:129] Top shape: 128 256 8 8 (2097152)
I1030 10:20:17.652859 10929 net.cpp:137] Memory required for data: 517472768
I1030 10:20:17.652861 10929 layer_factory.hpp:77] Creating layer pool7
I1030 10:20:17.652865 10929 net.cpp:84] Creating Layer pool7
I1030 10:20:17.652866 10929 net.cpp:406] pool7 <- conv7
I1030 10:20:17.652869 10929 net.cpp:380] pool7 -> pool7
I1030 10:20:17.652907 10929 net.cpp:122] Setting up pool7
I1030 10:20:17.652911 10929 net.cpp:129] Top shape: 128 256 4 4 (524288)
I1030 10:20:17.652914 10929 net.cpp:137] Memory required for data: 519569920
I1030 10:20:17.652915 10929 layer_factory.hpp:77] Creating layer fc65
I1030 10:20:17.652921 10929 net.cpp:84] Creating Layer fc65
I1030 10:20:17.652925 10929 net.cpp:406] fc65 <- pool7
I1030 10:20:17.652947 10929 net.cpp:380] fc65 -> fc65
I1030 10:20:17.663002 10929 net.cpp:122] Setting up fc65
I1030 10:20:17.663022 10929 net.cpp:129] Top shape: 128 256 (32768)
I1030 10:20:17.663023 10929 net.cpp:137] Memory required for data: 519700992
I1030 10:20:17.663030 10929 layer_factory.hpp:77] Creating layer relu65
I1030 10:20:17.663036 10929 net.cpp:84] Creating Layer relu65
I1030 10:20:17.663038 10929 net.cpp:406] relu65 <- fc65
I1030 10:20:17.663043 10929 net.cpp:367] relu65 -> fc65 (in-place)
I1030 10:20:17.663211 10929 net.cpp:122] Setting up relu65
I1030 10:20:17.663216 10929 net.cpp:129] Top shape: 128 256 (32768)
I1030 10:20:17.663218 10929 net.cpp:137] Memory required for data: 519832064
I1030 10:20:17.663219 10929 layer_factory.hpp:77] Creating layer drop65
I1030 10:20:17.663223 10929 net.cpp:84] Creating Layer drop65
I1030 10:20:17.663225 10929 net.cpp:406] drop65 <- fc65
I1030 10:20:17.663228 10929 net.cpp:367] drop65 -> fc65 (in-place)
I1030 10:20:17.663245 10929 net.cpp:122] Setting up drop65
I1030 10:20:17.663249 10929 net.cpp:129] Top shape: 128 256 (32768)
I1030 10:20:17.663249 10929 net.cpp:137] Memory required for data: 519963136
I1030 10:20:17.663250 10929 layer_factory.hpp:77] Creating layer fc66
I1030 10:20:17.663256 10929 net.cpp:84] Creating Layer fc66
I1030 10:20:17.663259 10929 net.cpp:406] fc66 <- fc65
I1030 10:20:17.663262 10929 net.cpp:380] fc66 -> fc66
I1030 10:20:17.663734 10929 net.cpp:122] Setting up fc66
I1030 10:20:17.663738 10929 net.cpp:129] Top shape: 128 256 (32768)
I1030 10:20:17.663740 10929 net.cpp:137] Memory required for data: 520094208
I1030 10:20:17.663743 10929 layer_factory.hpp:77] Creating layer relu66
I1030 10:20:17.663745 10929 net.cpp:84] Creating Layer relu66
I1030 10:20:17.663748 10929 net.cpp:406] relu66 <- fc66
I1030 10:20:17.663750 10929 net.cpp:367] relu66 -> fc66 (in-place)
I1030 10:20:17.663861 10929 net.cpp:122] Setting up relu66
I1030 10:20:17.663864 10929 net.cpp:129] Top shape: 128 256 (32768)
I1030 10:20:17.663866 10929 net.cpp:137] Memory required for data: 520225280
I1030 10:20:17.663868 10929 layer_factory.hpp:77] Creating layer drop66
I1030 10:20:17.663871 10929 net.cpp:84] Creating Layer drop66
I1030 10:20:17.663872 10929 net.cpp:406] drop66 <- fc66
I1030 10:20:17.663875 10929 net.cpp:367] drop66 -> fc66 (in-place)
I1030 10:20:17.663887 10929 net.cpp:122] Setting up drop66
I1030 10:20:17.663889 10929 net.cpp:129] Top shape: 128 256 (32768)
I1030 10:20:17.663890 10929 net.cpp:137] Memory required for data: 520356352
I1030 10:20:17.663892 10929 layer_factory.hpp:77] Creating layer fc100
I1030 10:20:17.663897 10929 net.cpp:84] Creating Layer fc100
I1030 10:20:17.663898 10929 net.cpp:406] fc100 <- fc66
I1030 10:20:17.663900 10929 net.cpp:380] fc100 -> fc100
I1030 10:20:17.664657 10929 net.cpp:122] Setting up fc100
I1030 10:20:17.664664 10929 net.cpp:129] Top shape: 128 62 (7936)
I1030 10:20:17.664666 10929 net.cpp:137] Memory required for data: 520388096
I1030 10:20:17.664670 10929 layer_factory.hpp:77] Creating layer loss
I1030 10:20:17.664674 10929 net.cpp:84] Creating Layer loss
I1030 10:20:17.664676 10929 net.cpp:406] loss <- fc100
I1030 10:20:17.664679 10929 net.cpp:406] loss <- label
I1030 10:20:17.664683 10929 net.cpp:380] loss -> loss
I1030 10:20:17.664690 10929 layer_factory.hpp:77] Creating layer loss
I1030 10:20:17.665060 10929 net.cpp:122] Setting up loss
I1030 10:20:17.665066 10929 net.cpp:129] Top shape: (1)
I1030 10:20:17.665068 10929 net.cpp:132]     with loss weight 1
I1030 10:20:17.665086 10929 net.cpp:137] Memory required for data: 520388100
I1030 10:20:17.665087 10929 net.cpp:198] loss needs backward computation.
I1030 10:20:17.665091 10929 net.cpp:198] fc100 needs backward computation.
I1030 10:20:17.665094 10929 net.cpp:198] drop66 needs backward computation.
I1030 10:20:17.665096 10929 net.cpp:198] relu66 needs backward computation.
I1030 10:20:17.665097 10929 net.cpp:198] fc66 needs backward computation.
I1030 10:20:17.665098 10929 net.cpp:198] drop65 needs backward computation.
I1030 10:20:17.665100 10929 net.cpp:198] relu65 needs backward computation.
I1030 10:20:17.665112 10929 net.cpp:198] fc65 needs backward computation.
I1030 10:20:17.665113 10929 net.cpp:198] pool7 needs backward computation.
I1030 10:20:17.665115 10929 net.cpp:198] relu7 needs backward computation.
I1030 10:20:17.665117 10929 net.cpp:198] scale7 needs backward computation.
I1030 10:20:17.665120 10929 net.cpp:198] BN7 needs backward computation.
I1030 10:20:17.665122 10929 net.cpp:198] conv7 needs backward computation.
I1030 10:20:17.665124 10929 net.cpp:198] relu6 needs backward computation.
I1030 10:20:17.665125 10929 net.cpp:198] scale6 needs backward computation.
I1030 10:20:17.665128 10929 net.cpp:198] BN6 needs backward computation.
I1030 10:20:17.665129 10929 net.cpp:198] conv6 needs backward computation.
I1030 10:20:17.665132 10929 net.cpp:198] relu5 needs backward computation.
I1030 10:20:17.665132 10929 net.cpp:198] scale5 needs backward computation.
I1030 10:20:17.665134 10929 net.cpp:198] BN5 needs backward computation.
I1030 10:20:17.665136 10929 net.cpp:198] conv5 needs backward computation.
I1030 10:20:17.665138 10929 net.cpp:198] pool4 needs backward computation.
I1030 10:20:17.665154 10929 net.cpp:198] relu4 needs backward computation.
I1030 10:20:17.665156 10929 net.cpp:198] scale4 needs backward computation.
I1030 10:20:17.665158 10929 net.cpp:198] BN4 needs backward computation.
I1030 10:20:17.665159 10929 net.cpp:198] conv4 needs backward computation.
I1030 10:20:17.665161 10929 net.cpp:198] relu3 needs backward computation.
I1030 10:20:17.665163 10929 net.cpp:198] scale3 needs backward computation.
I1030 10:20:17.665165 10929 net.cpp:198] BN3 needs backward computation.
I1030 10:20:17.665166 10929 net.cpp:198] conv3 needs backward computation.
I1030 10:20:17.665169 10929 net.cpp:198] pool2 needs backward computation.
I1030 10:20:17.665171 10929 net.cpp:198] relu2 needs backward computation.
I1030 10:20:17.665189 10929 net.cpp:198] scale2 needs backward computation.
I1030 10:20:17.665189 10929 net.cpp:198] BN2 needs backward computation.
I1030 10:20:17.665191 10929 net.cpp:198] conv2 needs backward computation.
I1030 10:20:17.665194 10929 net.cpp:198] relu1 needs backward computation.
I1030 10:20:17.665194 10929 net.cpp:198] scale1 needs backward computation.
I1030 10:20:17.665196 10929 net.cpp:198] BN1 needs backward computation.
I1030 10:20:17.665199 10929 net.cpp:198] conv1 needs backward computation.
I1030 10:20:17.665223 10929 net.cpp:200] face does not need backward computation.
I1030 10:20:17.665225 10929 net.cpp:242] This network produces output loss
I1030 10:20:17.665237 10929 net.cpp:255] Network initialization done.
I1030 10:20:17.665468 10929 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/ljf/caffe-master/examples/ljftest_alphabet_VggNet/test.prototxt
I1030 10:20:17.665474 10929 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1030 10:20:17.665477 10929 solver.cpp:172] Creating test net (#0) specified by test_net file: /home/ljf/caffe-master/examples/ljftest_alphabet_VggNet/test.prototxt
I1030 10:20:17.665632 10929 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "face"
  type: "Data"
  top: "data"
  top: "label"
  data_param {
    source: "/home/ljf/caffe-master/examples/ljftest_alphabet_VggNet/val_lmdb"
    batch_size: 100
    backend: LMDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BN1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "BN2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BN3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BN4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BN5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BN6"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "conv6"
  top: "conv6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BN7"
  type: "BatchNorm"
  bottom: "conv7"
  top: "conv7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "conv7"
  top: "conv7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "conv7"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "fc65"
  type: "InnerProduct"
  bottom: "pool7"
  top: "fc65"
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.00390625
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu65"
  type: "ReLU"
  bottom: "fc65"
  top: "fc65"
}
layer {
  name: "drop65"
  type: "Dropout"
  bottom: "fc65"
  top: "fc65"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "fc66"
  type: "InnerProduct"
  bottom: "fc65"
  top: "fc66"
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.00390625
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu66"
  type: "ReLU"
  bottom: "fc66"
  top: "fc66"
}
layer {
  name: "drop66"
  type: "Dropout"
  bottom: "fc66"
  top: "fc66"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc100"
  type: "InnerProduct"
  bottom: "fc66"
  top: "fc100"
  inner_product_param {
    num_output: 62
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc100"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc"
  type: "Accuracy"
  bottom: "fc100"
  bottom: "label"
  top: "acc"
}
I1030 10:20:17.665732 10929 layer_factory.hpp:77] Creating layer face
I1030 10:20:17.665769 10929 db_lmdb.cpp:35] Opened lmdb /home/ljf/caffe-master/examples/ljftest_alphabet_VggNet/val_lmdb
I1030 10:20:17.665781 10929 net.cpp:84] Creating Layer face
I1030 10:20:17.665783 10929 net.cpp:380] face -> data
I1030 10:20:17.665787 10929 net.cpp:380] face -> label
I1030 10:20:17.665858 10929 data_layer.cpp:45] output data size: 100,3,32,32
I1030 10:20:17.669591 10929 net.cpp:122] Setting up face
I1030 10:20:17.669611 10929 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1030 10:20:17.669615 10929 net.cpp:129] Top shape: 100 (100)
I1030 10:20:17.669616 10929 net.cpp:137] Memory required for data: 1229200
I1030 10:20:17.669622 10929 layer_factory.hpp:77] Creating layer label_face_1_split
I1030 10:20:17.669633 10929 net.cpp:84] Creating Layer label_face_1_split
I1030 10:20:17.669636 10929 net.cpp:406] label_face_1_split <- label
I1030 10:20:17.669642 10929 net.cpp:380] label_face_1_split -> label_face_1_split_0
I1030 10:20:17.669649 10929 net.cpp:380] label_face_1_split -> label_face_1_split_1
I1030 10:20:17.669703 10929 net.cpp:122] Setting up label_face_1_split
I1030 10:20:17.669723 10929 net.cpp:129] Top shape: 100 (100)
I1030 10:20:17.669724 10929 net.cpp:129] Top shape: 100 (100)
I1030 10:20:17.669735 10929 net.cpp:137] Memory required for data: 1230000
I1030 10:20:17.669737 10929 layer_factory.hpp:77] Creating layer conv1
I1030 10:20:17.669745 10929 net.cpp:84] Creating Layer conv1
I1030 10:20:17.669749 10929 net.cpp:406] conv1 <- data
I1030 10:20:17.669752 10929 net.cpp:380] conv1 -> conv1
I1030 10:20:17.670691 10929 net.cpp:122] Setting up conv1
I1030 10:20:17.670699 10929 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I1030 10:20:17.670702 10929 net.cpp:137] Memory required for data: 27444400
I1030 10:20:17.670708 10929 layer_factory.hpp:77] Creating layer BN1
I1030 10:20:17.670713 10929 net.cpp:84] Creating Layer BN1
I1030 10:20:17.670716 10929 net.cpp:406] BN1 <- conv1
I1030 10:20:17.670719 10929 net.cpp:367] BN1 -> conv1 (in-place)
I1030 10:20:17.670976 10929 net.cpp:122] Setting up BN1
I1030 10:20:17.670980 10929 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I1030 10:20:17.670982 10929 net.cpp:137] Memory required for data: 53658800
I1030 10:20:17.670989 10929 layer_factory.hpp:77] Creating layer scale1
I1030 10:20:17.670994 10929 net.cpp:84] Creating Layer scale1
I1030 10:20:17.670995 10929 net.cpp:406] scale1 <- conv1
I1030 10:20:17.670999 10929 net.cpp:367] scale1 -> conv1 (in-place)
I1030 10:20:17.671026 10929 layer_factory.hpp:77] Creating layer scale1
I1030 10:20:17.671140 10929 net.cpp:122] Setting up scale1
I1030 10:20:17.671144 10929 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I1030 10:20:17.671164 10929 net.cpp:137] Memory required for data: 79873200
I1030 10:20:17.671167 10929 layer_factory.hpp:77] Creating layer relu1
I1030 10:20:17.671174 10929 net.cpp:84] Creating Layer relu1
I1030 10:20:17.671175 10929 net.cpp:406] relu1 <- conv1
I1030 10:20:17.671178 10929 net.cpp:367] relu1 -> conv1 (in-place)
I1030 10:20:17.671305 10929 net.cpp:122] Setting up relu1
I1030 10:20:17.671310 10929 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I1030 10:20:17.671326 10929 net.cpp:137] Memory required for data: 106087600
I1030 10:20:17.671329 10929 layer_factory.hpp:77] Creating layer conv2
I1030 10:20:17.671334 10929 net.cpp:84] Creating Layer conv2
I1030 10:20:17.671336 10929 net.cpp:406] conv2 <- conv1
I1030 10:20:17.671342 10929 net.cpp:380] conv2 -> conv2
I1030 10:20:17.672467 10929 net.cpp:122] Setting up conv2
I1030 10:20:17.672475 10929 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I1030 10:20:17.672492 10929 net.cpp:137] Memory required for data: 132302000
I1030 10:20:17.672497 10929 layer_factory.hpp:77] Creating layer BN2
I1030 10:20:17.672502 10929 net.cpp:84] Creating Layer BN2
I1030 10:20:17.672504 10929 net.cpp:406] BN2 <- conv2
I1030 10:20:17.672508 10929 net.cpp:367] BN2 -> conv2 (in-place)
I1030 10:20:17.672669 10929 net.cpp:122] Setting up BN2
I1030 10:20:17.672673 10929 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I1030 10:20:17.672675 10929 net.cpp:137] Memory required for data: 158516400
I1030 10:20:17.672679 10929 layer_factory.hpp:77] Creating layer scale2
I1030 10:20:17.672683 10929 net.cpp:84] Creating Layer scale2
I1030 10:20:17.672684 10929 net.cpp:406] scale2 <- conv2
I1030 10:20:17.672688 10929 net.cpp:367] scale2 -> conv2 (in-place)
I1030 10:20:17.672729 10929 layer_factory.hpp:77] Creating layer scale2
I1030 10:20:17.672842 10929 net.cpp:122] Setting up scale2
I1030 10:20:17.672847 10929 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I1030 10:20:17.672848 10929 net.cpp:137] Memory required for data: 184730800
I1030 10:20:17.672868 10929 layer_factory.hpp:77] Creating layer relu2
I1030 10:20:17.672871 10929 net.cpp:84] Creating Layer relu2
I1030 10:20:17.672873 10929 net.cpp:406] relu2 <- conv2
I1030 10:20:17.672878 10929 net.cpp:367] relu2 -> conv2 (in-place)
I1030 10:20:17.672998 10929 net.cpp:122] Setting up relu2
I1030 10:20:17.673003 10929 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I1030 10:20:17.673005 10929 net.cpp:137] Memory required for data: 210945200
I1030 10:20:17.673022 10929 layer_factory.hpp:77] Creating layer pool2
I1030 10:20:17.673025 10929 net.cpp:84] Creating Layer pool2
I1030 10:20:17.673028 10929 net.cpp:406] pool2 <- conv2
I1030 10:20:17.673039 10929 net.cpp:380] pool2 -> pool2
I1030 10:20:17.673096 10929 net.cpp:122] Setting up pool2
I1030 10:20:17.673100 10929 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I1030 10:20:17.673105 10929 net.cpp:137] Memory required for data: 217498800
I1030 10:20:17.673106 10929 layer_factory.hpp:77] Creating layer conv3
I1030 10:20:17.673113 10929 net.cpp:84] Creating Layer conv3
I1030 10:20:17.673115 10929 net.cpp:406] conv3 <- pool2
I1030 10:20:17.673120 10929 net.cpp:380] conv3 -> conv3
I1030 10:20:17.674515 10929 net.cpp:122] Setting up conv3
I1030 10:20:17.674523 10929 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I1030 10:20:17.674525 10929 net.cpp:137] Memory required for data: 230606000
I1030 10:20:17.674530 10929 layer_factory.hpp:77] Creating layer BN3
I1030 10:20:17.674533 10929 net.cpp:84] Creating Layer BN3
I1030 10:20:17.674536 10929 net.cpp:406] BN3 <- conv3
I1030 10:20:17.674540 10929 net.cpp:367] BN3 -> conv3 (in-place)
I1030 10:20:17.674748 10929 net.cpp:122] Setting up BN3
I1030 10:20:17.674753 10929 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I1030 10:20:17.674757 10929 net.cpp:137] Memory required for data: 243713200
I1030 10:20:17.674762 10929 layer_factory.hpp:77] Creating layer scale3
I1030 10:20:17.674767 10929 net.cpp:84] Creating Layer scale3
I1030 10:20:17.674770 10929 net.cpp:406] scale3 <- conv3
I1030 10:20:17.674773 10929 net.cpp:367] scale3 -> conv3 (in-place)
I1030 10:20:17.674801 10929 layer_factory.hpp:77] Creating layer scale3
I1030 10:20:17.674870 10929 net.cpp:122] Setting up scale3
I1030 10:20:17.674873 10929 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I1030 10:20:17.674876 10929 net.cpp:137] Memory required for data: 256820400
I1030 10:20:17.674880 10929 layer_factory.hpp:77] Creating layer relu3
I1030 10:20:17.674882 10929 net.cpp:84] Creating Layer relu3
I1030 10:20:17.674885 10929 net.cpp:406] relu3 <- conv3
I1030 10:20:17.674887 10929 net.cpp:367] relu3 -> conv3 (in-place)
I1030 10:20:17.675004 10929 net.cpp:122] Setting up relu3
I1030 10:20:17.675010 10929 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I1030 10:20:17.675011 10929 net.cpp:137] Memory required for data: 269927600
I1030 10:20:17.675014 10929 layer_factory.hpp:77] Creating layer conv4
I1030 10:20:17.675019 10929 net.cpp:84] Creating Layer conv4
I1030 10:20:17.675022 10929 net.cpp:406] conv4 <- conv3
I1030 10:20:17.675025 10929 net.cpp:380] conv4 -> conv4
I1030 10:20:17.676843 10929 net.cpp:122] Setting up conv4
I1030 10:20:17.676852 10929 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I1030 10:20:17.676854 10929 net.cpp:137] Memory required for data: 283034800
I1030 10:20:17.676858 10929 layer_factory.hpp:77] Creating layer BN4
I1030 10:20:17.676864 10929 net.cpp:84] Creating Layer BN4
I1030 10:20:17.676867 10929 net.cpp:406] BN4 <- conv4
I1030 10:20:17.676870 10929 net.cpp:367] BN4 -> conv4 (in-place)
I1030 10:20:17.676992 10929 net.cpp:122] Setting up BN4
I1030 10:20:17.676997 10929 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I1030 10:20:17.676998 10929 net.cpp:137] Memory required for data: 296142000
I1030 10:20:17.677002 10929 layer_factory.hpp:77] Creating layer scale4
I1030 10:20:17.677006 10929 net.cpp:84] Creating Layer scale4
I1030 10:20:17.677007 10929 net.cpp:406] scale4 <- conv4
I1030 10:20:17.677011 10929 net.cpp:367] scale4 -> conv4 (in-place)
I1030 10:20:17.677036 10929 layer_factory.hpp:77] Creating layer scale4
I1030 10:20:17.677104 10929 net.cpp:122] Setting up scale4
I1030 10:20:17.677109 10929 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I1030 10:20:17.677110 10929 net.cpp:137] Memory required for data: 309249200
I1030 10:20:17.677114 10929 layer_factory.hpp:77] Creating layer relu4
I1030 10:20:17.677117 10929 net.cpp:84] Creating Layer relu4
I1030 10:20:17.677119 10929 net.cpp:406] relu4 <- conv4
I1030 10:20:17.677121 10929 net.cpp:367] relu4 -> conv4 (in-place)
I1030 10:20:17.677248 10929 net.cpp:122] Setting up relu4
I1030 10:20:17.677254 10929 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I1030 10:20:17.677269 10929 net.cpp:137] Memory required for data: 322356400
I1030 10:20:17.677278 10929 layer_factory.hpp:77] Creating layer pool4
I1030 10:20:17.677283 10929 net.cpp:84] Creating Layer pool4
I1030 10:20:17.677284 10929 net.cpp:406] pool4 <- conv4
I1030 10:20:17.677287 10929 net.cpp:380] pool4 -> pool4
I1030 10:20:17.677311 10929 net.cpp:122] Setting up pool4
I1030 10:20:17.677315 10929 net.cpp:129] Top shape: 100 128 8 8 (819200)
I1030 10:20:17.677317 10929 net.cpp:137] Memory required for data: 325633200
I1030 10:20:17.677320 10929 layer_factory.hpp:77] Creating layer conv5
I1030 10:20:17.677325 10929 net.cpp:84] Creating Layer conv5
I1030 10:20:17.677327 10929 net.cpp:406] conv5 <- pool4
I1030 10:20:17.677330 10929 net.cpp:380] conv5 -> conv5
I1030 10:20:17.680613 10929 net.cpp:122] Setting up conv5
I1030 10:20:17.680622 10929 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I1030 10:20:17.680625 10929 net.cpp:137] Memory required for data: 332186800
I1030 10:20:17.680629 10929 layer_factory.hpp:77] Creating layer BN5
I1030 10:20:17.680634 10929 net.cpp:84] Creating Layer BN5
I1030 10:20:17.680636 10929 net.cpp:406] BN5 <- conv5
I1030 10:20:17.680640 10929 net.cpp:367] BN5 -> conv5 (in-place)
I1030 10:20:17.680770 10929 net.cpp:122] Setting up BN5
I1030 10:20:17.680774 10929 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I1030 10:20:17.680776 10929 net.cpp:137] Memory required for data: 338740400
I1030 10:20:17.680783 10929 layer_factory.hpp:77] Creating layer scale5
I1030 10:20:17.680788 10929 net.cpp:84] Creating Layer scale5
I1030 10:20:17.680789 10929 net.cpp:406] scale5 <- conv5
I1030 10:20:17.680793 10929 net.cpp:367] scale5 -> conv5 (in-place)
I1030 10:20:17.680819 10929 layer_factory.hpp:77] Creating layer scale5
I1030 10:20:17.680889 10929 net.cpp:122] Setting up scale5
I1030 10:20:17.680893 10929 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I1030 10:20:17.680896 10929 net.cpp:137] Memory required for data: 345294000
I1030 10:20:17.680898 10929 layer_factory.hpp:77] Creating layer relu5
I1030 10:20:17.680902 10929 net.cpp:84] Creating Layer relu5
I1030 10:20:17.680904 10929 net.cpp:406] relu5 <- conv5
I1030 10:20:17.680907 10929 net.cpp:367] relu5 -> conv5 (in-place)
I1030 10:20:17.681213 10929 net.cpp:122] Setting up relu5
I1030 10:20:17.681221 10929 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I1030 10:20:17.681236 10929 net.cpp:137] Memory required for data: 351847600
I1030 10:20:17.681237 10929 layer_factory.hpp:77] Creating layer conv6
I1030 10:20:17.681242 10929 net.cpp:84] Creating Layer conv6
I1030 10:20:17.681246 10929 net.cpp:406] conv6 <- conv5
I1030 10:20:17.681251 10929 net.cpp:380] conv6 -> conv6
I1030 10:20:17.686203 10929 net.cpp:122] Setting up conv6
I1030 10:20:17.686211 10929 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I1030 10:20:17.686213 10929 net.cpp:137] Memory required for data: 358401200
I1030 10:20:17.686218 10929 layer_factory.hpp:77] Creating layer BN6
I1030 10:20:17.686223 10929 net.cpp:84] Creating Layer BN6
I1030 10:20:17.686224 10929 net.cpp:406] BN6 <- conv6
I1030 10:20:17.686228 10929 net.cpp:367] BN6 -> conv6 (in-place)
I1030 10:20:17.686367 10929 net.cpp:122] Setting up BN6
I1030 10:20:17.686372 10929 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I1030 10:20:17.686373 10929 net.cpp:137] Memory required for data: 364954800
I1030 10:20:17.686391 10929 layer_factory.hpp:77] Creating layer scale6
I1030 10:20:17.686395 10929 net.cpp:84] Creating Layer scale6
I1030 10:20:17.686396 10929 net.cpp:406] scale6 <- conv6
I1030 10:20:17.686399 10929 net.cpp:367] scale6 -> conv6 (in-place)
I1030 10:20:17.686425 10929 layer_factory.hpp:77] Creating layer scale6
I1030 10:20:17.686496 10929 net.cpp:122] Setting up scale6
I1030 10:20:17.686499 10929 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I1030 10:20:17.686501 10929 net.cpp:137] Memory required for data: 371508400
I1030 10:20:17.686504 10929 layer_factory.hpp:77] Creating layer relu6
I1030 10:20:17.686507 10929 net.cpp:84] Creating Layer relu6
I1030 10:20:17.686509 10929 net.cpp:406] relu6 <- conv6
I1030 10:20:17.686511 10929 net.cpp:367] relu6 -> conv6 (in-place)
I1030 10:20:17.686818 10929 net.cpp:122] Setting up relu6
I1030 10:20:17.686825 10929 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I1030 10:20:17.686841 10929 net.cpp:137] Memory required for data: 378062000
I1030 10:20:17.686843 10929 layer_factory.hpp:77] Creating layer conv7
I1030 10:20:17.686849 10929 net.cpp:84] Creating Layer conv7
I1030 10:20:17.686851 10929 net.cpp:406] conv7 <- conv6
I1030 10:20:17.686856 10929 net.cpp:380] conv7 -> conv7
I1030 10:20:17.692004 10929 net.cpp:122] Setting up conv7
I1030 10:20:17.692028 10929 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I1030 10:20:17.692030 10929 net.cpp:137] Memory required for data: 384615600
I1030 10:20:17.692034 10929 layer_factory.hpp:77] Creating layer BN7
I1030 10:20:17.692039 10929 net.cpp:84] Creating Layer BN7
I1030 10:20:17.692041 10929 net.cpp:406] BN7 <- conv7
I1030 10:20:17.692045 10929 net.cpp:367] BN7 -> conv7 (in-place)
I1030 10:20:17.692190 10929 net.cpp:122] Setting up BN7
I1030 10:20:17.692194 10929 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I1030 10:20:17.692210 10929 net.cpp:137] Memory required for data: 391169200
I1030 10:20:17.692214 10929 layer_factory.hpp:77] Creating layer scale7
I1030 10:20:17.692219 10929 net.cpp:84] Creating Layer scale7
I1030 10:20:17.692219 10929 net.cpp:406] scale7 <- conv7
I1030 10:20:17.692222 10929 net.cpp:367] scale7 -> conv7 (in-place)
I1030 10:20:17.692250 10929 layer_factory.hpp:77] Creating layer scale7
I1030 10:20:17.692322 10929 net.cpp:122] Setting up scale7
I1030 10:20:17.692327 10929 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I1030 10:20:17.692328 10929 net.cpp:137] Memory required for data: 397722800
I1030 10:20:17.692332 10929 layer_factory.hpp:77] Creating layer relu7
I1030 10:20:17.692334 10929 net.cpp:84] Creating Layer relu7
I1030 10:20:17.692335 10929 net.cpp:406] relu7 <- conv7
I1030 10:20:17.692338 10929 net.cpp:367] relu7 -> conv7 (in-place)
I1030 10:20:17.692466 10929 net.cpp:122] Setting up relu7
I1030 10:20:17.692469 10929 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I1030 10:20:17.692471 10929 net.cpp:137] Memory required for data: 404276400
I1030 10:20:17.692472 10929 layer_factory.hpp:77] Creating layer pool7
I1030 10:20:17.692494 10929 net.cpp:84] Creating Layer pool7
I1030 10:20:17.692497 10929 net.cpp:406] pool7 <- conv7
I1030 10:20:17.692499 10929 net.cpp:380] pool7 -> pool7
I1030 10:20:17.692528 10929 net.cpp:122] Setting up pool7
I1030 10:20:17.692531 10929 net.cpp:129] Top shape: 100 256 4 4 (409600)
I1030 10:20:17.692533 10929 net.cpp:137] Memory required for data: 405914800
I1030 10:20:17.692534 10929 layer_factory.hpp:77] Creating layer fc65
I1030 10:20:17.692538 10929 net.cpp:84] Creating Layer fc65
I1030 10:20:17.692540 10929 net.cpp:406] fc65 <- pool7
I1030 10:20:17.692543 10929 net.cpp:380] fc65 -> fc65
I1030 10:20:17.702268 10929 net.cpp:122] Setting up fc65
I1030 10:20:17.702294 10929 net.cpp:129] Top shape: 100 256 (25600)
I1030 10:20:17.702296 10929 net.cpp:137] Memory required for data: 406017200
I1030 10:20:17.702304 10929 layer_factory.hpp:77] Creating layer relu65
I1030 10:20:17.702311 10929 net.cpp:84] Creating Layer relu65
I1030 10:20:17.702313 10929 net.cpp:406] relu65 <- fc65
I1030 10:20:17.702317 10929 net.cpp:367] relu65 -> fc65 (in-place)
I1030 10:20:17.702512 10929 net.cpp:122] Setting up relu65
I1030 10:20:17.702517 10929 net.cpp:129] Top shape: 100 256 (25600)
I1030 10:20:17.702519 10929 net.cpp:137] Memory required for data: 406119600
I1030 10:20:17.702522 10929 layer_factory.hpp:77] Creating layer drop65
I1030 10:20:17.702525 10929 net.cpp:84] Creating Layer drop65
I1030 10:20:17.702527 10929 net.cpp:406] drop65 <- fc65
I1030 10:20:17.702530 10929 net.cpp:367] drop65 -> fc65 (in-place)
I1030 10:20:17.702582 10929 net.cpp:122] Setting up drop65
I1030 10:20:17.702585 10929 net.cpp:129] Top shape: 100 256 (25600)
I1030 10:20:17.702586 10929 net.cpp:137] Memory required for data: 406222000
I1030 10:20:17.702589 10929 layer_factory.hpp:77] Creating layer fc66
I1030 10:20:17.702605 10929 net.cpp:84] Creating Layer fc66
I1030 10:20:17.702607 10929 net.cpp:406] fc66 <- fc65
I1030 10:20:17.702639 10929 net.cpp:380] fc66 -> fc66
I1030 10:20:17.703179 10929 net.cpp:122] Setting up fc66
I1030 10:20:17.703186 10929 net.cpp:129] Top shape: 100 256 (25600)
I1030 10:20:17.703186 10929 net.cpp:137] Memory required for data: 406324400
I1030 10:20:17.703204 10929 layer_factory.hpp:77] Creating layer relu66
I1030 10:20:17.703208 10929 net.cpp:84] Creating Layer relu66
I1030 10:20:17.703210 10929 net.cpp:406] relu66 <- fc66
I1030 10:20:17.703212 10929 net.cpp:367] relu66 -> fc66 (in-place)
I1030 10:20:17.703341 10929 net.cpp:122] Setting up relu66
I1030 10:20:17.703346 10929 net.cpp:129] Top shape: 100 256 (25600)
I1030 10:20:17.703359 10929 net.cpp:137] Memory required for data: 406426800
I1030 10:20:17.703361 10929 layer_factory.hpp:77] Creating layer drop66
I1030 10:20:17.703364 10929 net.cpp:84] Creating Layer drop66
I1030 10:20:17.703366 10929 net.cpp:406] drop66 <- fc66
I1030 10:20:17.703371 10929 net.cpp:367] drop66 -> fc66 (in-place)
I1030 10:20:17.703388 10929 net.cpp:122] Setting up drop66
I1030 10:20:17.703392 10929 net.cpp:129] Top shape: 100 256 (25600)
I1030 10:20:17.703392 10929 net.cpp:137] Memory required for data: 406529200
I1030 10:20:17.703394 10929 layer_factory.hpp:77] Creating layer fc100
I1030 10:20:17.703411 10929 net.cpp:84] Creating Layer fc100
I1030 10:20:17.703413 10929 net.cpp:406] fc100 <- fc66
I1030 10:20:17.703416 10929 net.cpp:380] fc100 -> fc100
I1030 10:20:17.703678 10929 net.cpp:122] Setting up fc100
I1030 10:20:17.703682 10929 net.cpp:129] Top shape: 100 62 (6200)
I1030 10:20:17.703683 10929 net.cpp:137] Memory required for data: 406554000
I1030 10:20:17.703686 10929 layer_factory.hpp:77] Creating layer fc100_fc100_0_split
I1030 10:20:17.703691 10929 net.cpp:84] Creating Layer fc100_fc100_0_split
I1030 10:20:17.703693 10929 net.cpp:406] fc100_fc100_0_split <- fc100
I1030 10:20:17.703696 10929 net.cpp:380] fc100_fc100_0_split -> fc100_fc100_0_split_0
I1030 10:20:17.703701 10929 net.cpp:380] fc100_fc100_0_split -> fc100_fc100_0_split_1
I1030 10:20:17.703753 10929 net.cpp:122] Setting up fc100_fc100_0_split
I1030 10:20:17.703757 10929 net.cpp:129] Top shape: 100 62 (6200)
I1030 10:20:17.703758 10929 net.cpp:129] Top shape: 100 62 (6200)
I1030 10:20:17.703759 10929 net.cpp:137] Memory required for data: 406603600
I1030 10:20:17.703778 10929 layer_factory.hpp:77] Creating layer loss
I1030 10:20:17.703780 10929 net.cpp:84] Creating Layer loss
I1030 10:20:17.703783 10929 net.cpp:406] loss <- fc100_fc100_0_split_0
I1030 10:20:17.703799 10929 net.cpp:406] loss <- label_face_1_split_0
I1030 10:20:17.703802 10929 net.cpp:380] loss -> loss
I1030 10:20:17.703819 10929 layer_factory.hpp:77] Creating layer loss
I1030 10:20:17.704504 10929 net.cpp:122] Setting up loss
I1030 10:20:17.704511 10929 net.cpp:129] Top shape: (1)
I1030 10:20:17.704514 10929 net.cpp:132]     with loss weight 1
I1030 10:20:17.704521 10929 net.cpp:137] Memory required for data: 406603604
I1030 10:20:17.704522 10929 layer_factory.hpp:77] Creating layer acc
I1030 10:20:17.704526 10929 net.cpp:84] Creating Layer acc
I1030 10:20:17.704529 10929 net.cpp:406] acc <- fc100_fc100_0_split_1
I1030 10:20:17.704531 10929 net.cpp:406] acc <- label_face_1_split_1
I1030 10:20:17.704535 10929 net.cpp:380] acc -> acc
I1030 10:20:17.704540 10929 net.cpp:122] Setting up acc
I1030 10:20:17.704543 10929 net.cpp:129] Top shape: (1)
I1030 10:20:17.704545 10929 net.cpp:137] Memory required for data: 406603608
I1030 10:20:17.704546 10929 net.cpp:200] acc does not need backward computation.
I1030 10:20:17.704548 10929 net.cpp:198] loss needs backward computation.
I1030 10:20:17.704550 10929 net.cpp:198] fc100_fc100_0_split needs backward computation.
I1030 10:20:17.704567 10929 net.cpp:198] fc100 needs backward computation.
I1030 10:20:17.704569 10929 net.cpp:198] drop66 needs backward computation.
I1030 10:20:17.704571 10929 net.cpp:198] relu66 needs backward computation.
I1030 10:20:17.704572 10929 net.cpp:198] fc66 needs backward computation.
I1030 10:20:17.704574 10929 net.cpp:198] drop65 needs backward computation.
I1030 10:20:17.704582 10929 net.cpp:198] relu65 needs backward computation.
I1030 10:20:17.704584 10929 net.cpp:198] fc65 needs backward computation.
I1030 10:20:17.704586 10929 net.cpp:198] pool7 needs backward computation.
I1030 10:20:17.704588 10929 net.cpp:198] relu7 needs backward computation.
I1030 10:20:17.704591 10929 net.cpp:198] scale7 needs backward computation.
I1030 10:20:17.704592 10929 net.cpp:198] BN7 needs backward computation.
I1030 10:20:17.704594 10929 net.cpp:198] conv7 needs backward computation.
I1030 10:20:17.704596 10929 net.cpp:198] relu6 needs backward computation.
I1030 10:20:17.704598 10929 net.cpp:198] scale6 needs backward computation.
I1030 10:20:17.704599 10929 net.cpp:198] BN6 needs backward computation.
I1030 10:20:17.704602 10929 net.cpp:198] conv6 needs backward computation.
I1030 10:20:17.704603 10929 net.cpp:198] relu5 needs backward computation.
I1030 10:20:17.704605 10929 net.cpp:198] scale5 needs backward computation.
I1030 10:20:17.704607 10929 net.cpp:198] BN5 needs backward computation.
I1030 10:20:17.704608 10929 net.cpp:198] conv5 needs backward computation.
I1030 10:20:17.704610 10929 net.cpp:198] pool4 needs backward computation.
I1030 10:20:17.704612 10929 net.cpp:198] relu4 needs backward computation.
I1030 10:20:17.704627 10929 net.cpp:198] scale4 needs backward computation.
I1030 10:20:17.704629 10929 net.cpp:198] BN4 needs backward computation.
I1030 10:20:17.704630 10929 net.cpp:198] conv4 needs backward computation.
I1030 10:20:17.704632 10929 net.cpp:198] relu3 needs backward computation.
I1030 10:20:17.704634 10929 net.cpp:198] scale3 needs backward computation.
I1030 10:20:17.704650 10929 net.cpp:198] BN3 needs backward computation.
I1030 10:20:17.704653 10929 net.cpp:198] conv3 needs backward computation.
I1030 10:20:17.704653 10929 net.cpp:198] pool2 needs backward computation.
I1030 10:20:17.704655 10929 net.cpp:198] relu2 needs backward computation.
I1030 10:20:17.704658 10929 net.cpp:198] scale2 needs backward computation.
I1030 10:20:17.704659 10929 net.cpp:198] BN2 needs backward computation.
I1030 10:20:17.704661 10929 net.cpp:198] conv2 needs backward computation.
I1030 10:20:17.704663 10929 net.cpp:198] relu1 needs backward computation.
I1030 10:20:17.704665 10929 net.cpp:198] scale1 needs backward computation.
I1030 10:20:17.704666 10929 net.cpp:198] BN1 needs backward computation.
I1030 10:20:17.704668 10929 net.cpp:198] conv1 needs backward computation.
I1030 10:20:17.704670 10929 net.cpp:200] label_face_1_split does not need backward computation.
I1030 10:20:17.704672 10929 net.cpp:200] face does not need backward computation.
I1030 10:20:17.704674 10929 net.cpp:242] This network produces output acc
I1030 10:20:17.704676 10929 net.cpp:242] This network produces output loss
I1030 10:20:17.704691 10929 net.cpp:255] Network initialization done.
I1030 10:20:17.704771 10929 solver.cpp:56] Solver scaffolding done.
I1030 10:20:17.706205 10929 caffe.cpp:248] Starting Optimization
I1030 10:20:17.706212 10929 solver.cpp:272] Solving 
I1030 10:20:17.706212 10929 solver.cpp:273] Learning Rate Policy: inv
I1030 10:20:17.707834 10929 solver.cpp:330] Iteration 0, Testing net (#0)
I1030 10:20:17.922641 10929 solver.cpp:397]     Test net output #0: acc = 0.025
I1030 10:20:17.922663 10929 solver.cpp:397]     Test net output #1: loss = 85.1531 (* 1 = 85.1531 loss)
I1030 10:20:18.022421 10929 solver.cpp:218] Iteration 0 (5.26583e-16 iter/s, 0.316108s/20 iters), loss = 4.12263
I1030 10:20:18.022480 10929 solver.cpp:237]     Train net output #0: loss = 4.12263 (* 1 = 4.12263 loss)
I1030 10:20:18.022524 10929 sgd_solver.cpp:105] Iteration 0, lr = 0.003
I1030 10:20:19.892153 10929 solver.cpp:218] Iteration 20 (10.6976 iter/s, 1.86958s/20 iters), loss = 4.1469
I1030 10:20:19.892191 10929 solver.cpp:237]     Train net output #0: loss = 4.1469 (* 1 = 4.1469 loss)
I1030 10:20:19.892197 10929 sgd_solver.cpp:105] Iteration 20, lr = 0.00298864
I1030 10:20:21.759433 10929 solver.cpp:218] Iteration 40 (10.7114 iter/s, 1.86717s/20 iters), loss = 4.14242
I1030 10:20:21.759472 10929 solver.cpp:237]     Train net output #0: loss = 4.14242 (* 1 = 4.14242 loss)
I1030 10:20:21.759495 10929 sgd_solver.cpp:105] Iteration 40, lr = 0.00297738
I1030 10:20:23.626181 10929 solver.cpp:218] Iteration 60 (10.7144 iter/s, 1.86664s/20 iters), loss = 4.08459
I1030 10:20:23.626231 10929 solver.cpp:237]     Train net output #0: loss = 4.08459 (* 1 = 4.08459 loss)
I1030 10:20:23.626235 10929 sgd_solver.cpp:105] Iteration 60, lr = 0.0029662
I1030 10:20:25.489368 10929 solver.cpp:218] Iteration 80 (10.735 iter/s, 1.86307s/20 iters), loss = 4.06639
I1030 10:20:25.489394 10929 solver.cpp:237]     Train net output #0: loss = 4.06639 (* 1 = 4.06639 loss)
I1030 10:20:25.489399 10929 sgd_solver.cpp:105] Iteration 80, lr = 0.0029551
I1030 10:20:27.264597 10929 solver.cpp:330] Iteration 100, Testing net (#0)
I1030 10:20:27.473186 10929 solver.cpp:397]     Test net output #0: acc = 0.087
I1030 10:20:27.473222 10929 solver.cpp:397]     Test net output #1: loss = 4.00865 (* 1 = 4.00865 loss)
I1030 10:20:27.567307 10929 solver.cpp:218] Iteration 100 (9.62544 iter/s, 2.07783s/20 iters), loss = 4.01714
I1030 10:20:27.567368 10929 solver.cpp:237]     Train net output #0: loss = 4.01714 (* 1 = 4.01714 loss)
I1030 10:20:27.567378 10929 sgd_solver.cpp:105] Iteration 100, lr = 0.00294409
I1030 10:20:29.430771 10929 solver.cpp:218] Iteration 120 (10.7335 iter/s, 1.86333s/20 iters), loss = 3.92231
I1030 10:20:29.430797 10929 solver.cpp:237]     Train net output #0: loss = 3.92231 (* 1 = 3.92231 loss)
I1030 10:20:29.430802 10929 sgd_solver.cpp:105] Iteration 120, lr = 0.00293316
I1030 10:20:31.347050 10929 solver.cpp:218] Iteration 140 (10.4374 iter/s, 1.91618s/20 iters), loss = 3.7316
I1030 10:20:31.347075 10929 solver.cpp:237]     Train net output #0: loss = 3.7316 (* 1 = 3.7316 loss)
I1030 10:20:31.347080 10929 sgd_solver.cpp:105] Iteration 140, lr = 0.00292232
I1030 10:20:33.324686 10929 solver.cpp:218] Iteration 160 (10.1137 iter/s, 1.97752s/20 iters), loss = 3.61627
I1030 10:20:33.324759 10929 solver.cpp:237]     Train net output #0: loss = 3.61627 (* 1 = 3.61627 loss)
I1030 10:20:33.324774 10929 sgd_solver.cpp:105] Iteration 160, lr = 0.00291156
I1030 10:20:35.328755 10929 solver.cpp:218] Iteration 180 (9.98047 iter/s, 2.00391s/20 iters), loss = 3.49721
I1030 10:20:35.328779 10929 solver.cpp:237]     Train net output #0: loss = 3.49721 (* 1 = 3.49721 loss)
I1030 10:20:35.328784 10929 sgd_solver.cpp:105] Iteration 180, lr = 0.00290088
I1030 10:20:37.229815 10929 solver.cpp:330] Iteration 200, Testing net (#0)
I1030 10:20:37.453241 10929 solver.cpp:397]     Test net output #0: acc = 0.09
I1030 10:20:37.453287 10929 solver.cpp:397]     Test net output #1: loss = 3.66054 (* 1 = 3.66054 loss)
I1030 10:20:37.551914 10929 solver.cpp:218] Iteration 200 (8.99684 iter/s, 2.223s/20 iters), loss = 3.12214
I1030 10:20:37.551931 10929 solver.cpp:237]     Train net output #0: loss = 3.12214 (* 1 = 3.12214 loss)
I1030 10:20:37.551936 10929 sgd_solver.cpp:105] Iteration 200, lr = 0.00289028
I1030 10:20:39.524541 10929 solver.cpp:218] Iteration 220 (10.1395 iter/s, 1.97248s/20 iters), loss = 2.93982
I1030 10:20:39.524581 10929 solver.cpp:237]     Train net output #0: loss = 2.93982 (* 1 = 2.93982 loss)
I1030 10:20:39.524586 10929 sgd_solver.cpp:105] Iteration 220, lr = 0.00287976
I1030 10:20:41.408066 10929 solver.cpp:218] Iteration 240 (10.619 iter/s, 1.88341s/20 iters), loss = 2.78462
I1030 10:20:41.408094 10929 solver.cpp:237]     Train net output #0: loss = 2.78462 (* 1 = 2.78462 loss)
I1030 10:20:41.408102 10929 sgd_solver.cpp:105] Iteration 240, lr = 0.00286931
I1030 10:20:43.286202 10929 solver.cpp:218] Iteration 260 (10.6494 iter/s, 1.87803s/20 iters), loss = 2.57489
I1030 10:20:43.286247 10929 solver.cpp:237]     Train net output #0: loss = 2.57489 (* 1 = 2.57489 loss)
I1030 10:20:43.286253 10929 sgd_solver.cpp:105] Iteration 260, lr = 0.00285895
I1030 10:20:45.166705 10929 solver.cpp:218] Iteration 280 (10.6361 iter/s, 1.88039s/20 iters), loss = 2.38626
I1030 10:20:45.166744 10929 solver.cpp:237]     Train net output #0: loss = 2.38626 (* 1 = 2.38626 loss)
I1030 10:20:45.166770 10929 sgd_solver.cpp:105] Iteration 280, lr = 0.00284866
I1030 10:20:46.946879 10929 solver.cpp:330] Iteration 300, Testing net (#0)
I1030 10:20:47.153735 10929 solver.cpp:397]     Test net output #0: acc = 0.123
I1030 10:20:47.153756 10929 solver.cpp:397]     Test net output #1: loss = 3.4462 (* 1 = 3.4462 loss)
I1030 10:20:47.249047 10929 solver.cpp:218] Iteration 300 (9.60521 iter/s, 2.0822s/20 iters), loss = 2.19109
I1030 10:20:47.249266 10929 solver.cpp:237]     Train net output #0: loss = 2.19109 (* 1 = 2.19109 loss)
I1030 10:20:47.249279 10929 sgd_solver.cpp:105] Iteration 300, lr = 0.00283845
I1030 10:20:49.119549 10929 solver.cpp:218] Iteration 320 (10.6939 iter/s, 1.87022s/20 iters), loss = 2.00355
I1030 10:20:49.119587 10929 solver.cpp:237]     Train net output #0: loss = 2.00355 (* 1 = 2.00355 loss)
I1030 10:20:49.119592 10929 sgd_solver.cpp:105] Iteration 320, lr = 0.00282831
I1030 10:20:50.990758 10929 solver.cpp:218] Iteration 340 (10.6889 iter/s, 1.8711s/20 iters), loss = 1.87921
I1030 10:20:50.990784 10929 solver.cpp:237]     Train net output #0: loss = 1.87921 (* 1 = 1.87921 loss)
I1030 10:20:50.990789 10929 sgd_solver.cpp:105] Iteration 340, lr = 0.00281824
I1030 10:20:52.983711 10929 solver.cpp:218] Iteration 360 (10.0359 iter/s, 1.99285s/20 iters), loss = 1.80649
I1030 10:20:52.983742 10929 solver.cpp:237]     Train net output #0: loss = 1.80649 (* 1 = 1.80649 loss)
I1030 10:20:52.983750 10929 sgd_solver.cpp:105] Iteration 360, lr = 0.00280825
I1030 10:20:54.980031 10929 solver.cpp:218] Iteration 380 (10.0192 iter/s, 1.99616s/20 iters), loss = 1.68819
I1030 10:20:54.980067 10929 solver.cpp:237]     Train net output #0: loss = 1.68819 (* 1 = 1.68819 loss)
I1030 10:20:54.980072 10929 sgd_solver.cpp:105] Iteration 380, lr = 0.00279833
I1030 10:20:56.881043 10929 solver.cpp:330] Iteration 400, Testing net (#0)
I1030 10:20:57.103013 10929 solver.cpp:397]     Test net output #0: acc = 0.099
I1030 10:20:57.103036 10929 solver.cpp:397]     Test net output #1: loss = 3.49701 (* 1 = 3.49701 loss)
I1030 10:20:57.201478 10929 solver.cpp:218] Iteration 400 (9.00385 iter/s, 2.22127s/20 iters), loss = 1.47018
I1030 10:20:57.201556 10929 solver.cpp:237]     Train net output #0: loss = 1.47018 (* 1 = 1.47018 loss)
I1030 10:20:57.201568 10929 sgd_solver.cpp:105] Iteration 400, lr = 0.00278849
I1030 10:20:59.197108 10929 solver.cpp:218] Iteration 420 (10.0227 iter/s, 1.99548s/20 iters), loss = 1.37927
I1030 10:20:59.197150 10929 solver.cpp:237]     Train net output #0: loss = 1.37927 (* 1 = 1.37927 loss)
I1030 10:20:59.197158 10929 sgd_solver.cpp:105] Iteration 420, lr = 0.00277871
I1030 10:21:01.195518 10929 solver.cpp:218] Iteration 440 (10.0088 iter/s, 1.99824s/20 iters), loss = 1.15662
I1030 10:21:01.195547 10929 solver.cpp:237]     Train net output #0: loss = 1.15662 (* 1 = 1.15662 loss)
I1030 10:21:01.195552 10929 sgd_solver.cpp:105] Iteration 440, lr = 0.00276901
I1030 10:21:03.149224 10929 solver.cpp:218] Iteration 460 (10.2377 iter/s, 1.95356s/20 iters), loss = 1.10113
I1030 10:21:03.149308 10929 solver.cpp:237]     Train net output #0: loss = 1.10113 (* 1 = 1.10113 loss)
I1030 10:21:03.149322 10929 sgd_solver.cpp:105] Iteration 460, lr = 0.00275937
I1030 10:21:05.023808 10929 solver.cpp:218] Iteration 480 (10.6699 iter/s, 1.87443s/20 iters), loss = 1.2112
I1030 10:21:05.023834 10929 solver.cpp:237]     Train net output #0: loss = 1.2112 (* 1 = 1.2112 loss)
I1030 10:21:05.023839 10929 sgd_solver.cpp:105] Iteration 480, lr = 0.0027498
I1030 10:21:06.813006 10929 solver.cpp:330] Iteration 500, Testing net (#0)
I1030 10:21:07.019337 10929 solver.cpp:397]     Test net output #0: acc = 0.177
I1030 10:21:07.019358 10929 solver.cpp:397]     Test net output #1: loss = 3.13581 (* 1 = 3.13581 loss)
I1030 10:21:07.112963 10929 solver.cpp:218] Iteration 500 (9.57376 iter/s, 2.08904s/20 iters), loss = 0.953772
I1030 10:21:07.113029 10929 solver.cpp:237]     Train net output #0: loss = 0.953772 (* 1 = 0.953772 loss)
I1030 10:21:07.113039 10929 sgd_solver.cpp:105] Iteration 500, lr = 0.0027403
I1030 10:21:09.076107 10929 solver.cpp:218] Iteration 520 (10.1885 iter/s, 1.96299s/20 iters), loss = 1.0625
I1030 10:21:09.076153 10929 solver.cpp:237]     Train net output #0: loss = 1.0625 (* 1 = 1.0625 loss)
I1030 10:21:09.076159 10929 sgd_solver.cpp:105] Iteration 520, lr = 0.00273087
I1030 10:21:10.945449 10929 solver.cpp:218] Iteration 540 (10.6996 iter/s, 1.86923s/20 iters), loss = 0.835859
I1030 10:21:10.945475 10929 solver.cpp:237]     Train net output #0: loss = 0.835859 (* 1 = 0.835859 loss)
I1030 10:21:10.945514 10929 sgd_solver.cpp:105] Iteration 540, lr = 0.0027215
I1030 10:21:12.813500 10929 solver.cpp:218] Iteration 560 (10.7069 iter/s, 1.86795s/20 iters), loss = 0.929906
I1030 10:21:12.813549 10929 solver.cpp:237]     Train net output #0: loss = 0.929906 (* 1 = 0.929906 loss)
I1030 10:21:12.813556 10929 sgd_solver.cpp:105] Iteration 560, lr = 0.0027122
I1030 10:21:14.678750 10929 solver.cpp:218] Iteration 580 (10.7231 iter/s, 1.86513s/20 iters), loss = 0.868546
I1030 10:21:14.678777 10929 solver.cpp:237]     Train net output #0: loss = 0.868546 (* 1 = 0.868546 loss)
I1030 10:21:14.678781 10929 sgd_solver.cpp:105] Iteration 580, lr = 0.00270296
I1030 10:21:16.456441 10929 solver.cpp:330] Iteration 600, Testing net (#0)
I1030 10:21:16.663305 10929 solver.cpp:397]     Test net output #0: acc = 0.301
I1030 10:21:16.663341 10929 solver.cpp:397]     Test net output #1: loss = 2.5871 (* 1 = 2.5871 loss)
I1030 10:21:16.756551 10929 solver.cpp:218] Iteration 600 (9.62609 iter/s, 2.07769s/20 iters), loss = 0.742248
I1030 10:21:16.756618 10929 solver.cpp:237]     Train net output #0: loss = 0.742248 (* 1 = 0.742248 loss)
I1030 10:21:16.756628 10929 sgd_solver.cpp:105] Iteration 600, lr = 0.00269379
I1030 10:21:18.623047 10929 solver.cpp:218] Iteration 620 (10.7161 iter/s, 1.86635s/20 iters), loss = 0.725722
I1030 10:21:18.623178 10929 solver.cpp:237]     Train net output #0: loss = 0.725722 (* 1 = 0.725722 loss)
I1030 10:21:18.623183 10929 sgd_solver.cpp:105] Iteration 620, lr = 0.00268468
I1030 10:21:20.522655 10929 solver.cpp:218] Iteration 640 (10.5296 iter/s, 1.89941s/20 iters), loss = 0.591876
I1030 10:21:20.522682 10929 solver.cpp:237]     Train net output #0: loss = 0.591876 (* 1 = 0.591876 loss)
I1030 10:21:20.522689 10929 sgd_solver.cpp:105] Iteration 640, lr = 0.00267564
I1030 10:21:22.519186 10929 solver.cpp:218] Iteration 660 (10.0182 iter/s, 1.99637s/20 iters), loss = 0.681812
I1030 10:21:22.519217 10929 solver.cpp:237]     Train net output #0: loss = 0.681812 (* 1 = 0.681812 loss)
I1030 10:21:22.519227 10929 sgd_solver.cpp:105] Iteration 660, lr = 0.00266666
I1030 10:21:24.401120 10929 solver.cpp:218] Iteration 680 (10.6282 iter/s, 1.88179s/20 iters), loss = 0.673551
I1030 10:21:24.401165 10929 solver.cpp:237]     Train net output #0: loss = 0.673551 (* 1 = 0.673551 loss)
I1030 10:21:24.401172 10929 sgd_solver.cpp:105] Iteration 680, lr = 0.00265774
I1030 10:21:26.191114 10929 solver.cpp:330] Iteration 700, Testing net (#0)
I1030 10:21:26.399502 10929 solver.cpp:397]     Test net output #0: acc = 0.463
I1030 10:21:26.399523 10929 solver.cpp:397]     Test net output #1: loss = 2.1648 (* 1 = 2.1648 loss)
I1030 10:21:26.493479 10929 solver.cpp:218] Iteration 700 (9.55918 iter/s, 2.09223s/20 iters), loss = 0.580838
I1030 10:21:26.493542 10929 solver.cpp:237]     Train net output #0: loss = 0.580838 (* 1 = 0.580838 loss)
I1030 10:21:26.493553 10929 sgd_solver.cpp:105] Iteration 700, lr = 0.00264888
I1030 10:21:28.358996 10929 solver.cpp:218] Iteration 720 (10.7217 iter/s, 1.86538s/20 iters), loss = 0.753979
I1030 10:21:28.359043 10929 solver.cpp:237]     Train net output #0: loss = 0.753979 (* 1 = 0.753979 loss)
I1030 10:21:28.359050 10929 sgd_solver.cpp:105] Iteration 720, lr = 0.00264008
I1030 10:21:30.224249 10929 solver.cpp:218] Iteration 740 (10.7231 iter/s, 1.86514s/20 iters), loss = 0.640928
I1030 10:21:30.224274 10929 solver.cpp:237]     Train net output #0: loss = 0.640928 (* 1 = 0.640928 loss)
I1030 10:21:30.224278 10929 sgd_solver.cpp:105] Iteration 740, lr = 0.00263134
I1030 10:21:32.096246 10929 solver.cpp:218] Iteration 760 (10.6843 iter/s, 1.8719s/20 iters), loss = 0.615586
I1030 10:21:32.096273 10929 solver.cpp:237]     Train net output #0: loss = 0.615586 (* 1 = 0.615586 loss)
I1030 10:21:32.096278 10929 sgd_solver.cpp:105] Iteration 760, lr = 0.00262266
I1030 10:21:33.687083 10936 data_layer.cpp:73] Restarting data prefetching from start.
I1030 10:21:33.967270 10929 solver.cpp:218] Iteration 780 (10.6899 iter/s, 1.87093s/20 iters), loss = 0.540657
I1030 10:21:33.967312 10929 solver.cpp:237]     Train net output #0: loss = 0.540657 (* 1 = 0.540657 loss)
I1030 10:21:33.967317 10929 sgd_solver.cpp:105] Iteration 780, lr = 0.00261403
I1030 10:21:35.744984 10929 solver.cpp:330] Iteration 800, Testing net (#0)
I1030 10:21:35.953150 10929 solver.cpp:397]     Test net output #0: acc = 0.401
I1030 10:21:35.953172 10929 solver.cpp:397]     Test net output #1: loss = 2.21295 (* 1 = 2.21295 loss)
I1030 10:21:36.047394 10929 solver.cpp:218] Iteration 800 (9.61537 iter/s, 2.08s/20 iters), loss = 0.498958
I1030 10:21:36.047467 10929 solver.cpp:237]     Train net output #0: loss = 0.498958 (* 1 = 0.498958 loss)
I1030 10:21:36.047478 10929 sgd_solver.cpp:105] Iteration 800, lr = 0.00260547
I1030 10:21:37.914903 10929 solver.cpp:218] Iteration 820 (10.7103 iter/s, 1.86736s/20 iters), loss = 0.660213
I1030 10:21:37.914947 10929 solver.cpp:237]     Train net output #0: loss = 0.660213 (* 1 = 0.660213 loss)
I1030 10:21:37.914953 10929 sgd_solver.cpp:105] Iteration 820, lr = 0.00259696
I1030 10:21:39.781275 10929 solver.cpp:218] Iteration 840 (10.7166 iter/s, 1.86626s/20 iters), loss = 0.497287
I1030 10:21:39.781306 10929 solver.cpp:237]     Train net output #0: loss = 0.497287 (* 1 = 0.497287 loss)
I1030 10:21:39.781327 10929 sgd_solver.cpp:105] Iteration 840, lr = 0.00258851
I1030 10:21:41.654319 10929 solver.cpp:218] Iteration 860 (10.6784 iter/s, 1.87294s/20 iters), loss = 0.536676
I1030 10:21:41.654364 10929 solver.cpp:237]     Train net output #0: loss = 0.536676 (* 1 = 0.536676 loss)
I1030 10:21:41.654369 10929 sgd_solver.cpp:105] Iteration 860, lr = 0.00258012
I1030 10:21:43.571717 10929 solver.cpp:218] Iteration 880 (10.4315 iter/s, 1.91726s/20 iters), loss = 0.367524
I1030 10:21:43.571808 10929 solver.cpp:237]     Train net output #0: loss = 0.367524 (* 1 = 0.367524 loss)
I1030 10:21:43.571822 10929 sgd_solver.cpp:105] Iteration 880, lr = 0.00257178
I1030 10:21:45.357744 10929 solver.cpp:330] Iteration 900, Testing net (#0)
I1030 10:21:45.485483 10938 data_layer.cpp:73] Restarting data prefetching from start.
I1030 10:21:45.569223 10929 solver.cpp:397]     Test net output #0: acc = 0.243
I1030 10:21:45.569278 10929 solver.cpp:397]     Test net output #1: loss = 2.88303 (* 1 = 2.88303 loss)
I1030 10:21:45.663961 10929 solver.cpp:218] Iteration 900 (9.55988 iter/s, 2.09208s/20 iters), loss = 0.564335
I1030 10:21:45.664036 10929 solver.cpp:237]     Train net output #0: loss = 0.564335 (* 1 = 0.564335 loss)
I1030 10:21:45.664052 10929 sgd_solver.cpp:105] Iteration 900, lr = 0.0025635
I1030 10:21:47.535193 10929 solver.cpp:218] Iteration 920 (10.6889 iter/s, 1.8711s/20 iters), loss = 0.433393
I1030 10:21:47.535220 10929 solver.cpp:237]     Train net output #0: loss = 0.433393 (* 1 = 0.433393 loss)
I1030 10:21:47.535226 10929 sgd_solver.cpp:105] Iteration 920, lr = 0.00255527
I1030 10:21:49.403033 10929 solver.cpp:218] Iteration 940 (10.7081 iter/s, 1.86774s/20 iters), loss = 0.366301
