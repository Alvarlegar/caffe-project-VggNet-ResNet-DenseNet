I1028 14:12:04.316978 12618 caffe.cpp:218] Using GPUs 0
I1028 14:12:04.334293 12618 caffe.cpp:223] GPU 0: GeForce GTX 1060 6GB
I1028 14:12:04.534205 12618 solver.cpp:44] Initializing solver from parameters: 
test_iter: 10
test_interval: 1000
base_lr: 0.003
display: 200
max_iter: 50000
lr_policy: "inv"
gamma: 0.0002
power: 0.95
momentum: 0.9
weight_decay: 0.005
stepsize: 100000
snapshot: 10000
snapshot_prefix: "/home/ljf/caffe-master/examples/ljftest_alphabet/caffe_ljftest_train"
solver_mode: GPU
device_id: 0
net: "/home/ljf/caffe-master/examples/ljftest_alphabet/train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
I1028 14:12:04.534440 12618 solver.cpp:87] Creating training net from net file: /home/ljf/caffe-master/examples/ljftest_alphabet/train_val.prototxt
I1028 14:12:04.534694 12618 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer face
I1028 14:12:04.534721 12618 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer acc
I1028 14:12:04.534827 12618 net.cpp:51] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "face"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "/home/ljf/caffe-master/examples/ljftest_alphabet/train_lmdb"
    batch_size: 128
    backend: LMDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.00011111111
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.00011111111
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "norm3"
  type: "LRN"
  bottom: "pool3"
  top: "norm3"
  lrn_param {
    local_size: 5
    alpha: 0.00011111111
    beta: 0.75
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "norm3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "norm4"
  type: "LRN"
  bottom: "pool4"
  top: "norm4"
  lrn_param {
    local_size: 3
    alpha: 0.00011111111
    beta: 0.75
  }
}
layer {
  name: "fc65"
  type: "InnerProduct"
  bottom: "norm4"
  top: "fc65"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "gaussian"
      std: 0.0009765625
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu65"
  type: "ReLU"
  bottom: "fc65"
  top: "fc65"
}
layer {
  name: "drop65"
  type: "Dropout"
  bottom: "fc65"
  top: "fc65"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "fc100"
  type: "InnerProduct"
  bottom: "fc65"
  top: "fc100"
  inner_product_param {
    num_output: 62
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc100"
  bottom: "label"
  top: "loss"
}
I1028 14:12:04.534939 12618 layer_factory.hpp:77] Creating layer face
I1028 14:12:04.535058 12618 db_lmdb.cpp:35] Opened lmdb /home/ljf/caffe-master/examples/ljftest_alphabet/train_lmdb
I1028 14:12:04.535100 12618 net.cpp:84] Creating Layer face
I1028 14:12:04.535107 12618 net.cpp:380] face -> data
I1028 14:12:04.535123 12618 net.cpp:380] face -> label
I1028 14:12:04.535804 12618 data_layer.cpp:45] output data size: 128,3,32,32
I1028 14:12:04.540050 12618 net.cpp:122] Setting up face
I1028 14:12:04.540066 12618 net.cpp:129] Top shape: 128 3 32 32 (393216)
I1028 14:12:04.540069 12618 net.cpp:129] Top shape: 128 (128)
I1028 14:12:04.540072 12618 net.cpp:137] Memory required for data: 1573376
I1028 14:12:04.540079 12618 layer_factory.hpp:77] Creating layer conv1
I1028 14:12:04.540115 12618 net.cpp:84] Creating Layer conv1
I1028 14:12:04.540132 12618 net.cpp:406] conv1 <- data
I1028 14:12:04.540158 12618 net.cpp:380] conv1 -> conv1
I1028 14:12:04.702783 12618 net.cpp:122] Setting up conv1
I1028 14:12:04.702821 12618 net.cpp:129] Top shape: 128 32 32 32 (4194304)
I1028 14:12:04.702822 12618 net.cpp:137] Memory required for data: 18350592
I1028 14:12:04.702846 12618 layer_factory.hpp:77] Creating layer relu1
I1028 14:12:04.702858 12618 net.cpp:84] Creating Layer relu1
I1028 14:12:04.702864 12618 net.cpp:406] relu1 <- conv1
I1028 14:12:04.702870 12618 net.cpp:367] relu1 -> conv1 (in-place)
I1028 14:12:04.703032 12618 net.cpp:122] Setting up relu1
I1028 14:12:04.703038 12618 net.cpp:129] Top shape: 128 32 32 32 (4194304)
I1028 14:12:04.703054 12618 net.cpp:137] Memory required for data: 35127808
I1028 14:12:04.703057 12618 layer_factory.hpp:77] Creating layer pool1
I1028 14:12:04.703060 12618 net.cpp:84] Creating Layer pool1
I1028 14:12:04.703063 12618 net.cpp:406] pool1 <- conv1
I1028 14:12:04.703065 12618 net.cpp:380] pool1 -> pool1
I1028 14:12:04.703099 12618 net.cpp:122] Setting up pool1
I1028 14:12:04.703104 12618 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I1028 14:12:04.703105 12618 net.cpp:137] Memory required for data: 39322112
I1028 14:12:04.703107 12618 layer_factory.hpp:77] Creating layer norm1
I1028 14:12:04.703114 12618 net.cpp:84] Creating Layer norm1
I1028 14:12:04.703115 12618 net.cpp:406] norm1 <- pool1
I1028 14:12:04.703119 12618 net.cpp:380] norm1 -> norm1
I1028 14:12:04.703245 12618 net.cpp:122] Setting up norm1
I1028 14:12:04.703250 12618 net.cpp:129] Top shape: 128 32 16 16 (1048576)
I1028 14:12:04.703266 12618 net.cpp:137] Memory required for data: 43516416
I1028 14:12:04.703269 12618 layer_factory.hpp:77] Creating layer conv2
I1028 14:12:04.703275 12618 net.cpp:84] Creating Layer conv2
I1028 14:12:04.703277 12618 net.cpp:406] conv2 <- norm1
I1028 14:12:04.703280 12618 net.cpp:380] conv2 -> conv2
I1028 14:12:04.704567 12618 net.cpp:122] Setting up conv2
I1028 14:12:04.704576 12618 net.cpp:129] Top shape: 128 64 16 16 (2097152)
I1028 14:12:04.704592 12618 net.cpp:137] Memory required for data: 51905024
I1028 14:12:04.704597 12618 layer_factory.hpp:77] Creating layer relu2
I1028 14:12:04.704612 12618 net.cpp:84] Creating Layer relu2
I1028 14:12:04.704615 12618 net.cpp:406] relu2 <- conv2
I1028 14:12:04.704618 12618 net.cpp:367] relu2 -> conv2 (in-place)
I1028 14:12:04.704754 12618 net.cpp:122] Setting up relu2
I1028 14:12:04.704761 12618 net.cpp:129] Top shape: 128 64 16 16 (2097152)
I1028 14:12:04.704777 12618 net.cpp:137] Memory required for data: 60293632
I1028 14:12:04.704777 12618 layer_factory.hpp:77] Creating layer pool2
I1028 14:12:04.704780 12618 net.cpp:84] Creating Layer pool2
I1028 14:12:04.704783 12618 net.cpp:406] pool2 <- conv2
I1028 14:12:04.704785 12618 net.cpp:380] pool2 -> pool2
I1028 14:12:04.704805 12618 net.cpp:122] Setting up pool2
I1028 14:12:04.704809 12618 net.cpp:129] Top shape: 128 64 8 8 (524288)
I1028 14:12:04.704812 12618 net.cpp:137] Memory required for data: 62390784
I1028 14:12:04.704813 12618 layer_factory.hpp:77] Creating layer norm2
I1028 14:12:04.704818 12618 net.cpp:84] Creating Layer norm2
I1028 14:12:04.704818 12618 net.cpp:406] norm2 <- pool2
I1028 14:12:04.704821 12618 net.cpp:380] norm2 -> norm2
I1028 14:12:04.705147 12618 net.cpp:122] Setting up norm2
I1028 14:12:04.705154 12618 net.cpp:129] Top shape: 128 64 8 8 (524288)
I1028 14:12:04.705171 12618 net.cpp:137] Memory required for data: 64487936
I1028 14:12:04.705173 12618 layer_factory.hpp:77] Creating layer conv3
I1028 14:12:04.705178 12618 net.cpp:84] Creating Layer conv3
I1028 14:12:04.705180 12618 net.cpp:406] conv3 <- norm2
I1028 14:12:04.705183 12618 net.cpp:380] conv3 -> conv3
I1028 14:12:04.706207 12618 net.cpp:122] Setting up conv3
I1028 14:12:04.706214 12618 net.cpp:129] Top shape: 128 64 8 8 (524288)
I1028 14:12:04.706229 12618 net.cpp:137] Memory required for data: 66585088
I1028 14:12:04.706234 12618 layer_factory.hpp:77] Creating layer relu3
I1028 14:12:04.706238 12618 net.cpp:84] Creating Layer relu3
I1028 14:12:04.706241 12618 net.cpp:406] relu3 <- conv3
I1028 14:12:04.706244 12618 net.cpp:367] relu3 -> conv3 (in-place)
I1028 14:12:04.706382 12618 net.cpp:122] Setting up relu3
I1028 14:12:04.706387 12618 net.cpp:129] Top shape: 128 64 8 8 (524288)
I1028 14:12:04.706389 12618 net.cpp:137] Memory required for data: 68682240
I1028 14:12:04.706392 12618 layer_factory.hpp:77] Creating layer pool3
I1028 14:12:04.706406 12618 net.cpp:84] Creating Layer pool3
I1028 14:12:04.706408 12618 net.cpp:406] pool3 <- conv3
I1028 14:12:04.706411 12618 net.cpp:380] pool3 -> pool3
I1028 14:12:04.706449 12618 net.cpp:122] Setting up pool3
I1028 14:12:04.706452 12618 net.cpp:129] Top shape: 128 64 4 4 (131072)
I1028 14:12:04.706454 12618 net.cpp:137] Memory required for data: 69206528
I1028 14:12:04.706456 12618 layer_factory.hpp:77] Creating layer norm3
I1028 14:12:04.706459 12618 net.cpp:84] Creating Layer norm3
I1028 14:12:04.706461 12618 net.cpp:406] norm3 <- pool3
I1028 14:12:04.706463 12618 net.cpp:380] norm3 -> norm3
I1028 14:12:04.706629 12618 net.cpp:122] Setting up norm3
I1028 14:12:04.706634 12618 net.cpp:129] Top shape: 128 64 4 4 (131072)
I1028 14:12:04.706650 12618 net.cpp:137] Memory required for data: 69730816
I1028 14:12:04.706651 12618 layer_factory.hpp:77] Creating layer conv4
I1028 14:12:04.706656 12618 net.cpp:84] Creating Layer conv4
I1028 14:12:04.706658 12618 net.cpp:406] conv4 <- norm3
I1028 14:12:04.706661 12618 net.cpp:380] conv4 -> conv4
I1028 14:12:04.707501 12618 net.cpp:122] Setting up conv4
I1028 14:12:04.707509 12618 net.cpp:129] Top shape: 128 64 4 4 (131072)
I1028 14:12:04.707525 12618 net.cpp:137] Memory required for data: 70255104
I1028 14:12:04.707530 12618 layer_factory.hpp:77] Creating layer relu4
I1028 14:12:04.707532 12618 net.cpp:84] Creating Layer relu4
I1028 14:12:04.707535 12618 net.cpp:406] relu4 <- conv4
I1028 14:12:04.707538 12618 net.cpp:367] relu4 -> conv4 (in-place)
I1028 14:12:04.707653 12618 net.cpp:122] Setting up relu4
I1028 14:12:04.707659 12618 net.cpp:129] Top shape: 128 64 4 4 (131072)
I1028 14:12:04.707675 12618 net.cpp:137] Memory required for data: 70779392
I1028 14:12:04.707676 12618 layer_factory.hpp:77] Creating layer pool4
I1028 14:12:04.707685 12618 net.cpp:84] Creating Layer pool4
I1028 14:12:04.707687 12618 net.cpp:406] pool4 <- conv4
I1028 14:12:04.707691 12618 net.cpp:380] pool4 -> pool4
I1028 14:12:04.707716 12618 net.cpp:122] Setting up pool4
I1028 14:12:04.707720 12618 net.cpp:129] Top shape: 128 64 2 2 (32768)
I1028 14:12:04.707721 12618 net.cpp:137] Memory required for data: 70910464
I1028 14:12:04.707723 12618 layer_factory.hpp:77] Creating layer norm4
I1028 14:12:04.707727 12618 net.cpp:84] Creating Layer norm4
I1028 14:12:04.707729 12618 net.cpp:406] norm4 <- pool4
I1028 14:12:04.707732 12618 net.cpp:380] norm4 -> norm4
I1028 14:12:04.707881 12618 net.cpp:122] Setting up norm4
I1028 14:12:04.707887 12618 net.cpp:129] Top shape: 128 64 2 2 (32768)
I1028 14:12:04.707890 12618 net.cpp:137] Memory required for data: 71041536
I1028 14:12:04.707891 12618 layer_factory.hpp:77] Creating layer fc65
I1028 14:12:04.707897 12618 net.cpp:84] Creating Layer fc65
I1028 14:12:04.707900 12618 net.cpp:406] fc65 <- norm4
I1028 14:12:04.707903 12618 net.cpp:380] fc65 -> fc65
I1028 14:12:04.710136 12618 net.cpp:122] Setting up fc65
I1028 14:12:04.710144 12618 net.cpp:129] Top shape: 128 1024 (131072)
I1028 14:12:04.710146 12618 net.cpp:137] Memory required for data: 71565824
I1028 14:12:04.710165 12618 layer_factory.hpp:77] Creating layer relu65
I1028 14:12:04.710168 12618 net.cpp:84] Creating Layer relu65
I1028 14:12:04.710170 12618 net.cpp:406] relu65 <- fc65
I1028 14:12:04.710188 12618 net.cpp:367] relu65 -> fc65 (in-place)
I1028 14:12:04.710474 12618 net.cpp:122] Setting up relu65
I1028 14:12:04.710482 12618 net.cpp:129] Top shape: 128 1024 (131072)
I1028 14:12:04.710499 12618 net.cpp:137] Memory required for data: 72090112
I1028 14:12:04.710500 12618 layer_factory.hpp:77] Creating layer drop65
I1028 14:12:04.710505 12618 net.cpp:84] Creating Layer drop65
I1028 14:12:04.710507 12618 net.cpp:406] drop65 <- fc65
I1028 14:12:04.710510 12618 net.cpp:367] drop65 -> fc65 (in-place)
I1028 14:12:04.710526 12618 net.cpp:122] Setting up drop65
I1028 14:12:04.710530 12618 net.cpp:129] Top shape: 128 1024 (131072)
I1028 14:12:04.710531 12618 net.cpp:137] Memory required for data: 72614400
I1028 14:12:04.710533 12618 layer_factory.hpp:77] Creating layer fc100
I1028 14:12:04.710536 12618 net.cpp:84] Creating Layer fc100
I1028 14:12:04.710538 12618 net.cpp:406] fc100 <- fc65
I1028 14:12:04.710541 12618 net.cpp:380] fc100 -> fc100
I1028 14:12:04.711036 12618 net.cpp:122] Setting up fc100
I1028 14:12:04.711040 12618 net.cpp:129] Top shape: 128 62 (7936)
I1028 14:12:04.711042 12618 net.cpp:137] Memory required for data: 72646144
I1028 14:12:04.711061 12618 layer_factory.hpp:77] Creating layer loss
I1028 14:12:04.711064 12618 net.cpp:84] Creating Layer loss
I1028 14:12:04.711066 12618 net.cpp:406] loss <- fc100
I1028 14:12:04.711068 12618 net.cpp:406] loss <- label
I1028 14:12:04.711071 12618 net.cpp:380] loss -> loss
I1028 14:12:04.711082 12618 layer_factory.hpp:77] Creating layer loss
I1028 14:12:04.711807 12618 net.cpp:122] Setting up loss
I1028 14:12:04.711813 12618 net.cpp:129] Top shape: (1)
I1028 14:12:04.711830 12618 net.cpp:132]     with loss weight 1
I1028 14:12:04.711844 12618 net.cpp:137] Memory required for data: 72646148
I1028 14:12:04.711848 12618 net.cpp:198] loss needs backward computation.
I1028 14:12:04.711851 12618 net.cpp:198] fc100 needs backward computation.
I1028 14:12:04.711853 12618 net.cpp:198] drop65 needs backward computation.
I1028 14:12:04.711855 12618 net.cpp:198] relu65 needs backward computation.
I1028 14:12:04.711858 12618 net.cpp:198] fc65 needs backward computation.
I1028 14:12:04.711858 12618 net.cpp:198] norm4 needs backward computation.
I1028 14:12:04.711861 12618 net.cpp:198] pool4 needs backward computation.
I1028 14:12:04.711864 12618 net.cpp:198] relu4 needs backward computation.
I1028 14:12:04.711868 12618 net.cpp:198] conv4 needs backward computation.
I1028 14:12:04.711869 12618 net.cpp:198] norm3 needs backward computation.
I1028 14:12:04.711870 12618 net.cpp:198] pool3 needs backward computation.
I1028 14:12:04.711887 12618 net.cpp:198] relu3 needs backward computation.
I1028 14:12:04.711896 12618 net.cpp:198] conv3 needs backward computation.
I1028 14:12:04.711899 12618 net.cpp:198] norm2 needs backward computation.
I1028 14:12:04.711900 12618 net.cpp:198] pool2 needs backward computation.
I1028 14:12:04.711902 12618 net.cpp:198] relu2 needs backward computation.
I1028 14:12:04.711905 12618 net.cpp:198] conv2 needs backward computation.
I1028 14:12:04.711906 12618 net.cpp:198] norm1 needs backward computation.
I1028 14:12:04.711908 12618 net.cpp:198] pool1 needs backward computation.
I1028 14:12:04.711910 12618 net.cpp:198] relu1 needs backward computation.
I1028 14:12:04.711925 12618 net.cpp:198] conv1 needs backward computation.
I1028 14:12:04.711926 12618 net.cpp:200] face does not need backward computation.
I1028 14:12:04.711928 12618 net.cpp:242] This network produces output loss
I1028 14:12:04.711952 12618 net.cpp:255] Network initialization done.
I1028 14:12:04.712153 12618 solver.cpp:172] Creating test net (#0) specified by net file: /home/ljf/caffe-master/examples/ljftest_alphabet/train_val.prototxt
I1028 14:12:04.712201 12618 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer face
I1028 14:12:04.712317 12618 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "face"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "/home/ljf/caffe-master/examples/ljftest_alphabet/val_lmdb"
    batch_size: 100
    backend: LMDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.00011111111
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.00011111111
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "norm3"
  type: "LRN"
  bottom: "pool3"
  top: "norm3"
  lrn_param {
    local_size: 5
    alpha: 0.00011111111
    beta: 0.75
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "norm3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "norm4"
  type: "LRN"
  bottom: "pool4"
  top: "norm4"
  lrn_param {
    local_size: 3
    alpha: 0.00011111111
    beta: 0.75
  }
}
layer {
  name: "fc65"
  type: "InnerProduct"
  bottom: "norm4"
  top: "fc65"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "gaussian"
      std: 0.0009765625
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu65"
  type: "ReLU"
  bottom: "fc65"
  top: "fc65"
}
layer {
  name: "drop65"
  type: "Dropout"
  bottom: "fc65"
  top: "fc65"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "fc100"
  type: "InnerProduct"
  bottom: "fc65"
  top: "fc100"
  inner_product_param {
    num_output: 62
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc100"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc"
  type: "Accuracy"
  bottom: "fc100"
  bottom: "label"
  top: "acc"
  include {
    phase: TEST
  }
}
I1028 14:12:04.712400 12618 layer_factory.hpp:77] Creating layer face
I1028 14:12:04.712436 12618 db_lmdb.cpp:35] Opened lmdb /home/ljf/caffe-master/examples/ljftest_alphabet/val_lmdb
I1028 14:12:04.712458 12618 net.cpp:84] Creating Layer face
I1028 14:12:04.712477 12618 net.cpp:380] face -> data
I1028 14:12:04.712483 12618 net.cpp:380] face -> label
I1028 14:12:04.712560 12618 data_layer.cpp:45] output data size: 100,3,32,32
I1028 14:12:04.716534 12618 net.cpp:122] Setting up face
I1028 14:12:04.716557 12618 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1028 14:12:04.716560 12618 net.cpp:129] Top shape: 100 (100)
I1028 14:12:04.716562 12618 net.cpp:137] Memory required for data: 1229200
I1028 14:12:04.716568 12618 layer_factory.hpp:77] Creating layer label_face_1_split
I1028 14:12:04.716583 12618 net.cpp:84] Creating Layer label_face_1_split
I1028 14:12:04.716585 12618 net.cpp:406] label_face_1_split <- label
I1028 14:12:04.716604 12618 net.cpp:380] label_face_1_split -> label_face_1_split_0
I1028 14:12:04.716612 12618 net.cpp:380] label_face_1_split -> label_face_1_split_1
I1028 14:12:04.716660 12618 net.cpp:122] Setting up label_face_1_split
I1028 14:12:04.716665 12618 net.cpp:129] Top shape: 100 (100)
I1028 14:12:04.716667 12618 net.cpp:129] Top shape: 100 (100)
I1028 14:12:04.716668 12618 net.cpp:137] Memory required for data: 1230000
I1028 14:12:04.716670 12618 layer_factory.hpp:77] Creating layer conv1
I1028 14:12:04.716693 12618 net.cpp:84] Creating Layer conv1
I1028 14:12:04.716696 12618 net.cpp:406] conv1 <- data
I1028 14:12:04.716701 12618 net.cpp:380] conv1 -> conv1
I1028 14:12:04.717581 12618 net.cpp:122] Setting up conv1
I1028 14:12:04.717605 12618 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I1028 14:12:04.717608 12618 net.cpp:137] Memory required for data: 14337200
I1028 14:12:04.717617 12618 layer_factory.hpp:77] Creating layer relu1
I1028 14:12:04.717620 12618 net.cpp:84] Creating Layer relu1
I1028 14:12:04.717622 12618 net.cpp:406] relu1 <- conv1
I1028 14:12:04.717625 12618 net.cpp:367] relu1 -> conv1 (in-place)
I1028 14:12:04.717751 12618 net.cpp:122] Setting up relu1
I1028 14:12:04.717756 12618 net.cpp:129] Top shape: 100 32 32 32 (3276800)
I1028 14:12:04.717772 12618 net.cpp:137] Memory required for data: 27444400
I1028 14:12:04.717773 12618 layer_factory.hpp:77] Creating layer pool1
I1028 14:12:04.717779 12618 net.cpp:84] Creating Layer pool1
I1028 14:12:04.717780 12618 net.cpp:406] pool1 <- conv1
I1028 14:12:04.717784 12618 net.cpp:380] pool1 -> pool1
I1028 14:12:04.717824 12618 net.cpp:122] Setting up pool1
I1028 14:12:04.717828 12618 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1028 14:12:04.717852 12618 net.cpp:137] Memory required for data: 30721200
I1028 14:12:04.717854 12618 layer_factory.hpp:77] Creating layer norm1
I1028 14:12:04.717860 12618 net.cpp:84] Creating Layer norm1
I1028 14:12:04.717861 12618 net.cpp:406] norm1 <- pool1
I1028 14:12:04.717864 12618 net.cpp:380] norm1 -> norm1
I1028 14:12:04.717993 12618 net.cpp:122] Setting up norm1
I1028 14:12:04.717999 12618 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1028 14:12:04.718003 12618 net.cpp:137] Memory required for data: 33998000
I1028 14:12:04.718004 12618 layer_factory.hpp:77] Creating layer conv2
I1028 14:12:04.718010 12618 net.cpp:84] Creating Layer conv2
I1028 14:12:04.718014 12618 net.cpp:406] conv2 <- norm1
I1028 14:12:04.718017 12618 net.cpp:380] conv2 -> conv2
I1028 14:12:04.718968 12618 net.cpp:122] Setting up conv2
I1028 14:12:04.718977 12618 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I1028 14:12:04.718992 12618 net.cpp:137] Memory required for data: 40551600
I1028 14:12:04.718998 12618 layer_factory.hpp:77] Creating layer relu2
I1028 14:12:04.719003 12618 net.cpp:84] Creating Layer relu2
I1028 14:12:04.719005 12618 net.cpp:406] relu2 <- conv2
I1028 14:12:04.719008 12618 net.cpp:367] relu2 -> conv2 (in-place)
I1028 14:12:04.719328 12618 net.cpp:122] Setting up relu2
I1028 14:12:04.719336 12618 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I1028 14:12:04.719352 12618 net.cpp:137] Memory required for data: 47105200
I1028 14:12:04.719354 12618 layer_factory.hpp:77] Creating layer pool2
I1028 14:12:04.719362 12618 net.cpp:84] Creating Layer pool2
I1028 14:12:04.719363 12618 net.cpp:406] pool2 <- conv2
I1028 14:12:04.719367 12618 net.cpp:380] pool2 -> pool2
I1028 14:12:04.719393 12618 net.cpp:122] Setting up pool2
I1028 14:12:04.719410 12618 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1028 14:12:04.719413 12618 net.cpp:137] Memory required for data: 48743600
I1028 14:12:04.719413 12618 layer_factory.hpp:77] Creating layer norm2
I1028 14:12:04.719431 12618 net.cpp:84] Creating Layer norm2
I1028 14:12:04.719434 12618 net.cpp:406] norm2 <- pool2
I1028 14:12:04.719435 12618 net.cpp:380] norm2 -> norm2
I1028 14:12:04.719717 12618 net.cpp:122] Setting up norm2
I1028 14:12:04.719723 12618 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1028 14:12:04.719725 12618 net.cpp:137] Memory required for data: 50382000
I1028 14:12:04.719727 12618 layer_factory.hpp:77] Creating layer conv3
I1028 14:12:04.719732 12618 net.cpp:84] Creating Layer conv3
I1028 14:12:04.719735 12618 net.cpp:406] conv3 <- norm2
I1028 14:12:04.719739 12618 net.cpp:380] conv3 -> conv3
I1028 14:12:04.720788 12618 net.cpp:122] Setting up conv3
I1028 14:12:04.720798 12618 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1028 14:12:04.720800 12618 net.cpp:137] Memory required for data: 52020400
I1028 14:12:04.720808 12618 layer_factory.hpp:77] Creating layer relu3
I1028 14:12:04.720813 12618 net.cpp:84] Creating Layer relu3
I1028 14:12:04.720814 12618 net.cpp:406] relu3 <- conv3
I1028 14:12:04.720818 12618 net.cpp:367] relu3 -> conv3 (in-place)
I1028 14:12:04.720940 12618 net.cpp:122] Setting up relu3
I1028 14:12:04.720945 12618 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1028 14:12:04.720947 12618 net.cpp:137] Memory required for data: 53658800
I1028 14:12:04.720949 12618 layer_factory.hpp:77] Creating layer pool3
I1028 14:12:04.720968 12618 net.cpp:84] Creating Layer pool3
I1028 14:12:04.720971 12618 net.cpp:406] pool3 <- conv3
I1028 14:12:04.720974 12618 net.cpp:380] pool3 -> pool3
I1028 14:12:04.721002 12618 net.cpp:122] Setting up pool3
I1028 14:12:04.721006 12618 net.cpp:129] Top shape: 100 64 4 4 (102400)
I1028 14:12:04.721007 12618 net.cpp:137] Memory required for data: 54068400
I1028 14:12:04.721009 12618 layer_factory.hpp:77] Creating layer norm3
I1028 14:12:04.721025 12618 net.cpp:84] Creating Layer norm3
I1028 14:12:04.721027 12618 net.cpp:406] norm3 <- pool3
I1028 14:12:04.721030 12618 net.cpp:380] norm3 -> norm3
I1028 14:12:04.721181 12618 net.cpp:122] Setting up norm3
I1028 14:12:04.721186 12618 net.cpp:129] Top shape: 100 64 4 4 (102400)
I1028 14:12:04.721201 12618 net.cpp:137] Memory required for data: 54478000
I1028 14:12:04.721210 12618 layer_factory.hpp:77] Creating layer conv4
I1028 14:12:04.721216 12618 net.cpp:84] Creating Layer conv4
I1028 14:12:04.721220 12618 net.cpp:406] conv4 <- norm3
I1028 14:12:04.721226 12618 net.cpp:380] conv4 -> conv4
I1028 14:12:04.722420 12618 net.cpp:122] Setting up conv4
I1028 14:12:04.722429 12618 net.cpp:129] Top shape: 100 64 4 4 (102400)
I1028 14:12:04.722430 12618 net.cpp:137] Memory required for data: 54887600
I1028 14:12:04.722434 12618 layer_factory.hpp:77] Creating layer relu4
I1028 14:12:04.722439 12618 net.cpp:84] Creating Layer relu4
I1028 14:12:04.722440 12618 net.cpp:406] relu4 <- conv4
I1028 14:12:04.722443 12618 net.cpp:367] relu4 -> conv4 (in-place)
I1028 14:12:04.722755 12618 net.cpp:122] Setting up relu4
I1028 14:12:04.722762 12618 net.cpp:129] Top shape: 100 64 4 4 (102400)
I1028 14:12:04.722764 12618 net.cpp:137] Memory required for data: 55297200
I1028 14:12:04.722767 12618 layer_factory.hpp:77] Creating layer pool4
I1028 14:12:04.722772 12618 net.cpp:84] Creating Layer pool4
I1028 14:12:04.722774 12618 net.cpp:406] pool4 <- conv4
I1028 14:12:04.722777 12618 net.cpp:380] pool4 -> pool4
I1028 14:12:04.722836 12618 net.cpp:122] Setting up pool4
I1028 14:12:04.722839 12618 net.cpp:129] Top shape: 100 64 2 2 (25600)
I1028 14:12:04.722841 12618 net.cpp:137] Memory required for data: 55399600
I1028 14:12:04.722842 12618 layer_factory.hpp:77] Creating layer norm4
I1028 14:12:04.722847 12618 net.cpp:84] Creating Layer norm4
I1028 14:12:04.722849 12618 net.cpp:406] norm4 <- pool4
I1028 14:12:04.722869 12618 net.cpp:380] norm4 -> norm4
I1028 14:12:04.723063 12618 net.cpp:122] Setting up norm4
I1028 14:12:04.723070 12618 net.cpp:129] Top shape: 100 64 2 2 (25600)
I1028 14:12:04.723073 12618 net.cpp:137] Memory required for data: 55502000
I1028 14:12:04.723073 12618 layer_factory.hpp:77] Creating layer fc65
I1028 14:12:04.723078 12618 net.cpp:84] Creating Layer fc65
I1028 14:12:04.723079 12618 net.cpp:406] fc65 <- norm4
I1028 14:12:04.723083 12618 net.cpp:380] fc65 -> fc65
I1028 14:12:04.724774 12618 net.cpp:122] Setting up fc65
I1028 14:12:04.724779 12618 net.cpp:129] Top shape: 100 1024 (102400)
I1028 14:12:04.724782 12618 net.cpp:137] Memory required for data: 55911600
I1028 14:12:04.724787 12618 layer_factory.hpp:77] Creating layer relu65
I1028 14:12:04.724791 12618 net.cpp:84] Creating Layer relu65
I1028 14:12:04.724792 12618 net.cpp:406] relu65 <- fc65
I1028 14:12:04.724797 12618 net.cpp:367] relu65 -> fc65 (in-place)
I1028 14:12:04.724936 12618 net.cpp:122] Setting up relu65
I1028 14:12:04.724941 12618 net.cpp:129] Top shape: 100 1024 (102400)
I1028 14:12:04.724943 12618 net.cpp:137] Memory required for data: 56321200
I1028 14:12:04.724946 12618 layer_factory.hpp:77] Creating layer drop65
I1028 14:12:04.724948 12618 net.cpp:84] Creating Layer drop65
I1028 14:12:04.724951 12618 net.cpp:406] drop65 <- fc65
I1028 14:12:04.724952 12618 net.cpp:367] drop65 -> fc65 (in-place)
I1028 14:12:04.724983 12618 net.cpp:122] Setting up drop65
I1028 14:12:04.724987 12618 net.cpp:129] Top shape: 100 1024 (102400)
I1028 14:12:04.724988 12618 net.cpp:137] Memory required for data: 56730800
I1028 14:12:04.724989 12618 layer_factory.hpp:77] Creating layer fc100
I1028 14:12:04.724993 12618 net.cpp:84] Creating Layer fc100
I1028 14:12:04.724995 12618 net.cpp:406] fc100 <- fc65
I1028 14:12:04.724998 12618 net.cpp:380] fc100 -> fc100
I1028 14:12:04.725502 12618 net.cpp:122] Setting up fc100
I1028 14:12:04.725507 12618 net.cpp:129] Top shape: 100 62 (6200)
I1028 14:12:04.725507 12618 net.cpp:137] Memory required for data: 56755600
I1028 14:12:04.725510 12618 layer_factory.hpp:77] Creating layer fc100_fc100_0_split
I1028 14:12:04.725528 12618 net.cpp:84] Creating Layer fc100_fc100_0_split
I1028 14:12:04.725529 12618 net.cpp:406] fc100_fc100_0_split <- fc100
I1028 14:12:04.725533 12618 net.cpp:380] fc100_fc100_0_split -> fc100_fc100_0_split_0
I1028 14:12:04.725538 12618 net.cpp:380] fc100_fc100_0_split -> fc100_fc100_0_split_1
I1028 14:12:04.725560 12618 net.cpp:122] Setting up fc100_fc100_0_split
I1028 14:12:04.725585 12618 net.cpp:129] Top shape: 100 62 (6200)
I1028 14:12:04.725587 12618 net.cpp:129] Top shape: 100 62 (6200)
I1028 14:12:04.725589 12618 net.cpp:137] Memory required for data: 56805200
I1028 14:12:04.725590 12618 layer_factory.hpp:77] Creating layer loss
I1028 14:12:04.725594 12618 net.cpp:84] Creating Layer loss
I1028 14:12:04.725595 12618 net.cpp:406] loss <- fc100_fc100_0_split_0
I1028 14:12:04.725599 12618 net.cpp:406] loss <- label_face_1_split_0
I1028 14:12:04.725601 12618 net.cpp:380] loss -> loss
I1028 14:12:04.725606 12618 layer_factory.hpp:77] Creating layer loss
I1028 14:12:04.725800 12618 net.cpp:122] Setting up loss
I1028 14:12:04.725805 12618 net.cpp:129] Top shape: (1)
I1028 14:12:04.725806 12618 net.cpp:132]     with loss weight 1
I1028 14:12:04.725812 12618 net.cpp:137] Memory required for data: 56805204
I1028 14:12:04.725814 12618 layer_factory.hpp:77] Creating layer acc
I1028 14:12:04.725817 12618 net.cpp:84] Creating Layer acc
I1028 14:12:04.725819 12618 net.cpp:406] acc <- fc100_fc100_0_split_1
I1028 14:12:04.725822 12618 net.cpp:406] acc <- label_face_1_split_1
I1028 14:12:04.725826 12618 net.cpp:380] acc -> acc
I1028 14:12:04.725831 12618 net.cpp:122] Setting up acc
I1028 14:12:04.725847 12618 net.cpp:129] Top shape: (1)
I1028 14:12:04.725849 12618 net.cpp:137] Memory required for data: 56805208
I1028 14:12:04.725852 12618 net.cpp:200] acc does not need backward computation.
I1028 14:12:04.725853 12618 net.cpp:198] loss needs backward computation.
I1028 14:12:04.725855 12618 net.cpp:198] fc100_fc100_0_split needs backward computation.
I1028 14:12:04.725857 12618 net.cpp:198] fc100 needs backward computation.
I1028 14:12:04.725859 12618 net.cpp:198] drop65 needs backward computation.
I1028 14:12:04.725862 12618 net.cpp:198] relu65 needs backward computation.
I1028 14:12:04.725862 12618 net.cpp:198] fc65 needs backward computation.
I1028 14:12:04.725864 12618 net.cpp:198] norm4 needs backward computation.
I1028 14:12:04.725867 12618 net.cpp:198] pool4 needs backward computation.
I1028 14:12:04.725868 12618 net.cpp:198] relu4 needs backward computation.
I1028 14:12:04.725869 12618 net.cpp:198] conv4 needs backward computation.
I1028 14:12:04.725872 12618 net.cpp:198] norm3 needs backward computation.
I1028 14:12:04.725873 12618 net.cpp:198] pool3 needs backward computation.
I1028 14:12:04.725875 12618 net.cpp:198] relu3 needs backward computation.
I1028 14:12:04.725878 12618 net.cpp:198] conv3 needs backward computation.
I1028 14:12:04.725879 12618 net.cpp:198] norm2 needs backward computation.
I1028 14:12:04.725880 12618 net.cpp:198] pool2 needs backward computation.
I1028 14:12:04.725883 12618 net.cpp:198] relu2 needs backward computation.
I1028 14:12:04.725883 12618 net.cpp:198] conv2 needs backward computation.
I1028 14:12:04.725885 12618 net.cpp:198] norm1 needs backward computation.
I1028 14:12:04.725888 12618 net.cpp:198] pool1 needs backward computation.
I1028 14:12:04.725889 12618 net.cpp:198] relu1 needs backward computation.
I1028 14:12:04.725890 12618 net.cpp:198] conv1 needs backward computation.
I1028 14:12:04.725893 12618 net.cpp:200] label_face_1_split does not need backward computation.
I1028 14:12:04.725895 12618 net.cpp:200] face does not need backward computation.
I1028 14:12:04.725896 12618 net.cpp:242] This network produces output acc
I1028 14:12:04.725898 12618 net.cpp:242] This network produces output loss
I1028 14:12:04.725910 12618 net.cpp:255] Network initialization done.
I1028 14:12:04.725950 12618 solver.cpp:56] Solver scaffolding done.
I1028 14:12:04.726243 12618 caffe.cpp:248] Starting Optimization
I1028 14:12:04.726248 12618 solver.cpp:272] Solving 
I1028 14:12:04.726249 12618 solver.cpp:273] Learning Rate Policy: inv
I1028 14:12:04.726740 12618 solver.cpp:330] Iteration 0, Testing net (#0)
I1028 14:12:04.749500 12618 solver.cpp:397]     Test net output #0: acc = 0.015
I1028 14:12:04.749521 12618 solver.cpp:397]     Test net output #1: loss = 4.19418 (* 1 = 4.19418 loss)
I1028 14:12:04.761493 12618 solver.cpp:218] Iteration 0 (9.39714e-24 iter/s, 0.0352266s/200 iters), loss = 4.1666
I1028 14:12:04.761535 12618 solver.cpp:237]     Train net output #0: loss = 4.1666 (* 1 = 4.1666 loss)
I1028 14:12:04.761559 12618 sgd_solver.cpp:105] Iteration 0, lr = 0.003
I1028 14:12:06.291888 12618 solver.cpp:218] Iteration 200 (130.695 iter/s, 1.53028s/200 iters), loss = 4.03145
I1028 14:12:06.291915 12618 solver.cpp:237]     Train net output #0: loss = 4.03145 (* 1 = 4.03145 loss)
I1028 14:12:06.291919 12618 sgd_solver.cpp:105] Iteration 200, lr = 0.00289028
I1028 14:12:07.753926 12618 solver.cpp:218] Iteration 400 (136.804 iter/s, 1.46195s/200 iters), loss = 1.75918
I1028 14:12:07.753949 12618 solver.cpp:237]     Train net output #0: loss = 1.75918 (* 1 = 1.75918 loss)
I1028 14:12:07.753954 12618 sgd_solver.cpp:105] Iteration 400, lr = 0.00278849
I1028 14:12:09.200944 12618 solver.cpp:218] Iteration 600 (138.223 iter/s, 1.44693s/200 iters), loss = 0.616062
I1028 14:12:09.200970 12618 solver.cpp:237]     Train net output #0: loss = 0.616062 (* 1 = 0.616062 loss)
I1028 14:12:09.200974 12618 sgd_solver.cpp:105] Iteration 600, lr = 0.00269379
I1028 14:12:10.497854 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:12:10.666791 12618 solver.cpp:218] Iteration 800 (136.448 iter/s, 1.46576s/200 iters), loss = 0.536591
I1028 14:12:10.666831 12618 solver.cpp:237]     Train net output #0: loss = 0.536591 (* 1 = 0.536591 loss)
I1028 14:12:10.666836 12618 sgd_solver.cpp:105] Iteration 800, lr = 0.00260547
I1028 14:12:12.121726 12618 solver.cpp:330] Iteration 1000, Testing net (#0)
I1028 14:12:12.147527 12618 solver.cpp:397]     Test net output #0: acc = 0.864
I1028 14:12:12.147565 12618 solver.cpp:397]     Test net output #1: loss = 0.401416 (* 1 = 0.401416 loss)
I1028 14:12:12.155153 12618 solver.cpp:218] Iteration 1000 (134.384 iter/s, 1.48827s/200 iters), loss = 0.356575
I1028 14:12:12.155176 12618 solver.cpp:237]     Train net output #0: loss = 0.356575 (* 1 = 0.356575 loss)
I1028 14:12:12.155184 12618 sgd_solver.cpp:105] Iteration 1000, lr = 0.00252289
I1028 14:12:13.622591 12618 solver.cpp:218] Iteration 1200 (136.3 iter/s, 1.46735s/200 iters), loss = 0.378696
I1028 14:12:13.622613 12618 solver.cpp:237]     Train net output #0: loss = 0.378696 (* 1 = 0.378696 loss)
I1028 14:12:13.622618 12618 sgd_solver.cpp:105] Iteration 1200, lr = 0.00244552
I1028 14:12:15.074193 12618 solver.cpp:218] Iteration 1400 (137.787 iter/s, 1.45152s/200 iters), loss = 0.287409
I1028 14:12:15.074231 12618 solver.cpp:237]     Train net output #0: loss = 0.287409 (* 1 = 0.287409 loss)
I1028 14:12:15.074235 12618 sgd_solver.cpp:105] Iteration 1400, lr = 0.00237286
I1028 14:12:16.235877 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:12:16.544829 12618 solver.cpp:218] Iteration 1600 (136.005 iter/s, 1.47054s/200 iters), loss = 0.275412
I1028 14:12:16.544868 12618 solver.cpp:237]     Train net output #0: loss = 0.275412 (* 1 = 0.275412 loss)
I1028 14:12:16.544872 12618 sgd_solver.cpp:105] Iteration 1600, lr = 0.0023045
I1028 14:12:18.003579 12618 solver.cpp:218] Iteration 1800 (137.112 iter/s, 1.45866s/200 iters), loss = 0.209216
I1028 14:12:18.003604 12618 solver.cpp:237]     Train net output #0: loss = 0.209216 (* 1 = 0.209216 loss)
I1028 14:12:18.003608 12618 sgd_solver.cpp:105] Iteration 1800, lr = 0.00224006
I1028 14:12:19.437336 12618 solver.cpp:330] Iteration 2000, Testing net (#0)
I1028 14:12:19.463984 12618 solver.cpp:397]     Test net output #0: acc = 0.919
I1028 14:12:19.464028 12618 solver.cpp:397]     Test net output #1: loss = 0.228021 (* 1 = 0.228021 loss)
I1028 14:12:19.472731 12618 solver.cpp:218] Iteration 2000 (136.141 iter/s, 1.46907s/200 iters), loss = 0.146879
I1028 14:12:19.472754 12618 solver.cpp:237]     Train net output #0: loss = 0.146879 (* 1 = 0.146879 loss)
I1028 14:12:19.472760 12618 sgd_solver.cpp:105] Iteration 2000, lr = 0.00217921
I1028 14:12:20.946928 12618 solver.cpp:218] Iteration 2200 (135.675 iter/s, 1.47411s/200 iters), loss = 0.209908
I1028 14:12:20.946954 12618 solver.cpp:237]     Train net output #0: loss = 0.209908 (* 1 = 0.209908 loss)
I1028 14:12:20.946975 12618 sgd_solver.cpp:105] Iteration 2200, lr = 0.00212167
I1028 14:12:21.971755 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:12:22.419942 12618 solver.cpp:218] Iteration 2400 (135.784 iter/s, 1.47292s/200 iters), loss = 0.181047
I1028 14:12:22.419983 12618 solver.cpp:237]     Train net output #0: loss = 0.181047 (* 1 = 0.181047 loss)
I1028 14:12:22.419987 12618 sgd_solver.cpp:105] Iteration 2400, lr = 0.00206715
I1028 14:12:23.889345 12618 solver.cpp:218] Iteration 2600 (136.119 iter/s, 1.46931s/200 iters), loss = 0.215709
I1028 14:12:23.889370 12618 solver.cpp:237]     Train net output #0: loss = 0.215709 (* 1 = 0.215709 loss)
I1028 14:12:23.889374 12618 sgd_solver.cpp:105] Iteration 2600, lr = 0.00201544
I1028 14:12:25.351193 12618 solver.cpp:218] Iteration 2800 (136.821 iter/s, 1.46176s/200 iters), loss = 0.313141
I1028 14:12:25.351217 12618 solver.cpp:237]     Train net output #0: loss = 0.313141 (* 1 = 0.313141 loss)
I1028 14:12:25.351222 12618 sgd_solver.cpp:105] Iteration 2800, lr = 0.00196631
I1028 14:12:26.807188 12618 solver.cpp:330] Iteration 3000, Testing net (#0)
I1028 14:12:26.835728 12618 solver.cpp:397]     Test net output #0: acc = 0.928
I1028 14:12:26.835750 12618 solver.cpp:397]     Test net output #1: loss = 0.19435 (* 1 = 0.19435 loss)
I1028 14:12:26.843178 12618 solver.cpp:218] Iteration 3000 (134.057 iter/s, 1.4919s/200 iters), loss = 0.172785
I1028 14:12:26.843196 12618 solver.cpp:237]     Train net output #0: loss = 0.172785 (* 1 = 0.172785 loss)
I1028 14:12:26.843202 12618 sgd_solver.cpp:105] Iteration 3000, lr = 0.00191958
I1028 14:12:27.730083 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:12:28.313983 12618 solver.cpp:218] Iteration 3200 (135.987 iter/s, 1.47073s/200 iters), loss = 0.207641
I1028 14:12:28.314007 12618 solver.cpp:237]     Train net output #0: loss = 0.207641 (* 1 = 0.207641 loss)
I1028 14:12:28.314010 12618 sgd_solver.cpp:105] Iteration 3200, lr = 0.00187508
I1028 14:12:29.786450 12618 solver.cpp:218] Iteration 3400 (135.834 iter/s, 1.47238s/200 iters), loss = 0.288748
I1028 14:12:29.786474 12618 solver.cpp:237]     Train net output #0: loss = 0.288748 (* 1 = 0.288748 loss)
I1028 14:12:29.786478 12618 sgd_solver.cpp:105] Iteration 3400, lr = 0.00183264
I1028 14:12:31.256213 12618 solver.cpp:218] Iteration 3600 (136.084 iter/s, 1.46968s/200 iters), loss = 0.203769
I1028 14:12:31.256238 12618 solver.cpp:237]     Train net output #0: loss = 0.203769 (* 1 = 0.203769 loss)
I1028 14:12:31.256242 12618 sgd_solver.cpp:105] Iteration 3600, lr = 0.00179213
I1028 14:12:32.729351 12618 solver.cpp:218] Iteration 3800 (135.772 iter/s, 1.47305s/200 iters), loss = 0.156563
I1028 14:12:32.729375 12618 solver.cpp:237]     Train net output #0: loss = 0.156563 (* 1 = 0.156563 loss)
I1028 14:12:32.729379 12618 sgd_solver.cpp:105] Iteration 3800, lr = 0.00175341
I1028 14:12:33.485898 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:12:34.197795 12618 solver.cpp:330] Iteration 4000, Testing net (#0)
I1028 14:12:34.221940 12618 solver.cpp:397]     Test net output #0: acc = 0.942
I1028 14:12:34.221961 12618 solver.cpp:397]     Test net output #1: loss = 0.161911 (* 1 = 0.161911 loss)
I1028 14:12:34.230619 12618 solver.cpp:218] Iteration 4000 (133.228 iter/s, 1.50118s/200 iters), loss = 0.243317
I1028 14:12:34.230643 12618 solver.cpp:237]     Train net output #0: loss = 0.243317 (* 1 = 0.243317 loss)
I1028 14:12:34.230648 12618 sgd_solver.cpp:105] Iteration 4000, lr = 0.00171638
I1028 14:12:35.698225 12618 solver.cpp:218] Iteration 4200 (136.284 iter/s, 1.46752s/200 iters), loss = 0.120697
I1028 14:12:35.698369 12618 solver.cpp:237]     Train net output #0: loss = 0.120697 (* 1 = 0.120697 loss)
I1028 14:12:35.698374 12618 sgd_solver.cpp:105] Iteration 4200, lr = 0.00168091
I1028 14:12:37.164572 12618 solver.cpp:218] Iteration 4400 (136.411 iter/s, 1.46616s/200 iters), loss = 0.167544
I1028 14:12:37.164595 12618 solver.cpp:237]     Train net output #0: loss = 0.167544 (* 1 = 0.167544 loss)
I1028 14:12:37.164599 12618 sgd_solver.cpp:105] Iteration 4400, lr = 0.00164692
I1028 14:12:38.635284 12618 solver.cpp:218] Iteration 4600 (135.996 iter/s, 1.47063s/200 iters), loss = 0.172135
I1028 14:12:38.635311 12618 solver.cpp:237]     Train net output #0: loss = 0.172135 (* 1 = 0.172135 loss)
I1028 14:12:38.635315 12618 sgd_solver.cpp:105] Iteration 4600, lr = 0.0016143
I1028 14:12:39.251641 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:12:40.117207 12618 solver.cpp:218] Iteration 4800 (134.968 iter/s, 1.48184s/200 iters), loss = 0.133006
I1028 14:12:40.117230 12618 solver.cpp:237]     Train net output #0: loss = 0.133006 (* 1 = 0.133006 loss)
I1028 14:12:40.117234 12618 sgd_solver.cpp:105] Iteration 4800, lr = 0.00158299
I1028 14:12:41.577280 12618 solver.cpp:330] Iteration 5000, Testing net (#0)
I1028 14:12:41.602901 12618 solver.cpp:397]     Test net output #0: acc = 0.949
I1028 14:12:41.602922 12618 solver.cpp:397]     Test net output #1: loss = 0.154856 (* 1 = 0.154856 loss)
I1028 14:12:41.611263 12618 solver.cpp:218] Iteration 5000 (133.871 iter/s, 1.49397s/200 iters), loss = 0.153283
I1028 14:12:41.611282 12618 solver.cpp:237]     Train net output #0: loss = 0.153283 (* 1 = 0.153283 loss)
I1028 14:12:41.611287 12618 sgd_solver.cpp:105] Iteration 5000, lr = 0.0015529
I1028 14:12:43.084262 12618 solver.cpp:218] Iteration 5200 (135.785 iter/s, 1.47292s/200 iters), loss = 0.223833
I1028 14:12:43.084286 12618 solver.cpp:237]     Train net output #0: loss = 0.223833 (* 1 = 0.223833 loss)
I1028 14:12:43.084291 12618 sgd_solver.cpp:105] Iteration 5200, lr = 0.00152396
I1028 14:12:44.561163 12618 solver.cpp:218] Iteration 5400 (135.426 iter/s, 1.47682s/200 iters), loss = 0.177979
I1028 14:12:44.561187 12618 solver.cpp:237]     Train net output #0: loss = 0.177979 (* 1 = 0.177979 loss)
I1028 14:12:44.561190 12618 sgd_solver.cpp:105] Iteration 5400, lr = 0.0014961
I1028 14:12:45.033473 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:12:46.036176 12618 solver.cpp:218] Iteration 5600 (135.6 iter/s, 1.47493s/200 iters), loss = 0.153186
I1028 14:12:46.036201 12618 solver.cpp:237]     Train net output #0: loss = 0.153186 (* 1 = 0.153186 loss)
I1028 14:12:46.036206 12618 sgd_solver.cpp:105] Iteration 5600, lr = 0.00146927
I1028 14:12:47.498952 12618 solver.cpp:218] Iteration 5800 (136.734 iter/s, 1.46269s/200 iters), loss = 0.167377
I1028 14:12:47.498977 12618 solver.cpp:237]     Train net output #0: loss = 0.167377 (* 1 = 0.167377 loss)
I1028 14:12:47.498981 12618 sgd_solver.cpp:105] Iteration 5800, lr = 0.00144341
I1028 14:12:48.960006 12618 solver.cpp:330] Iteration 6000, Testing net (#0)
I1028 14:12:48.985401 12618 solver.cpp:397]     Test net output #0: acc = 0.966
I1028 14:12:48.985424 12618 solver.cpp:397]     Test net output #1: loss = 0.124683 (* 1 = 0.124683 loss)
I1028 14:12:48.994148 12618 solver.cpp:218] Iteration 6000 (133.769 iter/s, 1.49511s/200 iters), loss = 0.146548
I1028 14:12:48.994165 12618 solver.cpp:237]     Train net output #0: loss = 0.146548 (* 1 = 0.146548 loss)
I1028 14:12:48.994170 12618 sgd_solver.cpp:105] Iteration 6000, lr = 0.00141847
I1028 14:12:50.471382 12618 solver.cpp:218] Iteration 6200 (135.395 iter/s, 1.47716s/200 iters), loss = 0.196908
I1028 14:12:50.471406 12618 solver.cpp:237]     Train net output #0: loss = 0.196908 (* 1 = 0.196908 loss)
I1028 14:12:50.471410 12618 sgd_solver.cpp:105] Iteration 6200, lr = 0.00139439
I1028 14:12:50.808466 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:12:51.947827 12618 solver.cpp:218] Iteration 6400 (135.468 iter/s, 1.47636s/200 iters), loss = 0.155531
I1028 14:12:51.947851 12618 solver.cpp:237]     Train net output #0: loss = 0.155531 (* 1 = 0.155531 loss)
I1028 14:12:51.947887 12618 sgd_solver.cpp:105] Iteration 6400, lr = 0.00137114
I1028 14:12:53.411161 12618 solver.cpp:218] Iteration 6600 (136.682 iter/s, 1.46325s/200 iters), loss = 0.173372
I1028 14:12:53.411185 12618 solver.cpp:237]     Train net output #0: loss = 0.173372 (* 1 = 0.173372 loss)
I1028 14:12:53.411190 12618 sgd_solver.cpp:105] Iteration 6600, lr = 0.00134868
I1028 14:12:54.876014 12618 solver.cpp:218] Iteration 6800 (136.54 iter/s, 1.46477s/200 iters), loss = 0.227506
I1028 14:12:54.876039 12618 solver.cpp:237]     Train net output #0: loss = 0.227506 (* 1 = 0.227506 loss)
I1028 14:12:54.876042 12618 sgd_solver.cpp:105] Iteration 6800, lr = 0.00132695
I1028 14:12:56.332459 12618 solver.cpp:330] Iteration 7000, Testing net (#0)
I1028 14:12:56.357931 12618 solver.cpp:397]     Test net output #0: acc = 0.925
I1028 14:12:56.357955 12618 solver.cpp:397]     Test net output #1: loss = 0.211018 (* 1 = 0.211018 loss)
I1028 14:12:56.366065 12618 solver.cpp:218] Iteration 7000 (134.231 iter/s, 1.48997s/200 iters), loss = 0.137609
I1028 14:12:56.366083 12618 solver.cpp:237]     Train net output #0: loss = 0.137609 (* 1 = 0.137609 loss)
I1028 14:12:56.366091 12618 sgd_solver.cpp:105] Iteration 7000, lr = 0.00130593
I1028 14:12:56.573732 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:12:57.848913 12618 solver.cpp:218] Iteration 7200 (134.883 iter/s, 1.48277s/200 iters), loss = 0.229143
I1028 14:12:57.848938 12618 solver.cpp:237]     Train net output #0: loss = 0.229143 (* 1 = 0.229143 loss)
I1028 14:12:57.848943 12618 sgd_solver.cpp:105] Iteration 7200, lr = 0.00128559
I1028 14:12:59.322465 12618 solver.cpp:218] Iteration 7400 (135.734 iter/s, 1.47347s/200 iters), loss = 0.158632
I1028 14:12:59.322489 12618 solver.cpp:237]     Train net output #0: loss = 0.158632 (* 1 = 0.158632 loss)
I1028 14:12:59.322494 12618 sgd_solver.cpp:105] Iteration 7400, lr = 0.00126588
I1028 14:13:00.780930 12618 solver.cpp:218] Iteration 7600 (137.138 iter/s, 1.45838s/200 iters), loss = 0.135106
I1028 14:13:00.780956 12618 solver.cpp:237]     Train net output #0: loss = 0.135106 (* 1 = 0.135106 loss)
I1028 14:13:00.780961 12618 sgd_solver.cpp:105] Iteration 7600, lr = 0.00124678
I1028 14:13:02.243330 12618 solver.cpp:218] Iteration 7800 (136.77 iter/s, 1.46231s/200 iters), loss = 0.147572
I1028 14:13:02.243353 12618 solver.cpp:237]     Train net output #0: loss = 0.147572 (* 1 = 0.147572 loss)
I1028 14:13:02.243358 12618 sgd_solver.cpp:105] Iteration 7800, lr = 0.00122827
I1028 14:13:02.308044 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:13:03.712049 12618 solver.cpp:330] Iteration 8000, Testing net (#0)
I1028 14:13:03.737246 12618 solver.cpp:397]     Test net output #0: acc = 0.949
I1028 14:13:03.737267 12618 solver.cpp:397]     Test net output #1: loss = 0.146949 (* 1 = 0.146949 loss)
I1028 14:13:03.745863 12618 solver.cpp:218] Iteration 8000 (133.116 iter/s, 1.50245s/200 iters), loss = 0.111798
I1028 14:13:03.745883 12618 solver.cpp:237]     Train net output #0: loss = 0.111798 (* 1 = 0.111798 loss)
I1028 14:13:03.745888 12618 sgd_solver.cpp:105] Iteration 8000, lr = 0.00121031
I1028 14:13:05.220974 12618 solver.cpp:218] Iteration 8200 (135.59 iter/s, 1.47503s/200 iters), loss = 0.0912597
I1028 14:13:05.220999 12618 solver.cpp:237]     Train net output #0: loss = 0.0912597 (* 1 = 0.0912597 loss)
I1028 14:13:05.221004 12618 sgd_solver.cpp:105] Iteration 8200, lr = 0.00119288
I1028 14:13:06.683293 12618 solver.cpp:218] Iteration 8400 (136.777 iter/s, 1.46224s/200 iters), loss = 0.121535
I1028 14:13:06.683439 12618 solver.cpp:237]     Train net output #0: loss = 0.121535 (* 1 = 0.121535 loss)
I1028 14:13:06.683445 12618 sgd_solver.cpp:105] Iteration 8400, lr = 0.00117596
I1028 14:13:08.076581 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:13:08.157011 12618 solver.cpp:218] Iteration 8600 (135.729 iter/s, 1.47353s/200 iters), loss = 0.158113
I1028 14:13:08.157037 12618 solver.cpp:237]     Train net output #0: loss = 0.158113 (* 1 = 0.158113 loss)
I1028 14:13:08.157042 12618 sgd_solver.cpp:105] Iteration 8600, lr = 0.00115953
I1028 14:13:09.612628 12618 solver.cpp:218] Iteration 8800 (137.407 iter/s, 1.45553s/200 iters), loss = 0.125964
I1028 14:13:09.612653 12618 solver.cpp:237]     Train net output #0: loss = 0.125964 (* 1 = 0.125964 loss)
I1028 14:13:09.612658 12618 sgd_solver.cpp:105] Iteration 8800, lr = 0.00114356
I1028 14:13:11.071784 12618 solver.cpp:330] Iteration 9000, Testing net (#0)
I1028 14:13:11.091980 12627 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:13:11.097614 12618 solver.cpp:397]     Test net output #0: acc = 0.958
I1028 14:13:11.097646 12618 solver.cpp:397]     Test net output #1: loss = 0.135299 (* 1 = 0.135299 loss)
I1028 14:13:11.106006 12618 solver.cpp:218] Iteration 9000 (133.932 iter/s, 1.4933s/200 iters), loss = 0.186722
I1028 14:13:11.106039 12618 solver.cpp:237]     Train net output #0: loss = 0.186722 (* 1 = 0.186722 loss)
I1028 14:13:11.106043 12618 sgd_solver.cpp:105] Iteration 9000, lr = 0.00112803
I1028 14:13:12.573506 12618 solver.cpp:218] Iteration 9200 (136.295 iter/s, 1.46741s/200 iters), loss = 0.13278
I1028 14:13:12.573531 12618 solver.cpp:237]     Train net output #0: loss = 0.13278 (* 1 = 0.13278 loss)
I1028 14:13:12.573535 12618 sgd_solver.cpp:105] Iteration 9200, lr = 0.00111293
I1028 14:13:13.815170 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:13:14.035213 12618 solver.cpp:218] Iteration 9400 (136.834 iter/s, 1.46162s/200 iters), loss = 0.0964758
I1028 14:13:14.035238 12618 solver.cpp:237]     Train net output #0: loss = 0.0964758 (* 1 = 0.0964758 loss)
I1028 14:13:14.035243 12618 sgd_solver.cpp:105] Iteration 9400, lr = 0.00109824
I1028 14:13:15.508354 12618 solver.cpp:218] Iteration 9600 (135.772 iter/s, 1.47306s/200 iters), loss = 0.183721
I1028 14:13:15.508379 12618 solver.cpp:237]     Train net output #0: loss = 0.183721 (* 1 = 0.183721 loss)
I1028 14:13:15.508384 12618 sgd_solver.cpp:105] Iteration 9600, lr = 0.00108395
I1028 14:13:16.989347 12618 solver.cpp:218] Iteration 9800 (135.052 iter/s, 1.48091s/200 iters), loss = 0.109781
I1028 14:13:16.989372 12618 solver.cpp:237]     Train net output #0: loss = 0.109781 (* 1 = 0.109781 loss)
I1028 14:13:16.989377 12618 sgd_solver.cpp:105] Iteration 9800, lr = 0.00107003
I1028 14:13:18.459353 12618 solver.cpp:447] Snapshotting to binary proto file /home/ljf/caffe-master/examples/ljftest_alphabet/caffe_ljftest_train_iter_10000.caffemodel
I1028 14:13:18.467682 12618 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/ljf/caffe-master/examples/ljftest_alphabet/caffe_ljftest_train_iter_10000.solverstate
I1028 14:13:18.469698 12618 solver.cpp:330] Iteration 10000, Testing net (#0)
I1028 14:13:18.492617 12618 solver.cpp:397]     Test net output #0: acc = 0.956
I1028 14:13:18.492638 12618 solver.cpp:397]     Test net output #1: loss = 0.145146 (* 1 = 0.145146 loss)
I1028 14:13:18.499495 12618 solver.cpp:218] Iteration 10000 (132.445 iter/s, 1.51006s/200 iters), loss = 0.133159
I1028 14:13:18.499511 12618 solver.cpp:237]     Train net output #0: loss = 0.133159 (* 1 = 0.133159 loss)
I1028 14:13:18.499518 12618 sgd_solver.cpp:105] Iteration 10000, lr = 0.00105647
I1028 14:13:19.611515 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:13:19.959724 12618 solver.cpp:218] Iteration 10200 (136.973 iter/s, 1.46014s/200 iters), loss = 0.083942
I1028 14:13:19.959750 12618 solver.cpp:237]     Train net output #0: loss = 0.083942 (* 1 = 0.083942 loss)
I1028 14:13:19.959754 12618 sgd_solver.cpp:105] Iteration 10200, lr = 0.00104326
I1028 14:13:21.416822 12618 solver.cpp:218] Iteration 10400 (137.267 iter/s, 1.45701s/200 iters), loss = 0.18286
I1028 14:13:21.416847 12618 solver.cpp:237]     Train net output #0: loss = 0.18286 (* 1 = 0.18286 loss)
I1028 14:13:21.416851 12618 sgd_solver.cpp:105] Iteration 10400, lr = 0.00103038
I1028 14:13:22.891568 12618 solver.cpp:218] Iteration 10600 (135.625 iter/s, 1.47466s/200 iters), loss = 0.114393
I1028 14:13:22.891865 12618 solver.cpp:237]     Train net output #0: loss = 0.114393 (* 1 = 0.114393 loss)
I1028 14:13:22.891875 12618 sgd_solver.cpp:105] Iteration 10600, lr = 0.00101783
I1028 14:13:24.372745 12618 solver.cpp:218] Iteration 10800 (135.06 iter/s, 1.48082s/200 iters), loss = 0.187921
I1028 14:13:24.372769 12618 solver.cpp:237]     Train net output #0: loss = 0.187921 (* 1 = 0.187921 loss)
I1028 14:13:24.372773 12618 sgd_solver.cpp:105] Iteration 10800, lr = 0.00100558
I1028 14:13:25.362884 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:13:25.847126 12618 solver.cpp:330] Iteration 11000, Testing net (#0)
I1028 14:13:25.872695 12618 solver.cpp:397]     Test net output #0: acc = 0.953
I1028 14:13:25.872716 12618 solver.cpp:397]     Test net output #1: loss = 0.149178 (* 1 = 0.149178 loss)
I1028 14:13:25.881683 12618 solver.cpp:218] Iteration 11000 (132.551 iter/s, 1.50885s/200 iters), loss = 0.207372
I1028 14:13:25.881703 12618 solver.cpp:237]     Train net output #0: loss = 0.207372 (* 1 = 0.207372 loss)
I1028 14:13:25.881708 12618 sgd_solver.cpp:105] Iteration 11000, lr = 0.000993639
I1028 14:13:27.352634 12618 solver.cpp:218] Iteration 11200 (135.974 iter/s, 1.47087s/200 iters), loss = 0.167343
I1028 14:13:27.352661 12618 solver.cpp:237]     Train net output #0: loss = 0.167343 (* 1 = 0.167343 loss)
I1028 14:13:27.352666 12618 sgd_solver.cpp:105] Iteration 11200, lr = 0.000981982
I1028 14:13:28.804776 12618 solver.cpp:218] Iteration 11400 (137.736 iter/s, 1.45206s/200 iters), loss = 0.162806
I1028 14:13:28.804801 12618 solver.cpp:237]     Train net output #0: loss = 0.162806 (* 1 = 0.162806 loss)
I1028 14:13:28.804805 12618 sgd_solver.cpp:105] Iteration 11400, lr = 0.000970602
I1028 14:13:30.281205 12618 solver.cpp:218] Iteration 11600 (135.47 iter/s, 1.47634s/200 iters), loss = 0.122216
I1028 14:13:30.281242 12618 solver.cpp:237]     Train net output #0: loss = 0.122216 (* 1 = 0.122216 loss)
I1028 14:13:30.281247 12618 sgd_solver.cpp:105] Iteration 11600, lr = 0.000959489
I1028 14:13:31.129483 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:13:31.767767 12618 solver.cpp:218] Iteration 11800 (134.546 iter/s, 1.48648s/200 iters), loss = 0.110039
I1028 14:13:31.767804 12618 solver.cpp:237]     Train net output #0: loss = 0.110039 (* 1 = 0.110039 loss)
I1028 14:13:31.767809 12618 sgd_solver.cpp:105] Iteration 11800, lr = 0.000948635
I1028 14:13:33.214845 12618 solver.cpp:330] Iteration 12000, Testing net (#0)
I1028 14:13:33.243402 12618 solver.cpp:397]     Test net output #0: acc = 0.948
I1028 14:13:33.243430 12618 solver.cpp:397]     Test net output #1: loss = 0.169464 (* 1 = 0.169464 loss)
I1028 14:13:33.250962 12618 solver.cpp:218] Iteration 12000 (134.851 iter/s, 1.48311s/200 iters), loss = 0.145851
I1028 14:13:33.250979 12618 solver.cpp:237]     Train net output #0: loss = 0.145851 (* 1 = 0.145851 loss)
I1028 14:13:33.250984 12618 sgd_solver.cpp:105] Iteration 12000, lr = 0.000938029
I1028 14:13:34.725669 12618 solver.cpp:218] Iteration 12200 (135.627 iter/s, 1.47463s/200 iters), loss = 0.156856
I1028 14:13:34.725693 12618 solver.cpp:237]     Train net output #0: loss = 0.156856 (* 1 = 0.156856 loss)
I1028 14:13:34.725697 12618 sgd_solver.cpp:105] Iteration 12200, lr = 0.000927664
I1028 14:13:36.196738 12618 solver.cpp:218] Iteration 12400 (135.963 iter/s, 1.47098s/200 iters), loss = 0.10724
I1028 14:13:36.196763 12618 solver.cpp:237]     Train net output #0: loss = 0.10724 (* 1 = 0.10724 loss)
I1028 14:13:36.196768 12618 sgd_solver.cpp:105] Iteration 12400, lr = 0.000917531
I1028 14:13:36.903756 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:13:37.677981 12618 solver.cpp:218] Iteration 12600 (135.03 iter/s, 1.48116s/200 iters), loss = 0.0800464
I1028 14:13:37.678005 12618 solver.cpp:237]     Train net output #0: loss = 0.0800464 (* 1 = 0.0800464 loss)
I1028 14:13:37.678010 12618 sgd_solver.cpp:105] Iteration 12600, lr = 0.000907624
I1028 14:13:39.146540 12618 solver.cpp:218] Iteration 12800 (136.196 iter/s, 1.46848s/200 iters), loss = 0.114104
I1028 14:13:39.146565 12618 solver.cpp:237]     Train net output #0: loss = 0.114104 (* 1 = 0.114104 loss)
I1028 14:13:39.146569 12618 sgd_solver.cpp:105] Iteration 12800, lr = 0.000897933
I1028 14:13:40.617044 12618 solver.cpp:330] Iteration 13000, Testing net (#0)
I1028 14:13:40.642966 12618 solver.cpp:397]     Test net output #0: acc = 0.95
I1028 14:13:40.642989 12618 solver.cpp:397]     Test net output #1: loss = 0.144936 (* 1 = 0.144936 loss)
I1028 14:13:40.651141 12618 solver.cpp:218] Iteration 13000 (132.933 iter/s, 1.50452s/200 iters), loss = 0.165258
I1028 14:13:40.651161 12618 solver.cpp:237]     Train net output #0: loss = 0.165258 (* 1 = 0.165258 loss)
I1028 14:13:40.651167 12618 sgd_solver.cpp:105] Iteration 13000, lr = 0.000888452
I1028 14:13:42.100849 12618 solver.cpp:218] Iteration 13200 (137.966 iter/s, 1.44963s/200 iters), loss = 0.107363
I1028 14:13:42.100889 12618 solver.cpp:237]     Train net output #0: loss = 0.107363 (* 1 = 0.107363 loss)
I1028 14:13:42.100893 12618 sgd_solver.cpp:105] Iteration 13200, lr = 0.000879174
I1028 14:13:42.662758 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:13:43.556867 12618 solver.cpp:218] Iteration 13400 (137.37 iter/s, 1.45592s/200 iters), loss = 0.120698
I1028 14:13:43.556906 12618 solver.cpp:237]     Train net output #0: loss = 0.120698 (* 1 = 0.120698 loss)
I1028 14:13:43.556910 12618 sgd_solver.cpp:105] Iteration 13400, lr = 0.000870093
I1028 14:13:45.032151 12618 solver.cpp:218] Iteration 13600 (135.575 iter/s, 1.4752s/200 iters), loss = 0.24569
I1028 14:13:45.032177 12618 solver.cpp:237]     Train net output #0: loss = 0.24569 (* 1 = 0.24569 loss)
I1028 14:13:45.032181 12618 sgd_solver.cpp:105] Iteration 13600, lr = 0.000861203
I1028 14:13:46.511015 12618 solver.cpp:218] Iteration 13800 (135.247 iter/s, 1.47878s/200 iters), loss = 0.153917
I1028 14:13:46.511041 12618 solver.cpp:237]     Train net output #0: loss = 0.153917 (* 1 = 0.153917 loss)
I1028 14:13:46.511046 12618 sgd_solver.cpp:105] Iteration 13800, lr = 0.000852497
I1028 14:13:47.957006 12618 solver.cpp:330] Iteration 14000, Testing net (#0)
I1028 14:13:47.981778 12618 solver.cpp:397]     Test net output #0: acc = 0.939
I1028 14:13:47.981799 12618 solver.cpp:397]     Test net output #1: loss = 0.159998 (* 1 = 0.159998 loss)
I1028 14:13:47.990286 12618 solver.cpp:218] Iteration 14000 (135.209 iter/s, 1.47919s/200 iters), loss = 0.10977
I1028 14:13:47.990308 12618 solver.cpp:237]     Train net output #0: loss = 0.10977 (* 1 = 0.10977 loss)
I1028 14:13:47.990314 12618 sgd_solver.cpp:105] Iteration 14000, lr = 0.00084397
I1028 14:13:48.422276 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:13:49.470252 12618 solver.cpp:218] Iteration 14200 (135.146 iter/s, 1.47988s/200 iters), loss = 0.140317
I1028 14:13:49.470276 12618 solver.cpp:237]     Train net output #0: loss = 0.140317 (* 1 = 0.140317 loss)
I1028 14:13:49.470280 12618 sgd_solver.cpp:105] Iteration 14200, lr = 0.000835616
I1028 14:13:50.941768 12618 solver.cpp:218] Iteration 14400 (135.922 iter/s, 1.47143s/200 iters), loss = 0.124366
I1028 14:13:50.941792 12618 solver.cpp:237]     Train net output #0: loss = 0.124366 (* 1 = 0.124366 loss)
I1028 14:13:50.941797 12618 sgd_solver.cpp:105] Iteration 14400, lr = 0.00082743
I1028 14:13:52.421378 12618 solver.cpp:218] Iteration 14600 (135.178 iter/s, 1.47953s/200 iters), loss = 0.172878
I1028 14:13:52.421402 12618 solver.cpp:237]     Train net output #0: loss = 0.172878 (* 1 = 0.172878 loss)
I1028 14:13:52.421406 12618 sgd_solver.cpp:105] Iteration 14600, lr = 0.000819407
I1028 14:13:53.892033 12618 solver.cpp:218] Iteration 14800 (136.002 iter/s, 1.47057s/200 iters), loss = 0.136837
I1028 14:13:53.892076 12618 solver.cpp:237]     Train net output #0: loss = 0.136837 (* 1 = 0.136837 loss)
I1028 14:13:53.892081 12618 sgd_solver.cpp:105] Iteration 14800, lr = 0.000811542
I1028 14:13:54.186763 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:13:55.363895 12618 solver.cpp:330] Iteration 15000, Testing net (#0)
I1028 14:13:55.389366 12618 solver.cpp:397]     Test net output #0: acc = 0.955
I1028 14:13:55.389386 12618 solver.cpp:397]     Test net output #1: loss = 0.132901 (* 1 = 0.132901 loss)
I1028 14:13:55.397725 12618 solver.cpp:218] Iteration 15000 (132.838 iter/s, 1.50559s/200 iters), loss = 0.171022
I1028 14:13:55.397744 12618 solver.cpp:237]     Train net output #0: loss = 0.171022 (* 1 = 0.171022 loss)
I1028 14:13:55.397748 12618 sgd_solver.cpp:105] Iteration 15000, lr = 0.00080383
I1028 14:13:56.879128 12618 solver.cpp:218] Iteration 15200 (135.014 iter/s, 1.48132s/200 iters), loss = 0.131605
I1028 14:13:56.879153 12618 solver.cpp:237]     Train net output #0: loss = 0.131605 (* 1 = 0.131605 loss)
I1028 14:13:56.879156 12618 sgd_solver.cpp:105] Iteration 15200, lr = 0.000796267
I1028 14:13:58.346402 12618 solver.cpp:218] Iteration 15400 (136.315 iter/s, 1.46719s/200 iters), loss = 0.163473
I1028 14:13:58.346427 12618 solver.cpp:237]     Train net output #0: loss = 0.163473 (* 1 = 0.163473 loss)
I1028 14:13:58.346431 12618 sgd_solver.cpp:105] Iteration 15400, lr = 0.000788849
I1028 14:13:59.824360 12618 solver.cpp:218] Iteration 15600 (135.33 iter/s, 1.47787s/200 iters), loss = 0.131273
I1028 14:13:59.824383 12618 solver.cpp:237]     Train net output #0: loss = 0.131273 (* 1 = 0.131273 loss)
I1028 14:13:59.824388 12618 sgd_solver.cpp:105] Iteration 15600, lr = 0.000781572
I1028 14:13:59.974860 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:14:01.310344 12618 solver.cpp:218] Iteration 15800 (134.599 iter/s, 1.4859s/200 iters), loss = 0.120237
I1028 14:14:01.310382 12618 solver.cpp:237]     Train net output #0: loss = 0.120237 (* 1 = 0.120237 loss)
I1028 14:14:01.310387 12618 sgd_solver.cpp:105] Iteration 15800, lr = 0.000774431
I1028 14:14:02.765064 12618 solver.cpp:330] Iteration 16000, Testing net (#0)
I1028 14:14:02.790874 12618 solver.cpp:397]     Test net output #0: acc = 0.976
I1028 14:14:02.790900 12618 solver.cpp:397]     Test net output #1: loss = 0.108241 (* 1 = 0.108241 loss)
I1028 14:14:02.799398 12618 solver.cpp:218] Iteration 16000 (134.321 iter/s, 1.48897s/200 iters), loss = 0.0996772
I1028 14:14:02.799418 12618 solver.cpp:237]     Train net output #0: loss = 0.0996772 (* 1 = 0.0996772 loss)
I1028 14:14:02.799423 12618 sgd_solver.cpp:105] Iteration 16000, lr = 0.000767422
I1028 14:14:04.260341 12618 solver.cpp:218] Iteration 16200 (136.905 iter/s, 1.46086s/200 iters), loss = 0.110937
I1028 14:14:04.260380 12618 solver.cpp:237]     Train net output #0: loss = 0.110937 (* 1 = 0.110937 loss)
I1028 14:14:04.260383 12618 sgd_solver.cpp:105] Iteration 16200, lr = 0.000760543
I1028 14:14:05.741693 12618 solver.cpp:218] Iteration 16400 (135.019 iter/s, 1.48127s/200 iters), loss = 0.103863
I1028 14:14:05.741719 12618 solver.cpp:237]     Train net output #0: loss = 0.103863 (* 1 = 0.103863 loss)
I1028 14:14:05.741724 12618 sgd_solver.cpp:105] Iteration 16400, lr = 0.000753789
I1028 14:14:05.758857 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:14:07.217440 12618 solver.cpp:218] Iteration 16600 (135.532 iter/s, 1.47566s/200 iters), loss = 0.165495
I1028 14:14:07.217619 12618 solver.cpp:237]     Train net output #0: loss = 0.165495 (* 1 = 0.165495 loss)
I1028 14:14:07.217643 12618 sgd_solver.cpp:105] Iteration 16600, lr = 0.000747157
I1028 14:14:08.697479 12618 solver.cpp:218] Iteration 16800 (135.153 iter/s, 1.4798s/200 iters), loss = 0.122263
I1028 14:14:08.697504 12618 solver.cpp:237]     Train net output #0: loss = 0.122263 (* 1 = 0.122263 loss)
I1028 14:14:08.697507 12618 sgd_solver.cpp:105] Iteration 16800, lr = 0.000740643
I1028 14:14:10.170814 12618 solver.cpp:330] Iteration 17000, Testing net (#0)
I1028 14:14:10.197408 12618 solver.cpp:397]     Test net output #0: acc = 0.951
I1028 14:14:10.197479 12618 solver.cpp:397]     Test net output #1: loss = 0.175101 (* 1 = 0.175101 loss)
I1028 14:14:10.206498 12618 solver.cpp:218] Iteration 17000 (132.546 iter/s, 1.50891s/200 iters), loss = 0.183214
I1028 14:14:10.206547 12618 solver.cpp:237]     Train net output #0: loss = 0.183214 (* 1 = 0.183214 loss)
I1028 14:14:10.206573 12618 sgd_solver.cpp:105] Iteration 17000, lr = 0.000734245
I1028 14:14:11.535600 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:14:11.662957 12618 solver.cpp:218] Iteration 17200 (137.329 iter/s, 1.45635s/200 iters), loss = 0.151628
I1028 14:14:11.662983 12618 solver.cpp:237]     Train net output #0: loss = 0.151628 (* 1 = 0.151628 loss)
I1028 14:14:11.662987 12618 sgd_solver.cpp:105] Iteration 17200, lr = 0.00072796
I1028 14:14:13.132807 12618 solver.cpp:218] Iteration 17400 (136.076 iter/s, 1.46976s/200 iters), loss = 0.154758
I1028 14:14:13.132846 12618 solver.cpp:237]     Train net output #0: loss = 0.154758 (* 1 = 0.154758 loss)
I1028 14:14:13.132850 12618 sgd_solver.cpp:105] Iteration 17400, lr = 0.000721784
I1028 14:14:14.605010 12618 solver.cpp:218] Iteration 17600 (135.859 iter/s, 1.47211s/200 iters), loss = 0.326946
I1028 14:14:14.605562 12618 solver.cpp:237]     Train net output #0: loss = 0.326945 (* 1 = 0.326945 loss)
I1028 14:14:14.605574 12618 sgd_solver.cpp:105] Iteration 17600, lr = 0.000715714
I1028 14:14:16.083329 12618 solver.cpp:218] Iteration 17800 (135.345 iter/s, 1.47771s/200 iters), loss = 0.131108
I1028 14:14:16.083534 12618 solver.cpp:237]     Train net output #0: loss = 0.131108 (* 1 = 0.131108 loss)
I1028 14:14:16.083544 12618 sgd_solver.cpp:105] Iteration 17800, lr = 0.000709749
I1028 14:14:17.301193 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:14:17.554266 12618 solver.cpp:330] Iteration 18000, Testing net (#0)
I1028 14:14:17.580410 12618 solver.cpp:397]     Test net output #0: acc = 0.951
I1028 14:14:17.580433 12618 solver.cpp:397]     Test net output #1: loss = 0.149144 (* 1 = 0.149144 loss)
I1028 14:14:17.589201 12618 solver.cpp:218] Iteration 18000 (132.836 iter/s, 1.50561s/200 iters), loss = 0.115569
I1028 14:14:17.589236 12618 solver.cpp:237]     Train net output #0: loss = 0.115569 (* 1 = 0.115569 loss)
I1028 14:14:17.589244 12618 sgd_solver.cpp:105] Iteration 18000, lr = 0.000703884
I1028 14:14:19.059393 12618 solver.cpp:218] Iteration 18200 (136.046 iter/s, 1.47009s/200 iters), loss = 0.130753
I1028 14:14:19.059418 12618 solver.cpp:237]     Train net output #0: loss = 0.130753 (* 1 = 0.130753 loss)
I1028 14:14:19.059422 12618 sgd_solver.cpp:105] Iteration 18200, lr = 0.000698119
I1028 14:14:20.541575 12618 solver.cpp:218] Iteration 18400 (134.944 iter/s, 1.4821s/200 iters), loss = 0.14143
I1028 14:14:20.541600 12618 solver.cpp:237]     Train net output #0: loss = 0.14143 (* 1 = 0.14143 loss)
I1028 14:14:20.541604 12618 sgd_solver.cpp:105] Iteration 18400, lr = 0.000692449
I1028 14:14:22.013943 12618 solver.cpp:218] Iteration 18600 (135.843 iter/s, 1.47228s/200 iters), loss = 0.135182
I1028 14:14:22.013968 12618 solver.cpp:237]     Train net output #0: loss = 0.135182 (* 1 = 0.135182 loss)
I1028 14:14:22.013972 12618 sgd_solver.cpp:105] Iteration 18600, lr = 0.000686873
I1028 14:14:23.087311 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:14:23.494127 12618 solver.cpp:218] Iteration 18800 (135.126 iter/s, 1.4801s/200 iters), loss = 0.123937
I1028 14:14:23.494170 12618 solver.cpp:237]     Train net output #0: loss = 0.123937 (* 1 = 0.123937 loss)
I1028 14:14:23.494174 12618 sgd_solver.cpp:105] Iteration 18800, lr = 0.000681388
I1028 14:14:24.963227 12618 solver.cpp:330] Iteration 19000, Testing net (#0)
I1028 14:14:24.982138 12627 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:14:24.989094 12618 solver.cpp:397]     Test net output #0: acc = 0.953
I1028 14:14:24.989122 12618 solver.cpp:397]     Test net output #1: loss = 0.144111 (* 1 = 0.144111 loss)
I1028 14:14:24.997182 12618 solver.cpp:218] Iteration 19000 (133.071 iter/s, 1.50295s/200 iters), loss = 0.0841447
I1028 14:14:24.997200 12618 solver.cpp:237]     Train net output #0: loss = 0.0841446 (* 1 = 0.0841446 loss)
I1028 14:14:24.997220 12618 sgd_solver.cpp:105] Iteration 19000, lr = 0.000675993
I1028 14:14:26.480630 12618 solver.cpp:218] Iteration 19200 (134.828 iter/s, 1.48337s/200 iters), loss = 0.1839
I1028 14:14:26.480654 12618 solver.cpp:237]     Train net output #0: loss = 0.1839 (* 1 = 0.1839 loss)
I1028 14:14:26.480659 12618 sgd_solver.cpp:105] Iteration 19200, lr = 0.000670684
I1028 14:14:27.968832 12618 solver.cpp:218] Iteration 19400 (134.398 iter/s, 1.48812s/200 iters), loss = 0.111008
I1028 14:14:27.968857 12618 solver.cpp:237]     Train net output #0: loss = 0.111008 (* 1 = 0.111008 loss)
I1028 14:14:27.968860 12618 sgd_solver.cpp:105] Iteration 19400, lr = 0.000665461
I1028 14:14:28.915120 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:14:29.455112 12618 solver.cpp:218] Iteration 19600 (134.572 iter/s, 1.4862s/200 iters), loss = 0.0937152
I1028 14:14:29.455137 12618 solver.cpp:237]     Train net output #0: loss = 0.0937151 (* 1 = 0.0937151 loss)
I1028 14:14:29.455140 12618 sgd_solver.cpp:105] Iteration 19600, lr = 0.00066032
I1028 14:14:30.924371 12618 solver.cpp:218] Iteration 19800 (136.131 iter/s, 1.46917s/200 iters), loss = 0.116904
I1028 14:14:30.924397 12618 solver.cpp:237]     Train net output #0: loss = 0.116904 (* 1 = 0.116904 loss)
I1028 14:14:30.924401 12618 sgd_solver.cpp:105] Iteration 19800, lr = 0.00065526
I1028 14:14:32.394948 12618 solver.cpp:447] Snapshotting to binary proto file /home/ljf/caffe-master/examples/ljftest_alphabet/caffe_ljftest_train_iter_20000.caffemodel
I1028 14:14:32.402916 12618 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/ljf/caffe-master/examples/ljftest_alphabet/caffe_ljftest_train_iter_20000.solverstate
I1028 14:14:32.404911 12618 solver.cpp:330] Iteration 20000, Testing net (#0)
I1028 14:14:32.427880 12618 solver.cpp:397]     Test net output #0: acc = 0.955
I1028 14:14:32.427901 12618 solver.cpp:397]     Test net output #1: loss = 0.14263 (* 1 = 0.14263 loss)
I1028 14:14:32.434859 12618 solver.cpp:218] Iteration 20000 (132.415 iter/s, 1.5104s/200 iters), loss = 0.134534
I1028 14:14:32.434890 12618 solver.cpp:237]     Train net output #0: loss = 0.134534 (* 1 = 0.134534 loss)
I1028 14:14:32.434901 12618 sgd_solver.cpp:105] Iteration 20000, lr = 0.000650279
I1028 14:14:33.913309 12618 solver.cpp:218] Iteration 20200 (135.285 iter/s, 1.47836s/200 iters), loss = 0.118858
I1028 14:14:33.913333 12618 solver.cpp:237]     Train net output #0: loss = 0.118858 (* 1 = 0.118858 loss)
I1028 14:14:33.913337 12618 sgd_solver.cpp:105] Iteration 20200, lr = 0.000645375
I1028 14:14:34.715005 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:14:35.397748 12618 solver.cpp:218] Iteration 20400 (134.739 iter/s, 1.48435s/200 iters), loss = 0.109264
I1028 14:14:35.397773 12618 solver.cpp:237]     Train net output #0: loss = 0.109264 (* 1 = 0.109264 loss)
I1028 14:14:35.397778 12618 sgd_solver.cpp:105] Iteration 20400, lr = 0.000640547
I1028 14:14:36.879045 12618 solver.cpp:218] Iteration 20600 (135.025 iter/s, 1.48121s/200 iters), loss = 0.152099
I1028 14:14:36.879070 12618 solver.cpp:237]     Train net output #0: loss = 0.152098 (* 1 = 0.152098 loss)
I1028 14:14:36.879075 12618 sgd_solver.cpp:105] Iteration 20600, lr = 0.000635792
I1028 14:14:38.359525 12618 solver.cpp:218] Iteration 20800 (135.099 iter/s, 1.4804s/200 iters), loss = 0.101517
I1028 14:14:38.359637 12618 solver.cpp:237]     Train net output #0: loss = 0.101517 (* 1 = 0.101517 loss)
I1028 14:14:38.359642 12618 sgd_solver.cpp:105] Iteration 20800, lr = 0.000631109
I1028 14:14:39.829731 12618 solver.cpp:330] Iteration 21000, Testing net (#0)
I1028 14:14:39.855737 12618 solver.cpp:397]     Test net output #0: acc = 0.954
I1028 14:14:39.855775 12618 solver.cpp:397]     Test net output #1: loss = 0.143371 (* 1 = 0.143371 loss)
I1028 14:14:39.864369 12618 solver.cpp:218] Iteration 21000 (132.919 iter/s, 1.50467s/200 iters), loss = 0.136976
I1028 14:14:39.864397 12618 solver.cpp:237]     Train net output #0: loss = 0.136976 (* 1 = 0.136976 loss)
I1028 14:14:39.864404 12618 sgd_solver.cpp:105] Iteration 21000, lr = 0.000626496
I1028 14:14:40.533550 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:14:41.353154 12618 solver.cpp:218] Iteration 21200 (134.346 iter/s, 1.48869s/200 iters), loss = 0.147741
I1028 14:14:41.353193 12618 solver.cpp:237]     Train net output #0: loss = 0.147741 (* 1 = 0.147741 loss)
I1028 14:14:41.353197 12618 sgd_solver.cpp:105] Iteration 21200, lr = 0.000621952
I1028 14:14:42.810317 12618 solver.cpp:218] Iteration 21400 (137.262 iter/s, 1.45707s/200 iters), loss = 0.176533
I1028 14:14:42.810340 12618 solver.cpp:237]     Train net output #0: loss = 0.176533 (* 1 = 0.176533 loss)
I1028 14:14:42.810344 12618 sgd_solver.cpp:105] Iteration 21400, lr = 0.000617475
I1028 14:14:44.282963 12618 solver.cpp:218] Iteration 21600 (135.818 iter/s, 1.47256s/200 iters), loss = 0.140633
I1028 14:14:44.282989 12618 solver.cpp:237]     Train net output #0: loss = 0.140633 (* 1 = 0.140633 loss)
I1028 14:14:44.282994 12618 sgd_solver.cpp:105] Iteration 21600, lr = 0.000613063
I1028 14:14:45.733759 12618 solver.cpp:218] Iteration 21800 (137.863 iter/s, 1.45071s/200 iters), loss = 0.126876
I1028 14:14:45.733785 12618 solver.cpp:237]     Train net output #0: loss = 0.126876 (* 1 = 0.126876 loss)
I1028 14:14:45.733789 12618 sgd_solver.cpp:105] Iteration 21800, lr = 0.000608716
I1028 14:14:46.243430 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:14:47.178897 12618 solver.cpp:330] Iteration 22000, Testing net (#0)
I1028 14:14:47.205392 12618 solver.cpp:397]     Test net output #0: acc = 0.959
I1028 14:14:47.205442 12618 solver.cpp:397]     Test net output #1: loss = 0.142443 (* 1 = 0.142443 loss)
I1028 14:14:47.214895 12618 solver.cpp:218] Iteration 22000 (135.04 iter/s, 1.48105s/200 iters), loss = 0.105198
I1028 14:14:47.214926 12618 solver.cpp:237]     Train net output #0: loss = 0.105198 (* 1 = 0.105198 loss)
I1028 14:14:47.214946 12618 sgd_solver.cpp:105] Iteration 22000, lr = 0.000604432
I1028 14:14:48.680472 12618 solver.cpp:218] Iteration 22200 (136.473 iter/s, 1.46549s/200 iters), loss = 0.145015
I1028 14:14:48.680497 12618 solver.cpp:237]     Train net output #0: loss = 0.145015 (* 1 = 0.145015 loss)
I1028 14:14:48.680501 12618 sgd_solver.cpp:105] Iteration 22200, lr = 0.000600209
I1028 14:14:50.131883 12618 solver.cpp:218] Iteration 22400 (137.805 iter/s, 1.45133s/200 iters), loss = 0.15544
I1028 14:14:50.131908 12618 solver.cpp:237]     Train net output #0: loss = 0.15544 (* 1 = 0.15544 loss)
I1028 14:14:50.131912 12618 sgd_solver.cpp:105] Iteration 22400, lr = 0.000596046
I1028 14:14:51.582375 12618 solver.cpp:218] Iteration 22600 (137.892 iter/s, 1.45041s/200 iters), loss = 0.130653
I1028 14:14:51.582401 12618 solver.cpp:237]     Train net output #0: loss = 0.130653 (* 1 = 0.130653 loss)
I1028 14:14:51.582404 12618 sgd_solver.cpp:105] Iteration 22600, lr = 0.000591942
I1028 14:14:51.972421 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:14:53.071401 12618 solver.cpp:218] Iteration 22800 (134.324 iter/s, 1.48894s/200 iters), loss = 0.140181
I1028 14:14:53.071441 12618 solver.cpp:237]     Train net output #0: loss = 0.140181 (* 1 = 0.140181 loss)
I1028 14:14:53.071445 12618 sgd_solver.cpp:105] Iteration 22800, lr = 0.000587896
I1028 14:14:54.536979 12618 solver.cpp:330] Iteration 23000, Testing net (#0)
I1028 14:14:54.562678 12618 solver.cpp:397]     Test net output #0: acc = 0.957
I1028 14:14:54.562724 12618 solver.cpp:397]     Test net output #1: loss = 0.133656 (* 1 = 0.133656 loss)
I1028 14:14:54.571094 12618 solver.cpp:218] Iteration 23000 (133.369 iter/s, 1.4996s/200 iters), loss = 0.12276
I1028 14:14:54.571113 12618 solver.cpp:237]     Train net output #0: loss = 0.12276 (* 1 = 0.12276 loss)
I1028 14:14:54.571118 12618 sgd_solver.cpp:105] Iteration 23000, lr = 0.000583906
I1028 14:14:56.032850 12618 solver.cpp:218] Iteration 23200 (136.829 iter/s, 1.46168s/200 iters), loss = 0.147208
I1028 14:14:56.032876 12618 solver.cpp:237]     Train net output #0: loss = 0.147208 (* 1 = 0.147208 loss)
I1028 14:14:56.032881 12618 sgd_solver.cpp:105] Iteration 23200, lr = 0.000579971
I1028 14:14:57.500459 12618 solver.cpp:218] Iteration 23400 (136.284 iter/s, 1.46752s/200 iters), loss = 0.11024
I1028 14:14:57.500497 12618 solver.cpp:237]     Train net output #0: loss = 0.11024 (* 1 = 0.11024 loss)
I1028 14:14:57.500502 12618 sgd_solver.cpp:105] Iteration 23400, lr = 0.00057609
I1028 14:14:57.748795 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:14:58.975644 12618 solver.cpp:218] Iteration 23600 (135.584 iter/s, 1.4751s/200 iters), loss = 0.0941177
I1028 14:14:58.975668 12618 solver.cpp:237]     Train net output #0: loss = 0.0941176 (* 1 = 0.0941176 loss)
I1028 14:14:58.975673 12618 sgd_solver.cpp:105] Iteration 23600, lr = 0.000572262
I1028 14:15:00.445314 12618 solver.cpp:218] Iteration 23800 (136.093 iter/s, 1.46959s/200 iters), loss = 0.113326
I1028 14:15:00.445339 12618 solver.cpp:237]     Train net output #0: loss = 0.113326 (* 1 = 0.113326 loss)
I1028 14:15:00.445344 12618 sgd_solver.cpp:105] Iteration 23800, lr = 0.000568486
I1028 14:15:01.915112 12618 solver.cpp:330] Iteration 24000, Testing net (#0)
I1028 14:15:01.941094 12618 solver.cpp:397]     Test net output #0: acc = 0.96
I1028 14:15:01.941118 12618 solver.cpp:397]     Test net output #1: loss = 0.127363 (* 1 = 0.127363 loss)
I1028 14:15:01.949293 12618 solver.cpp:218] Iteration 24000 (132.988 iter/s, 1.50389s/200 iters), loss = 0.0779742
I1028 14:15:01.949313 12618 solver.cpp:237]     Train net output #0: loss = 0.0779741 (* 1 = 0.0779741 loss)
I1028 14:15:01.949319 12618 sgd_solver.cpp:105] Iteration 24000, lr = 0.000564761
I1028 14:15:03.433630 12618 solver.cpp:218] Iteration 24200 (134.748 iter/s, 1.48426s/200 iters), loss = 0.161677
I1028 14:15:03.433655 12618 solver.cpp:237]     Train net output #0: loss = 0.161677 (* 1 = 0.161677 loss)
I1028 14:15:03.433660 12618 sgd_solver.cpp:105] Iteration 24200, lr = 0.000561086
I1028 14:15:03.544289 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:15:04.925613 12618 solver.cpp:218] Iteration 24400 (134.057 iter/s, 1.4919s/200 iters), loss = 0.152118
I1028 14:15:04.925639 12618 solver.cpp:237]     Train net output #0: loss = 0.152118 (* 1 = 0.152118 loss)
I1028 14:15:04.925643 12618 sgd_solver.cpp:105] Iteration 24400, lr = 0.000557459
I1028 14:15:06.411350 12618 solver.cpp:218] Iteration 24600 (134.621 iter/s, 1.48565s/200 iters), loss = 0.161635
I1028 14:15:06.411375 12618 solver.cpp:237]     Train net output #0: loss = 0.161635 (* 1 = 0.161635 loss)
I1028 14:15:06.411379 12618 sgd_solver.cpp:105] Iteration 24600, lr = 0.00055388
I1028 14:15:07.886751 12618 solver.cpp:218] Iteration 24800 (135.564 iter/s, 1.47532s/200 iters), loss = 0.111338
I1028 14:15:07.886777 12618 solver.cpp:237]     Train net output #0: loss = 0.111338 (* 1 = 0.111338 loss)
I1028 14:15:07.886781 12618 sgd_solver.cpp:105] Iteration 24800, lr = 0.000550348
I1028 14:15:09.315363 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:15:09.337052 12618 solver.cpp:330] Iteration 25000, Testing net (#0)
I1028 14:15:09.364068 12618 solver.cpp:397]     Test net output #0: acc = 0.953
I1028 14:15:09.364102 12618 solver.cpp:397]     Test net output #1: loss = 0.137984 (* 1 = 0.137984 loss)
I1028 14:15:09.371556 12618 solver.cpp:218] Iteration 25000 (134.706 iter/s, 1.48472s/200 iters), loss = 0.193917
I1028 14:15:09.371589 12618 solver.cpp:237]     Train net output #0: loss = 0.193917 (* 1 = 0.193917 loss)
I1028 14:15:09.371599 12618 sgd_solver.cpp:105] Iteration 25000, lr = 0.000546862
I1028 14:15:10.844509 12618 solver.cpp:218] Iteration 25200 (135.791 iter/s, 1.47285s/200 iters), loss = 0.093143
I1028 14:15:10.844548 12618 solver.cpp:237]     Train net output #0: loss = 0.0931429 (* 1 = 0.0931429 loss)
I1028 14:15:10.844552 12618 sgd_solver.cpp:105] Iteration 25200, lr = 0.000543421
I1028 14:15:12.313784 12618 solver.cpp:218] Iteration 25400 (136.13 iter/s, 1.46918s/200 iters), loss = 0.196865
I1028 14:15:12.313808 12618 solver.cpp:237]     Train net output #0: loss = 0.196865 (* 1 = 0.196865 loss)
I1028 14:15:12.313812 12618 sgd_solver.cpp:105] Iteration 25400, lr = 0.000540024
I1028 14:15:13.790860 12618 solver.cpp:218] Iteration 25600 (135.41 iter/s, 1.47699s/200 iters), loss = 0.0986601
I1028 14:15:13.790885 12618 solver.cpp:237]     Train net output #0: loss = 0.0986601 (* 1 = 0.0986601 loss)
I1028 14:15:13.790889 12618 sgd_solver.cpp:105] Iteration 25600, lr = 0.00053667
I1028 14:15:15.113164 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:15:15.280290 12618 solver.cpp:218] Iteration 25800 (134.287 iter/s, 1.48935s/200 iters), loss = 0.121601
I1028 14:15:15.280316 12618 solver.cpp:237]     Train net output #0: loss = 0.121601 (* 1 = 0.121601 loss)
I1028 14:15:15.280320 12618 sgd_solver.cpp:105] Iteration 25800, lr = 0.000533359
I1028 14:15:16.756548 12618 solver.cpp:330] Iteration 26000, Testing net (#0)
I1028 14:15:16.782397 12618 solver.cpp:397]     Test net output #0: acc = 0.975
I1028 14:15:16.782418 12618 solver.cpp:397]     Test net output #1: loss = 0.108504 (* 1 = 0.108504 loss)
I1028 14:15:16.790808 12618 solver.cpp:218] Iteration 26000 (132.412 iter/s, 1.51043s/200 iters), loss = 0.100293
I1028 14:15:16.790838 12618 solver.cpp:237]     Train net output #0: loss = 0.100293 (* 1 = 0.100293 loss)
I1028 14:15:16.790843 12618 sgd_solver.cpp:105] Iteration 26000, lr = 0.000530089
I1028 14:15:18.280303 12618 solver.cpp:218] Iteration 26200 (134.282 iter/s, 1.4894s/200 iters), loss = 0.123049
I1028 14:15:18.280328 12618 solver.cpp:237]     Train net output #0: loss = 0.123049 (* 1 = 0.123049 loss)
I1028 14:15:18.280331 12618 sgd_solver.cpp:105] Iteration 26200, lr = 0.000526861
I1028 14:15:19.760465 12618 solver.cpp:218] Iteration 26400 (135.128 iter/s, 1.48008s/200 iters), loss = 0.110945
I1028 14:15:19.760490 12618 solver.cpp:237]     Train net output #0: loss = 0.110945 (* 1 = 0.110945 loss)
I1028 14:15:19.760509 12618 sgd_solver.cpp:105] Iteration 26400, lr = 0.000523672
I1028 14:15:20.916399 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:15:21.227113 12618 solver.cpp:218] Iteration 26600 (136.373 iter/s, 1.46656s/200 iters), loss = 0.127091
I1028 14:15:21.227139 12618 solver.cpp:237]     Train net output #0: loss = 0.127091 (* 1 = 0.127091 loss)
I1028 14:15:21.227144 12618 sgd_solver.cpp:105] Iteration 26600, lr = 0.000520523
I1028 14:15:22.700150 12618 solver.cpp:218] Iteration 26800 (135.782 iter/s, 1.47295s/200 iters), loss = 0.147481
I1028 14:15:22.700177 12618 solver.cpp:237]     Train net output #0: loss = 0.147481 (* 1 = 0.147481 loss)
I1028 14:15:22.700183 12618 sgd_solver.cpp:105] Iteration 26800, lr = 0.000517413
I1028 14:15:24.157445 12618 solver.cpp:330] Iteration 27000, Testing net (#0)
I1028 14:15:24.183192 12618 solver.cpp:397]     Test net output #0: acc = 0.953
I1028 14:15:24.183213 12618 solver.cpp:397]     Test net output #1: loss = 0.164645 (* 1 = 0.164645 loss)
I1028 14:15:24.191642 12618 solver.cpp:218] Iteration 27000 (134.102 iter/s, 1.49141s/200 iters), loss = 0.0793447
I1028 14:15:24.191680 12618 solver.cpp:237]     Train net output #0: loss = 0.0793446 (* 1 = 0.0793446 loss)
I1028 14:15:24.191687 12618 sgd_solver.cpp:105] Iteration 27000, lr = 0.00051434
I1028 14:15:25.663498 12618 solver.cpp:218] Iteration 27200 (135.892 iter/s, 1.47176s/200 iters), loss = 0.14008
I1028 14:15:25.663525 12618 solver.cpp:237]     Train net output #0: loss = 0.14008 (* 1 = 0.14008 loss)
I1028 14:15:25.663532 12618 sgd_solver.cpp:105] Iteration 27200, lr = 0.000511305
I1028 14:15:26.698972 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:15:27.147088 12618 solver.cpp:218] Iteration 27400 (134.816 iter/s, 1.4835s/200 iters), loss = 0.104119
I1028 14:15:27.147112 12618 solver.cpp:237]     Train net output #0: loss = 0.104119 (* 1 = 0.104119 loss)
I1028 14:15:27.147117 12618 sgd_solver.cpp:105] Iteration 27400, lr = 0.000508306
I1028 14:15:28.603788 12618 solver.cpp:218] Iteration 27600 (137.305 iter/s, 1.45662s/200 iters), loss = 0.133455
I1028 14:15:28.603812 12618 solver.cpp:237]     Train net output #0: loss = 0.133455 (* 1 = 0.133455 loss)
I1028 14:15:28.603816 12618 sgd_solver.cpp:105] Iteration 27600, lr = 0.000505343
I1028 14:15:30.089278 12618 solver.cpp:218] Iteration 27800 (134.643 iter/s, 1.48541s/200 iters), loss = 0.184419
I1028 14:15:30.089303 12618 solver.cpp:237]     Train net output #0: loss = 0.184419 (* 1 = 0.184419 loss)
I1028 14:15:30.089308 12618 sgd_solver.cpp:105] Iteration 27800, lr = 0.000502415
I1028 14:15:31.560516 12618 solver.cpp:330] Iteration 28000, Testing net (#0)
I1028 14:15:31.585794 12618 solver.cpp:397]     Test net output #0: acc = 0.956
I1028 14:15:31.585814 12618 solver.cpp:397]     Test net output #1: loss = 0.139064 (* 1 = 0.139064 loss)
I1028 14:15:31.594020 12618 solver.cpp:218] Iteration 28000 (132.92 iter/s, 1.50466s/200 iters), loss = 0.0953586
I1028 14:15:31.594040 12618 solver.cpp:237]     Train net output #0: loss = 0.0953585 (* 1 = 0.0953585 loss)
I1028 14:15:31.594045 12618 sgd_solver.cpp:105] Iteration 28000, lr = 0.000499522
I1028 14:15:32.470602 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:15:33.058749 12618 solver.cpp:218] Iteration 28200 (136.552 iter/s, 1.46465s/200 iters), loss = 0.117294
I1028 14:15:33.058789 12618 solver.cpp:237]     Train net output #0: loss = 0.117294 (* 1 = 0.117294 loss)
I1028 14:15:33.058792 12618 sgd_solver.cpp:105] Iteration 28200, lr = 0.000496663
I1028 14:15:34.541970 12618 solver.cpp:218] Iteration 28400 (134.85 iter/s, 1.48313s/200 iters), loss = 0.167268
I1028 14:15:34.541995 12618 solver.cpp:237]     Train net output #0: loss = 0.167268 (* 1 = 0.167268 loss)
I1028 14:15:34.541998 12618 sgd_solver.cpp:105] Iteration 28400, lr = 0.000493837
I1028 14:15:36.030679 12618 solver.cpp:218] Iteration 28600 (134.352 iter/s, 1.48862s/200 iters), loss = 0.161104
I1028 14:15:36.030704 12618 solver.cpp:237]     Train net output #0: loss = 0.161104 (* 1 = 0.161104 loss)
I1028 14:15:36.030709 12618 sgd_solver.cpp:105] Iteration 28600, lr = 0.000491044
I1028 14:15:37.505367 12618 solver.cpp:218] Iteration 28800 (135.63 iter/s, 1.4746s/200 iters), loss = 0.12542
I1028 14:15:37.505393 12618 solver.cpp:237]     Train net output #0: loss = 0.12542 (* 1 = 0.12542 loss)
I1028 14:15:37.505395 12618 sgd_solver.cpp:105] Iteration 28800, lr = 0.000488283
I1028 14:15:38.269363 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:15:38.989444 12618 solver.cpp:330] Iteration 29000, Testing net (#0)
I1028 14:15:39.008117 12627 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:15:39.015875 12618 solver.cpp:397]     Test net output #0: acc = 0.956
I1028 14:15:39.015908 12618 solver.cpp:397]     Test net output #1: loss = 0.131944 (* 1 = 0.131944 loss)
I1028 14:15:39.023902 12618 solver.cpp:218] Iteration 29000 (131.713 iter/s, 1.51845s/200 iters), loss = 0.140949
I1028 14:15:39.023921 12618 solver.cpp:237]     Train net output #0: loss = 0.140949 (* 1 = 0.140949 loss)
I1028 14:15:39.023926 12618 sgd_solver.cpp:105] Iteration 29000, lr = 0.000485554
I1028 14:15:40.522410 12618 solver.cpp:218] Iteration 29200 (133.473 iter/s, 1.49843s/200 iters), loss = 0.0708578
I1028 14:15:40.522486 12618 solver.cpp:237]     Train net output #0: loss = 0.0708578 (* 1 = 0.0708578 loss)
I1028 14:15:40.522491 12618 sgd_solver.cpp:105] Iteration 29200, lr = 0.000482856
I1028 14:15:41.993419 12618 solver.cpp:218] Iteration 29400 (135.973 iter/s, 1.47088s/200 iters), loss = 0.123876
I1028 14:15:41.993444 12618 solver.cpp:237]     Train net output #0: loss = 0.123876 (* 1 = 0.123876 loss)
I1028 14:15:41.993448 12618 sgd_solver.cpp:105] Iteration 29400, lr = 0.000480189
I1028 14:15:43.484534 12618 solver.cpp:218] Iteration 29600 (134.136 iter/s, 1.49103s/200 iters), loss = 0.103365
I1028 14:15:43.484558 12618 solver.cpp:237]     Train net output #0: loss = 0.103365 (* 1 = 0.103365 loss)
I1028 14:15:43.484562 12618 sgd_solver.cpp:105] Iteration 29600, lr = 0.000477552
I1028 14:15:44.106950 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:15:44.980648 12618 solver.cpp:218] Iteration 29800 (133.687 iter/s, 1.49603s/200 iters), loss = 0.110511
I1028 14:15:44.980844 12618 solver.cpp:237]     Train net output #0: loss = 0.110511 (* 1 = 0.110511 loss)
I1028 14:15:44.980850 12618 sgd_solver.cpp:105] Iteration 29800, lr = 0.000474944
I1028 14:15:46.448911 12618 solver.cpp:447] Snapshotting to binary proto file /home/ljf/caffe-master/examples/ljftest_alphabet/caffe_ljftest_train_iter_30000.caffemodel
I1028 14:15:46.456804 12618 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/ljf/caffe-master/examples/ljftest_alphabet/caffe_ljftest_train_iter_30000.solverstate
I1028 14:15:46.458771 12618 solver.cpp:330] Iteration 30000, Testing net (#0)
I1028 14:15:46.481845 12618 solver.cpp:397]     Test net output #0: acc = 0.955
I1028 14:15:46.481868 12618 solver.cpp:397]     Test net output #1: loss = 0.150979 (* 1 = 0.150979 loss)
I1028 14:15:46.488823 12618 solver.cpp:218] Iteration 30000 (132.633 iter/s, 1.50792s/200 iters), loss = 0.143641
I1028 14:15:46.488840 12618 solver.cpp:237]     Train net output #0: loss = 0.14364 (* 1 = 0.14364 loss)
I1028 14:15:46.488845 12618 sgd_solver.cpp:105] Iteration 30000, lr = 0.000472365
I1028 14:15:47.982501 12618 solver.cpp:218] Iteration 30200 (133.905 iter/s, 1.4936s/200 iters), loss = 0.230473
I1028 14:15:47.982525 12618 solver.cpp:237]     Train net output #0: loss = 0.230472 (* 1 = 0.230472 loss)
I1028 14:15:47.982529 12618 sgd_solver.cpp:105] Iteration 30200, lr = 0.000469815
I1028 14:15:49.473090 12618 solver.cpp:218] Iteration 30400 (134.183 iter/s, 1.4905s/200 iters), loss = 0.15555
I1028 14:15:49.473131 12618 solver.cpp:237]     Train net output #0: loss = 0.15555 (* 1 = 0.15555 loss)
I1028 14:15:49.473135 12618 sgd_solver.cpp:105] Iteration 30400, lr = 0.000467293
I1028 14:15:49.957712 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:15:50.972539 12618 solver.cpp:218] Iteration 30600 (133.391 iter/s, 1.49935s/200 iters), loss = 0.133477
I1028 14:15:50.972564 12618 solver.cpp:237]     Train net output #0: loss = 0.133476 (* 1 = 0.133476 loss)
I1028 14:15:50.972569 12618 sgd_solver.cpp:105] Iteration 30600, lr = 0.000464799
I1028 14:15:52.457484 12618 solver.cpp:218] Iteration 30800 (134.693 iter/s, 1.48486s/200 iters), loss = 0.146781
I1028 14:15:52.457509 12618 solver.cpp:237]     Train net output #0: loss = 0.14678 (* 1 = 0.14678 loss)
I1028 14:15:52.457514 12618 sgd_solver.cpp:105] Iteration 30800, lr = 0.000462332
I1028 14:15:53.931443 12618 solver.cpp:330] Iteration 31000, Testing net (#0)
I1028 14:15:53.958253 12618 solver.cpp:397]     Test net output #0: acc = 0.955
I1028 14:15:53.958320 12618 solver.cpp:397]     Test net output #1: loss = 0.148671 (* 1 = 0.148671 loss)
I1028 14:15:53.968106 12618 solver.cpp:218] Iteration 31000 (132.404 iter/s, 1.51053s/200 iters), loss = 0.14242
I1028 14:15:53.968149 12618 solver.cpp:237]     Train net output #0: loss = 0.14242 (* 1 = 0.14242 loss)
I1028 14:15:53.968155 12618 sgd_solver.cpp:105] Iteration 31000, lr = 0.000459892
I1028 14:15:55.460471 12618 solver.cpp:218] Iteration 31200 (134.023 iter/s, 1.49228s/200 iters), loss = 0.162861
I1028 14:15:55.460510 12618 solver.cpp:237]     Train net output #0: loss = 0.162861 (* 1 = 0.162861 loss)
I1028 14:15:55.460546 12618 sgd_solver.cpp:105] Iteration 31200, lr = 0.000457477
I1028 14:15:55.800647 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:15:56.954684 12618 solver.cpp:218] Iteration 31400 (133.859 iter/s, 1.49411s/200 iters), loss = 0.0923867
I1028 14:15:56.954707 12618 solver.cpp:237]     Train net output #0: loss = 0.0923867 (* 1 = 0.0923867 loss)
I1028 14:15:56.954711 12618 sgd_solver.cpp:105] Iteration 31400, lr = 0.000455089
I1028 14:15:58.440493 12618 solver.cpp:218] Iteration 31600 (134.614 iter/s, 1.48573s/200 iters), loss = 0.202446
I1028 14:15:58.440532 12618 solver.cpp:237]     Train net output #0: loss = 0.202446 (* 1 = 0.202446 loss)
I1028 14:15:58.440536 12618 sgd_solver.cpp:105] Iteration 31600, lr = 0.000452726
I1028 14:15:59.929504 12618 solver.cpp:218] Iteration 31800 (134.326 iter/s, 1.48891s/200 iters), loss = 0.180856
I1028 14:15:59.929529 12618 solver.cpp:237]     Train net output #0: loss = 0.180856 (* 1 = 0.180856 loss)
I1028 14:15:59.929533 12618 sgd_solver.cpp:105] Iteration 31800, lr = 0.000450389
I1028 14:16:01.393724 12618 solver.cpp:330] Iteration 32000, Testing net (#0)
I1028 14:16:01.420522 12618 solver.cpp:397]     Test net output #0: acc = 0.95
I1028 14:16:01.420593 12618 solver.cpp:397]     Test net output #1: loss = 0.154288 (* 1 = 0.154288 loss)
I1028 14:16:01.429078 12618 solver.cpp:218] Iteration 32000 (133.38 iter/s, 1.49948s/200 iters), loss = 0.125626
I1028 14:16:01.429126 12618 solver.cpp:237]     Train net output #0: loss = 0.125626 (* 1 = 0.125626 loss)
I1028 14:16:01.429139 12618 sgd_solver.cpp:105] Iteration 32000, lr = 0.000448075
I1028 14:16:01.639238 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:16:02.914320 12618 solver.cpp:218] Iteration 32200 (134.668 iter/s, 1.48513s/200 iters), loss = 0.163546
I1028 14:16:02.914345 12618 solver.cpp:237]     Train net output #0: loss = 0.163546 (* 1 = 0.163546 loss)
I1028 14:16:02.914350 12618 sgd_solver.cpp:105] Iteration 32200, lr = 0.000445787
I1028 14:16:04.408715 12618 solver.cpp:218] Iteration 32400 (133.841 iter/s, 1.49431s/200 iters), loss = 0.143384
I1028 14:16:04.408740 12618 solver.cpp:237]     Train net output #0: loss = 0.143384 (* 1 = 0.143384 loss)
I1028 14:16:04.408745 12618 sgd_solver.cpp:105] Iteration 32400, lr = 0.000443522
I1028 14:16:05.902992 12618 solver.cpp:218] Iteration 32600 (133.852 iter/s, 1.49419s/200 iters), loss = 0.160998
I1028 14:16:05.903017 12618 solver.cpp:237]     Train net output #0: loss = 0.160998 (* 1 = 0.160998 loss)
I1028 14:16:05.903023 12618 sgd_solver.cpp:105] Iteration 32600, lr = 0.00044128
I1028 14:16:07.392567 12618 solver.cpp:218] Iteration 32800 (134.274 iter/s, 1.48949s/200 iters), loss = 0.113262
I1028 14:16:07.392590 12618 solver.cpp:237]     Train net output #0: loss = 0.113262 (* 1 = 0.113262 loss)
I1028 14:16:07.392594 12618 sgd_solver.cpp:105] Iteration 32800, lr = 0.000439062
I1028 14:16:07.457828 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:16:08.873165 12618 solver.cpp:330] Iteration 33000, Testing net (#0)
I1028 14:16:08.899237 12618 solver.cpp:397]     Test net output #0: acc = 0.955
I1028 14:16:08.899262 12618 solver.cpp:397]     Test net output #1: loss = 0.143338 (* 1 = 0.143338 loss)
I1028 14:16:08.907797 12618 solver.cpp:218] Iteration 33000 (132 iter/s, 1.51515s/200 iters), loss = 0.103506
I1028 14:16:08.907816 12618 solver.cpp:237]     Train net output #0: loss = 0.103506 (* 1 = 0.103506 loss)
I1028 14:16:08.907821 12618 sgd_solver.cpp:105] Iteration 33000, lr = 0.000436866
I1028 14:16:10.390663 12618 solver.cpp:218] Iteration 33200 (134.881 iter/s, 1.48279s/200 iters), loss = 0.0945351
I1028 14:16:10.390688 12618 solver.cpp:237]     Train net output #0: loss = 0.094535 (* 1 = 0.094535 loss)
I1028 14:16:10.390692 12618 sgd_solver.cpp:105] Iteration 33200, lr = 0.000434693
I1028 14:16:11.870486 12618 solver.cpp:218] Iteration 33400 (135.159 iter/s, 1.47974s/200 iters), loss = 0.0834246
I1028 14:16:11.870635 12618 solver.cpp:237]     Train net output #0: loss = 0.0834245 (* 1 = 0.0834245 loss)
I1028 14:16:11.870654 12618 sgd_solver.cpp:105] Iteration 33400, lr = 0.000432542
I1028 14:16:13.275444 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:16:13.356230 12618 solver.cpp:218] Iteration 33600 (134.631 iter/s, 1.48554s/200 iters), loss = 0.134927
I1028 14:16:13.356268 12618 solver.cpp:237]     Train net output #0: loss = 0.134927 (* 1 = 0.134927 loss)
I1028 14:16:13.356273 12618 sgd_solver.cpp:105] Iteration 33600, lr = 0.000430412
I1028 14:16:14.832391 12618 solver.cpp:218] Iteration 33800 (135.494 iter/s, 1.47608s/200 iters), loss = 0.0844256
I1028 14:16:14.832428 12618 solver.cpp:237]     Train net output #0: loss = 0.0844255 (* 1 = 0.0844255 loss)
I1028 14:16:14.832432 12618 sgd_solver.cpp:105] Iteration 33800, lr = 0.000428305
I1028 14:16:16.315151 12618 solver.cpp:330] Iteration 34000, Testing net (#0)
I1028 14:16:16.341567 12618 solver.cpp:397]     Test net output #0: acc = 0.956
I1028 14:16:16.341591 12618 solver.cpp:397]     Test net output #1: loss = 0.131968 (* 1 = 0.131968 loss)
I1028 14:16:16.350397 12618 solver.cpp:218] Iteration 34000 (131.759 iter/s, 1.51793s/200 iters), loss = 0.171201
I1028 14:16:16.350414 12618 solver.cpp:237]     Train net output #0: loss = 0.171201 (* 1 = 0.171201 loss)
I1028 14:16:16.350419 12618 sgd_solver.cpp:105] Iteration 34000, lr = 0.000426218
I1028 14:16:17.835703 12618 solver.cpp:218] Iteration 34200 (134.659 iter/s, 1.48523s/200 iters), loss = 0.116907
I1028 14:16:17.835727 12618 solver.cpp:237]     Train net output #0: loss = 0.116907 (* 1 = 0.116907 loss)
I1028 14:16:17.835732 12618 sgd_solver.cpp:105] Iteration 34200, lr = 0.000424152
I1028 14:16:19.098853 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:16:19.321976 12618 solver.cpp:218] Iteration 34400 (134.572 iter/s, 1.48619s/200 iters), loss = 0.0836187
I1028 14:16:19.322003 12618 solver.cpp:237]     Train net output #0: loss = 0.0836187 (* 1 = 0.0836187 loss)
I1028 14:16:19.322008 12618 sgd_solver.cpp:105] Iteration 34400, lr = 0.000422106
I1028 14:16:20.813644 12618 solver.cpp:218] Iteration 34600 (134.086 iter/s, 1.49158s/200 iters), loss = 0.15245
I1028 14:16:20.813668 12618 solver.cpp:237]     Train net output #0: loss = 0.15245 (* 1 = 0.15245 loss)
I1028 14:16:20.813673 12618 sgd_solver.cpp:105] Iteration 34600, lr = 0.00042008
I1028 14:16:22.287869 12618 solver.cpp:218] Iteration 34800 (135.672 iter/s, 1.47414s/200 iters), loss = 0.118344
I1028 14:16:22.287894 12618 solver.cpp:237]     Train net output #0: loss = 0.118344 (* 1 = 0.118344 loss)
I1028 14:16:22.287897 12618 sgd_solver.cpp:105] Iteration 34800, lr = 0.000418075
I1028 14:16:23.759447 12618 solver.cpp:330] Iteration 35000, Testing net (#0)
I1028 14:16:23.785743 12618 solver.cpp:397]     Test net output #0: acc = 0.955
I1028 14:16:23.785764 12618 solver.cpp:397]     Test net output #1: loss = 0.132082 (* 1 = 0.132082 loss)
I1028 14:16:23.794170 12618 solver.cpp:218] Iteration 35000 (132.783 iter/s, 1.50622s/200 iters), loss = 0.128782
I1028 14:16:23.794188 12618 solver.cpp:237]     Train net output #0: loss = 0.128782 (* 1 = 0.128782 loss)
I1028 14:16:23.794193 12618 sgd_solver.cpp:105] Iteration 35000, lr = 0.000416089
I1028 14:16:24.912684 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:16:25.269145 12618 solver.cpp:218] Iteration 35200 (135.603 iter/s, 1.4749s/200 iters), loss = 0.0713597
I1028 14:16:25.269171 12618 solver.cpp:237]     Train net output #0: loss = 0.0713597 (* 1 = 0.0713597 loss)
I1028 14:16:25.269176 12618 sgd_solver.cpp:105] Iteration 35200, lr = 0.000414122
I1028 14:16:26.745018 12618 solver.cpp:218] Iteration 35400 (135.521 iter/s, 1.47579s/200 iters), loss = 0.134885
I1028 14:16:26.745043 12618 solver.cpp:237]     Train net output #0: loss = 0.134885 (* 1 = 0.134885 loss)
I1028 14:16:26.745061 12618 sgd_solver.cpp:105] Iteration 35400, lr = 0.000412174
I1028 14:16:28.237422 12618 solver.cpp:218] Iteration 35600 (134.02 iter/s, 1.49232s/200 iters), loss = 0.101086
I1028 14:16:28.237463 12618 solver.cpp:237]     Train net output #0: loss = 0.101086 (* 1 = 0.101086 loss)
I1028 14:16:28.237469 12618 sgd_solver.cpp:105] Iteration 35600, lr = 0.000410245
I1028 14:16:29.722894 12618 solver.cpp:218] Iteration 35800 (134.646 iter/s, 1.48537s/200 iters), loss = 0.161254
I1028 14:16:29.722918 12618 solver.cpp:237]     Train net output #0: loss = 0.161254 (* 1 = 0.161254 loss)
I1028 14:16:29.722924 12618 sgd_solver.cpp:105] Iteration 35800, lr = 0.000408334
I1028 14:16:30.717941 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:16:31.202689 12618 solver.cpp:330] Iteration 36000, Testing net (#0)
I1028 14:16:31.229883 12618 solver.cpp:397]     Test net output #0: acc = 0.967
I1028 14:16:31.229903 12618 solver.cpp:397]     Test net output #1: loss = 0.112285 (* 1 = 0.112285 loss)
I1028 14:16:31.237346 12618 solver.cpp:218] Iteration 36000 (132.068 iter/s, 1.51437s/200 iters), loss = 0.159487
I1028 14:16:31.237363 12618 solver.cpp:237]     Train net output #0: loss = 0.159487 (* 1 = 0.159487 loss)
I1028 14:16:31.237368 12618 sgd_solver.cpp:105] Iteration 36000, lr = 0.000406442
I1028 14:16:32.720259 12618 solver.cpp:218] Iteration 36200 (134.877 iter/s, 1.48283s/200 iters), loss = 0.130271
I1028 14:16:32.720284 12618 solver.cpp:237]     Train net output #0: loss = 0.130271 (* 1 = 0.130271 loss)
I1028 14:16:32.720288 12618 sgd_solver.cpp:105] Iteration 36200, lr = 0.000404567
I1028 14:16:34.202245 12618 solver.cpp:218] Iteration 36400 (134.962 iter/s, 1.4819s/200 iters), loss = 0.131583
I1028 14:16:34.202270 12618 solver.cpp:237]     Train net output #0: loss = 0.131583 (* 1 = 0.131583 loss)
I1028 14:16:34.202275 12618 sgd_solver.cpp:105] Iteration 36400, lr = 0.00040271
I1028 14:16:35.670132 12618 solver.cpp:218] Iteration 36600 (136.258 iter/s, 1.4678s/200 iters), loss = 0.107994
I1028 14:16:35.670168 12618 solver.cpp:237]     Train net output #0: loss = 0.107994 (* 1 = 0.107994 loss)
I1028 14:16:35.670172 12618 sgd_solver.cpp:105] Iteration 36600, lr = 0.000400871
I1028 14:16:36.521952 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:16:37.160351 12618 solver.cpp:218] Iteration 36800 (134.217 iter/s, 1.49012s/200 iters), loss = 0.0872085
I1028 14:16:37.160377 12618 solver.cpp:237]     Train net output #0: loss = 0.0872085 (* 1 = 0.0872085 loss)
I1028 14:16:37.160379 12618 sgd_solver.cpp:105] Iteration 36800, lr = 0.000399048
I1028 14:16:38.626641 12618 solver.cpp:330] Iteration 37000, Testing net (#0)
I1028 14:16:38.653012 12618 solver.cpp:397]     Test net output #0: acc = 0.952
I1028 14:16:38.653040 12618 solver.cpp:397]     Test net output #1: loss = 0.168528 (* 1 = 0.168528 loss)
I1028 14:16:38.661466 12618 solver.cpp:218] Iteration 37000 (133.242 iter/s, 1.50103s/200 iters), loss = 0.129443
I1028 14:16:38.661483 12618 solver.cpp:237]     Train net output #0: loss = 0.129443 (* 1 = 0.129443 loss)
I1028 14:16:38.661487 12618 sgd_solver.cpp:105] Iteration 37000, lr = 0.000397243
I1028 14:16:40.150905 12618 solver.cpp:218] Iteration 37200 (134.286 iter/s, 1.48936s/200 iters), loss = 0.159947
I1028 14:16:40.150930 12618 solver.cpp:237]     Train net output #0: loss = 0.159947 (* 1 = 0.159947 loss)
I1028 14:16:40.150935 12618 sgd_solver.cpp:105] Iteration 37200, lr = 0.000395454
I1028 14:16:41.634521 12618 solver.cpp:218] Iteration 37400 (134.814 iter/s, 1.48353s/200 iters), loss = 0.0833963
I1028 14:16:41.634547 12618 solver.cpp:237]     Train net output #0: loss = 0.0833963 (* 1 = 0.0833963 loss)
I1028 14:16:41.634552 12618 sgd_solver.cpp:105] Iteration 37400, lr = 0.000393682
I1028 14:16:42.345001 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:16:43.119997 12618 solver.cpp:218] Iteration 37600 (134.645 iter/s, 1.48539s/200 iters), loss = 0.0746068
I1028 14:16:43.120023 12618 solver.cpp:237]     Train net output #0: loss = 0.0746068 (* 1 = 0.0746068 loss)
I1028 14:16:43.120026 12618 sgd_solver.cpp:105] Iteration 37600, lr = 0.000391926
I1028 14:16:44.596124 12618 solver.cpp:218] Iteration 37800 (135.497 iter/s, 1.47604s/200 iters), loss = 0.118631
I1028 14:16:44.596148 12618 solver.cpp:237]     Train net output #0: loss = 0.118631 (* 1 = 0.118631 loss)
I1028 14:16:44.596153 12618 sgd_solver.cpp:105] Iteration 37800, lr = 0.000390186
I1028 14:16:46.052049 12618 solver.cpp:330] Iteration 38000, Testing net (#0)
I1028 14:16:46.078063 12618 solver.cpp:397]     Test net output #0: acc = 0.956
I1028 14:16:46.078107 12618 solver.cpp:397]     Test net output #1: loss = 0.141197 (* 1 = 0.141197 loss)
I1028 14:16:46.086707 12618 solver.cpp:218] Iteration 38000 (134.183 iter/s, 1.4905s/200 iters), loss = 0.14337
I1028 14:16:46.086735 12618 solver.cpp:237]     Train net output #0: loss = 0.14337 (* 1 = 0.14337 loss)
I1028 14:16:46.086757 12618 sgd_solver.cpp:105] Iteration 38000, lr = 0.000388461
I1028 14:16:47.578423 12618 solver.cpp:218] Iteration 38200 (134.082 iter/s, 1.49163s/200 iters), loss = 0.121778
I1028 14:16:47.578449 12618 solver.cpp:237]     Train net output #0: loss = 0.121778 (* 1 = 0.121778 loss)
I1028 14:16:47.578452 12618 sgd_solver.cpp:105] Iteration 38200, lr = 0.000386753
I1028 14:16:48.147519 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:16:49.062608 12618 solver.cpp:218] Iteration 38400 (134.762 iter/s, 1.4841s/200 iters), loss = 0.12069
I1028 14:16:49.062633 12618 solver.cpp:237]     Train net output #0: loss = 0.12069 (* 1 = 0.12069 loss)
I1028 14:16:49.062638 12618 sgd_solver.cpp:105] Iteration 38400, lr = 0.000385059
I1028 14:16:50.545004 12618 solver.cpp:218] Iteration 38600 (134.924 iter/s, 1.48231s/200 iters), loss = 0.204219
I1028 14:16:50.545029 12618 solver.cpp:237]     Train net output #0: loss = 0.204219 (* 1 = 0.204219 loss)
I1028 14:16:50.545033 12618 sgd_solver.cpp:105] Iteration 38600, lr = 0.000383381
I1028 14:16:52.037452 12618 solver.cpp:218] Iteration 38800 (134.016 iter/s, 1.49236s/200 iters), loss = 0.118568
I1028 14:16:52.037477 12618 solver.cpp:237]     Train net output #0: loss = 0.118568 (* 1 = 0.118568 loss)
I1028 14:16:52.037482 12618 sgd_solver.cpp:105] Iteration 38800, lr = 0.000381718
I1028 14:16:53.512068 12618 solver.cpp:330] Iteration 39000, Testing net (#0)
I1028 14:16:53.530782 12627 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:16:53.538305 12618 solver.cpp:397]     Test net output #0: acc = 0.95
I1028 14:16:53.538337 12618 solver.cpp:397]     Test net output #1: loss = 0.141049 (* 1 = 0.141049 loss)
I1028 14:16:53.546712 12618 solver.cpp:218] Iteration 39000 (132.523 iter/s, 1.50918s/200 iters), loss = 0.105634
I1028 14:16:53.546732 12618 solver.cpp:237]     Train net output #0: loss = 0.105634 (* 1 = 0.105634 loss)
I1028 14:16:53.546737 12618 sgd_solver.cpp:105] Iteration 39000, lr = 0.000380069
I1028 14:16:53.978515 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:16:55.029812 12618 solver.cpp:218] Iteration 39200 (134.86 iter/s, 1.48302s/200 iters), loss = 0.122162
I1028 14:16:55.029837 12618 solver.cpp:237]     Train net output #0: loss = 0.122162 (* 1 = 0.122162 loss)
I1028 14:16:55.029841 12618 sgd_solver.cpp:105] Iteration 39200, lr = 0.000378435
I1028 14:16:56.499241 12618 solver.cpp:218] Iteration 39400 (136.115 iter/s, 1.46934s/200 iters), loss = 0.139636
I1028 14:16:56.499267 12618 solver.cpp:237]     Train net output #0: loss = 0.139636 (* 1 = 0.139636 loss)
I1028 14:16:56.499271 12618 sgd_solver.cpp:105] Iteration 39400, lr = 0.000376816
I1028 14:16:57.979197 12618 solver.cpp:218] Iteration 39600 (135.147 iter/s, 1.47987s/200 iters), loss = 0.168252
I1028 14:16:57.979220 12618 solver.cpp:237]     Train net output #0: loss = 0.168252 (* 1 = 0.168252 loss)
I1028 14:16:57.979224 12618 sgd_solver.cpp:105] Iteration 39600, lr = 0.00037521
I1028 14:16:59.460106 12618 solver.cpp:218] Iteration 39800 (135.06 iter/s, 1.48083s/200 iters), loss = 0.134037
I1028 14:16:59.460131 12618 solver.cpp:237]     Train net output #0: loss = 0.134037 (* 1 = 0.134037 loss)
I1028 14:16:59.460135 12618 sgd_solver.cpp:105] Iteration 39800, lr = 0.000373619
I1028 14:16:59.754842 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:17:00.948885 12618 solver.cpp:447] Snapshotting to binary proto file /home/ljf/caffe-master/examples/ljftest_alphabet/caffe_ljftest_train_iter_40000.caffemodel
I1028 14:17:00.969605 12618 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/ljf/caffe-master/examples/ljftest_alphabet/caffe_ljftest_train_iter_40000.solverstate
I1028 14:17:00.976173 12618 solver.cpp:330] Iteration 40000, Testing net (#0)
I1028 14:17:00.997592 12618 blocking_queue.cpp:49] Waiting for data
I1028 14:17:01.002545 12618 solver.cpp:397]     Test net output #0: acc = 0.954
I1028 14:17:01.002593 12618 solver.cpp:397]     Test net output #1: loss = 0.14142 (* 1 = 0.14142 loss)
I1028 14:17:01.010202 12618 solver.cpp:218] Iteration 40000 (129.032 iter/s, 1.55001s/200 iters), loss = 0.153204
I1028 14:17:01.010356 12618 solver.cpp:237]     Train net output #0: loss = 0.153204 (* 1 = 0.153204 loss)
I1028 14:17:01.010385 12618 sgd_solver.cpp:105] Iteration 40000, lr = 0.000372041
I1028 14:17:02.504983 12618 solver.cpp:218] Iteration 40200 (133.817 iter/s, 1.49458s/200 iters), loss = 0.140148
I1028 14:17:02.505023 12618 solver.cpp:237]     Train net output #0: loss = 0.140148 (* 1 = 0.140148 loss)
I1028 14:17:02.505026 12618 sgd_solver.cpp:105] Iteration 40200, lr = 0.000370477
I1028 14:17:03.997782 12618 solver.cpp:218] Iteration 40400 (133.985 iter/s, 1.4927s/200 iters), loss = 0.174256
I1028 14:17:03.997807 12618 solver.cpp:237]     Train net output #0: loss = 0.174256 (* 1 = 0.174256 loss)
I1028 14:17:03.997812 12618 sgd_solver.cpp:105] Iteration 40400, lr = 0.000368926
I1028 14:17:05.490097 12618 solver.cpp:218] Iteration 40600 (134.028 iter/s, 1.49223s/200 iters), loss = 0.111858
I1028 14:17:05.490121 12618 solver.cpp:237]     Train net output #0: loss = 0.111858 (* 1 = 0.111858 loss)
I1028 14:17:05.490126 12618 sgd_solver.cpp:105] Iteration 40600, lr = 0.000367389
I1028 14:17:05.644474 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:17:06.985687 12618 solver.cpp:218] Iteration 40800 (133.734 iter/s, 1.49551s/200 iters), loss = 0.12725
I1028 14:17:06.985713 12618 solver.cpp:237]     Train net output #0: loss = 0.12725 (* 1 = 0.12725 loss)
I1028 14:17:06.985718 12618 sgd_solver.cpp:105] Iteration 40800, lr = 0.000365865
I1028 14:17:08.441484 12618 solver.cpp:330] Iteration 41000, Testing net (#0)
I1028 14:17:08.467388 12618 solver.cpp:397]     Test net output #0: acc = 0.957
I1028 14:17:08.467411 12618 solver.cpp:397]     Test net output #1: loss = 0.143414 (* 1 = 0.143414 loss)
I1028 14:17:08.475774 12618 solver.cpp:218] Iteration 41000 (134.228 iter/s, 1.49s/200 iters), loss = 0.111369
I1028 14:17:08.475792 12618 solver.cpp:237]     Train net output #0: loss = 0.111369 (* 1 = 0.111369 loss)
I1028 14:17:08.475798 12618 sgd_solver.cpp:105] Iteration 41000, lr = 0.000364353
I1028 14:17:09.969329 12618 solver.cpp:218] Iteration 41200 (133.916 iter/s, 1.49348s/200 iters), loss = 0.0992817
I1028 14:17:09.969354 12618 solver.cpp:237]     Train net output #0: loss = 0.0992817 (* 1 = 0.0992817 loss)
I1028 14:17:09.969358 12618 sgd_solver.cpp:105] Iteration 41200, lr = 0.000362855
I1028 14:17:11.450511 12618 solver.cpp:218] Iteration 41400 (135.035 iter/s, 1.4811s/200 iters), loss = 0.0882902
I1028 14:17:11.450536 12618 solver.cpp:237]     Train net output #0: loss = 0.0882902 (* 1 = 0.0882902 loss)
I1028 14:17:11.450541 12618 sgd_solver.cpp:105] Iteration 41400, lr = 0.000361369
I1028 14:17:11.467357 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:17:12.929317 12618 solver.cpp:218] Iteration 41600 (135.252 iter/s, 1.47872s/200 iters), loss = 0.161491
I1028 14:17:12.929479 12618 solver.cpp:237]     Train net output #0: loss = 0.161491 (* 1 = 0.161491 loss)
I1028 14:17:12.929486 12618 sgd_solver.cpp:105] Iteration 41600, lr = 0.000359895
I1028 14:17:14.417062 12618 solver.cpp:218] Iteration 41800 (134.451 iter/s, 1.48753s/200 iters), loss = 0.116062
I1028 14:17:14.417086 12618 solver.cpp:237]     Train net output #0: loss = 0.116062 (* 1 = 0.116062 loss)
I1028 14:17:14.417091 12618 sgd_solver.cpp:105] Iteration 41800, lr = 0.000358434
I1028 14:17:15.895187 12618 solver.cpp:330] Iteration 42000, Testing net (#0)
I1028 14:17:15.921140 12618 solver.cpp:397]     Test net output #0: acc = 0.965
I1028 14:17:15.921162 12618 solver.cpp:397]     Test net output #1: loss = 0.133793 (* 1 = 0.133793 loss)
I1028 14:17:15.929600 12618 solver.cpp:218] Iteration 42000 (132.235 iter/s, 1.51246s/200 iters), loss = 0.157155
I1028 14:17:15.929616 12618 solver.cpp:237]     Train net output #0: loss = 0.157155 (* 1 = 0.157155 loss)
I1028 14:17:15.929622 12618 sgd_solver.cpp:105] Iteration 42000, lr = 0.000356985
I1028 14:17:17.292203 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:17:17.421290 12618 solver.cpp:218] Iteration 42200 (134.083 iter/s, 1.49161s/200 iters), loss = 0.15357
I1028 14:17:17.421315 12618 solver.cpp:237]     Train net output #0: loss = 0.15357 (* 1 = 0.15357 loss)
I1028 14:17:17.421319 12618 sgd_solver.cpp:105] Iteration 42200, lr = 0.000355548
I1028 14:17:18.896597 12618 solver.cpp:218] Iteration 42400 (135.573 iter/s, 1.47522s/200 iters), loss = 0.137445
I1028 14:17:18.896621 12618 solver.cpp:237]     Train net output #0: loss = 0.137445 (* 1 = 0.137445 loss)
I1028 14:17:18.896625 12618 sgd_solver.cpp:105] Iteration 42400, lr = 0.000354122
I1028 14:17:20.382922 12618 solver.cpp:218] Iteration 42600 (134.568 iter/s, 1.48624s/200 iters), loss = 0.281337
I1028 14:17:20.382949 12618 solver.cpp:237]     Train net output #0: loss = 0.281337 (* 1 = 0.281337 loss)
I1028 14:17:20.382953 12618 sgd_solver.cpp:105] Iteration 42600, lr = 0.000352709
I1028 14:17:21.852022 12618 solver.cpp:218] Iteration 42800 (136.146 iter/s, 1.46901s/200 iters), loss = 0.121247
I1028 14:17:21.852046 12618 solver.cpp:237]     Train net output #0: loss = 0.121247 (* 1 = 0.121247 loss)
I1028 14:17:21.852051 12618 sgd_solver.cpp:105] Iteration 42800, lr = 0.000351307
I1028 14:17:23.067405 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:17:23.322770 12618 solver.cpp:330] Iteration 43000, Testing net (#0)
I1028 14:17:23.351992 12618 solver.cpp:397]     Test net output #0: acc = 0.959
I1028 14:17:23.352033 12618 solver.cpp:397]     Test net output #1: loss = 0.137119 (* 1 = 0.137119 loss)
I1028 14:17:23.359488 12618 solver.cpp:218] Iteration 43000 (132.68 iter/s, 1.50738s/200 iters), loss = 0.10439
I1028 14:17:23.359508 12618 solver.cpp:237]     Train net output #0: loss = 0.10439 (* 1 = 0.10439 loss)
I1028 14:17:23.359513 12618 sgd_solver.cpp:105] Iteration 43000, lr = 0.000349916
I1028 14:17:24.849524 12618 solver.cpp:218] Iteration 43200 (134.232 iter/s, 1.48995s/200 iters), loss = 0.133576
I1028 14:17:24.849550 12618 solver.cpp:237]     Train net output #0: loss = 0.133576 (* 1 = 0.133576 loss)
I1028 14:17:24.849555 12618 sgd_solver.cpp:105] Iteration 43200, lr = 0.000348536
I1028 14:17:26.408480 12618 solver.cpp:218] Iteration 43400 (128.298 iter/s, 1.55887s/200 iters), loss = 0.13248
I1028 14:17:26.408509 12618 solver.cpp:237]     Train net output #0: loss = 0.13248 (* 1 = 0.13248 loss)
I1028 14:17:26.408529 12618 sgd_solver.cpp:105] Iteration 43400, lr = 0.000347168
I1028 14:17:27.899108 12618 solver.cpp:218] Iteration 43600 (134.179 iter/s, 1.49054s/200 iters), loss = 0.127252
I1028 14:17:27.899133 12618 solver.cpp:237]     Train net output #0: loss = 0.127252 (* 1 = 0.127252 loss)
I1028 14:17:27.899137 12618 sgd_solver.cpp:105] Iteration 43600, lr = 0.000345811
I1028 14:17:28.983495 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:17:29.382793 12618 solver.cpp:218] Iteration 43800 (134.807 iter/s, 1.4836s/200 iters), loss = 0.113402
I1028 14:17:29.382994 12618 solver.cpp:237]     Train net output #0: loss = 0.113402 (* 1 = 0.113402 loss)
I1028 14:17:29.383000 12618 sgd_solver.cpp:105] Iteration 43800, lr = 0.000344464
I1028 14:17:30.858472 12618 solver.cpp:330] Iteration 44000, Testing net (#0)
I1028 14:17:30.884232 12618 solver.cpp:397]     Test net output #0: acc = 0.96
I1028 14:17:30.884253 12618 solver.cpp:397]     Test net output #1: loss = 0.12785 (* 1 = 0.12785 loss)
I1028 14:17:30.892292 12618 solver.cpp:218] Iteration 44000 (132.517 iter/s, 1.50924s/200 iters), loss = 0.093544
I1028 14:17:30.892329 12618 solver.cpp:237]     Train net output #0: loss = 0.0935439 (* 1 = 0.0935439 loss)
I1028 14:17:30.892341 12618 sgd_solver.cpp:105] Iteration 44000, lr = 0.000343128
I1028 14:17:32.381785 12618 solver.cpp:218] Iteration 44200 (134.283 iter/s, 1.4894s/200 iters), loss = 0.183429
I1028 14:17:32.381809 12618 solver.cpp:237]     Train net output #0: loss = 0.183429 (* 1 = 0.183429 loss)
I1028 14:17:32.381814 12618 sgd_solver.cpp:105] Iteration 44200, lr = 0.000341803
I1028 14:17:33.875840 12618 solver.cpp:218] Iteration 44400 (133.871 iter/s, 1.49397s/200 iters), loss = 0.104751
I1028 14:17:33.875867 12618 solver.cpp:237]     Train net output #0: loss = 0.104751 (* 1 = 0.104751 loss)
I1028 14:17:33.875871 12618 sgd_solver.cpp:105] Iteration 44400, lr = 0.000340488
I1028 14:17:34.831845 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:17:35.377722 12618 solver.cpp:218] Iteration 44600 (133.174 iter/s, 1.50179s/200 iters), loss = 0.0860448
I1028 14:17:35.377934 12618 solver.cpp:237]     Train net output #0: loss = 0.0860448 (* 1 = 0.0860448 loss)
I1028 14:17:35.377941 12618 sgd_solver.cpp:105] Iteration 44600, lr = 0.000339184
I1028 14:17:36.877182 12618 solver.cpp:218] Iteration 44800 (133.405 iter/s, 1.49919s/200 iters), loss = 0.107971
I1028 14:17:36.877221 12618 solver.cpp:237]     Train net output #0: loss = 0.107971 (* 1 = 0.107971 loss)
I1028 14:17:36.877225 12618 sgd_solver.cpp:105] Iteration 44800, lr = 0.00033789
I1028 14:17:38.343319 12618 solver.cpp:330] Iteration 45000, Testing net (#0)
I1028 14:17:38.369485 12618 solver.cpp:397]     Test net output #0: acc = 0.948
I1028 14:17:38.369508 12618 solver.cpp:397]     Test net output #1: loss = 0.136204 (* 1 = 0.136204 loss)
I1028 14:17:38.377918 12618 solver.cpp:218] Iteration 45000 (133.276 iter/s, 1.50064s/200 iters), loss = 0.134989
I1028 14:17:38.377936 12618 solver.cpp:237]     Train net output #0: loss = 0.134989 (* 1 = 0.134989 loss)
I1028 14:17:38.377941 12618 sgd_solver.cpp:105] Iteration 45000, lr = 0.000336606
I1028 14:17:39.878511 12618 solver.cpp:218] Iteration 45200 (133.288 iter/s, 1.50051s/200 iters), loss = 0.102838
I1028 14:17:39.878552 12618 solver.cpp:237]     Train net output #0: loss = 0.102838 (* 1 = 0.102838 loss)
I1028 14:17:39.878557 12618 sgd_solver.cpp:105] Iteration 45200, lr = 0.000335331
I1028 14:17:40.674309 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:17:41.350003 12618 solver.cpp:218] Iteration 45400 (135.924 iter/s, 1.47141s/200 iters), loss = 0.10007
I1028 14:17:41.350029 12618 solver.cpp:237]     Train net output #0: loss = 0.10007 (* 1 = 0.10007 loss)
I1028 14:17:41.350033 12618 sgd_solver.cpp:105] Iteration 45400, lr = 0.000334067
I1028 14:17:42.841545 12618 solver.cpp:218] Iteration 45600 (134.097 iter/s, 1.49145s/200 iters), loss = 0.127875
I1028 14:17:42.841748 12618 solver.cpp:237]     Train net output #0: loss = 0.127875 (* 1 = 0.127875 loss)
I1028 14:17:42.841755 12618 sgd_solver.cpp:105] Iteration 45600, lr = 0.000332813
I1028 14:17:44.338305 12618 solver.cpp:218] Iteration 45800 (133.646 iter/s, 1.4965s/200 iters), loss = 0.108403
I1028 14:17:44.338486 12618 solver.cpp:237]     Train net output #0: loss = 0.108402 (* 1 = 0.108402 loss)
I1028 14:17:44.338507 12618 sgd_solver.cpp:105] Iteration 45800, lr = 0.000331568
I1028 14:17:45.820312 12618 solver.cpp:330] Iteration 46000, Testing net (#0)
I1028 14:17:45.846530 12618 solver.cpp:397]     Test net output #0: acc = 0.972
I1028 14:17:45.846549 12618 solver.cpp:397]     Test net output #1: loss = 0.11015 (* 1 = 0.11015 loss)
I1028 14:17:45.855010 12618 solver.cpp:218] Iteration 46000 (131.885 iter/s, 1.51647s/200 iters), loss = 0.127401
I1028 14:17:45.855026 12618 solver.cpp:237]     Train net output #0: loss = 0.127401 (* 1 = 0.127401 loss)
I1028 14:17:45.855031 12618 sgd_solver.cpp:105] Iteration 46000, lr = 0.000330332
I1028 14:17:46.513963 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:17:47.339998 12618 solver.cpp:218] Iteration 46200 (134.688 iter/s, 1.48491s/200 iters), loss = 0.145251
I1028 14:17:47.340024 12618 solver.cpp:237]     Train net output #0: loss = 0.145251 (* 1 = 0.145251 loss)
I1028 14:17:47.340029 12618 sgd_solver.cpp:105] Iteration 46200, lr = 0.000329106
I1028 14:17:48.826997 12618 solver.cpp:218] Iteration 46400 (134.507 iter/s, 1.48691s/200 iters), loss = 0.177889
I1028 14:17:48.827023 12618 solver.cpp:237]     Train net output #0: loss = 0.177889 (* 1 = 0.177889 loss)
I1028 14:17:48.827028 12618 sgd_solver.cpp:105] Iteration 46400, lr = 0.00032789
I1028 14:17:50.316515 12618 solver.cpp:218] Iteration 46600 (134.279 iter/s, 1.48943s/200 iters), loss = 0.145296
I1028 14:17:50.316540 12618 solver.cpp:237]     Train net output #0: loss = 0.145296 (* 1 = 0.145296 loss)
I1028 14:17:50.316545 12618 sgd_solver.cpp:105] Iteration 46600, lr = 0.000326682
I1028 14:17:51.799243 12618 solver.cpp:218] Iteration 46800 (134.894 iter/s, 1.48264s/200 iters), loss = 0.126513
I1028 14:17:51.799268 12618 solver.cpp:237]     Train net output #0: loss = 0.126513 (* 1 = 0.126513 loss)
I1028 14:17:51.799273 12618 sgd_solver.cpp:105] Iteration 46800, lr = 0.000325484
I1028 14:17:52.325737 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:17:53.281062 12618 solver.cpp:330] Iteration 47000, Testing net (#0)
I1028 14:17:53.307025 12618 solver.cpp:397]     Test net output #0: acc = 0.953
I1028 14:17:53.307063 12618 solver.cpp:397]     Test net output #1: loss = 0.157402 (* 1 = 0.157402 loss)
I1028 14:17:53.315649 12618 solver.cpp:218] Iteration 47000 (131.898 iter/s, 1.51632s/200 iters), loss = 0.0948283
I1028 14:17:53.315667 12618 solver.cpp:237]     Train net output #0: loss = 0.0948282 (* 1 = 0.0948282 loss)
I1028 14:17:53.315672 12618 sgd_solver.cpp:105] Iteration 47000, lr = 0.000324295
I1028 14:17:54.807772 12618 solver.cpp:218] Iteration 47200 (134.044 iter/s, 1.49204s/200 iters), loss = 0.135686
I1028 14:17:54.807968 12618 solver.cpp:237]     Train net output #0: loss = 0.135686 (* 1 = 0.135686 loss)
I1028 14:17:54.807976 12618 sgd_solver.cpp:105] Iteration 47200, lr = 0.000323114
I1028 14:17:56.286603 12618 solver.cpp:218] Iteration 47400 (135.265 iter/s, 1.47858s/200 iters), loss = 0.137749
I1028 14:17:56.286828 12618 solver.cpp:237]     Train net output #0: loss = 0.137749 (* 1 = 0.137749 loss)
I1028 14:17:56.286840 12618 sgd_solver.cpp:105] Iteration 47400, lr = 0.000321942
I1028 14:17:57.770483 12618 solver.cpp:218] Iteration 47600 (134.807 iter/s, 1.4836s/200 iters), loss = 0.124705
I1028 14:17:57.770684 12618 solver.cpp:237]     Train net output #0: loss = 0.124705 (* 1 = 0.124705 loss)
I1028 14:17:57.770691 12618 sgd_solver.cpp:105] Iteration 47600, lr = 0.000320779
I1028 14:17:58.166357 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:17:59.270931 12618 solver.cpp:218] Iteration 47800 (133.316 iter/s, 1.50019s/200 iters), loss = 0.119798
I1028 14:17:59.270958 12618 solver.cpp:237]     Train net output #0: loss = 0.119798 (* 1 = 0.119798 loss)
I1028 14:17:59.270964 12618 sgd_solver.cpp:105] Iteration 47800, lr = 0.000319625
I1028 14:18:00.752944 12618 solver.cpp:330] Iteration 48000, Testing net (#0)
I1028 14:18:00.778751 12618 solver.cpp:397]     Test net output #0: acc = 0.958
I1028 14:18:00.778801 12618 solver.cpp:397]     Test net output #1: loss = 0.146096 (* 1 = 0.146096 loss)
I1028 14:18:00.787387 12618 solver.cpp:218] Iteration 48000 (131.894 iter/s, 1.51637s/200 iters), loss = 0.133547
I1028 14:18:00.787406 12618 solver.cpp:237]     Train net output #0: loss = 0.133547 (* 1 = 0.133547 loss)
I1028 14:18:00.787412 12618 sgd_solver.cpp:105] Iteration 48000, lr = 0.000318479
I1028 14:18:02.278564 12618 solver.cpp:218] Iteration 48200 (134.13 iter/s, 1.4911s/200 iters), loss = 0.130583
I1028 14:18:02.278590 12618 solver.cpp:237]     Train net output #0: loss = 0.130583 (* 1 = 0.130583 loss)
I1028 14:18:02.278594 12618 sgd_solver.cpp:105] Iteration 48200, lr = 0.000317341
I1028 14:18:03.759279 12618 solver.cpp:218] Iteration 48400 (135.078 iter/s, 1.48063s/200 iters), loss = 0.100056
I1028 14:18:03.759488 12618 solver.cpp:237]     Train net output #0: loss = 0.100056 (* 1 = 0.100056 loss)
I1028 14:18:03.759495 12618 sgd_solver.cpp:105] Iteration 48400, lr = 0.000316212
I1028 14:18:04.009789 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:18:05.254575 12618 solver.cpp:218] Iteration 48600 (133.777 iter/s, 1.49503s/200 iters), loss = 0.0931363
I1028 14:18:05.254777 12618 solver.cpp:237]     Train net output #0: loss = 0.0931362 (* 1 = 0.0931362 loss)
I1028 14:18:05.254783 12618 sgd_solver.cpp:105] Iteration 48600, lr = 0.000315091
I1028 14:18:06.743896 12618 solver.cpp:218] Iteration 48800 (134.313 iter/s, 1.48906s/200 iters), loss = 0.0978694
I1028 14:18:06.743921 12618 solver.cpp:237]     Train net output #0: loss = 0.0978694 (* 1 = 0.0978694 loss)
I1028 14:18:06.743926 12618 sgd_solver.cpp:105] Iteration 48800, lr = 0.000313978
I1028 14:18:08.210062 12618 solver.cpp:330] Iteration 49000, Testing net (#0)
I1028 14:18:08.229249 12627 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:18:08.236145 12618 solver.cpp:397]     Test net output #0: acc = 0.958
I1028 14:18:08.236160 12618 solver.cpp:397]     Test net output #1: loss = 0.128837 (* 1 = 0.128837 loss)
I1028 14:18:08.244413 12618 solver.cpp:218] Iteration 49000 (133.294 iter/s, 1.50044s/200 iters), loss = 0.080147
I1028 14:18:08.244431 12618 solver.cpp:237]     Train net output #0: loss = 0.0801469 (* 1 = 0.0801469 loss)
I1028 14:18:08.244436 12618 sgd_solver.cpp:105] Iteration 49000, lr = 0.000312873
I1028 14:18:09.729718 12618 solver.cpp:218] Iteration 49200 (134.66 iter/s, 1.48523s/200 iters), loss = 0.155997
I1028 14:18:09.729917 12618 solver.cpp:237]     Train net output #0: loss = 0.155997 (* 1 = 0.155997 loss)
I1028 14:18:09.729923 12618 sgd_solver.cpp:105] Iteration 49200, lr = 0.000311777
I1028 14:18:09.850627 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:18:11.222746 12618 solver.cpp:218] Iteration 49400 (133.979 iter/s, 1.49277s/200 iters), loss = 0.153785
I1028 14:18:11.222965 12618 solver.cpp:237]     Train net output #0: loss = 0.153785 (* 1 = 0.153785 loss)
I1028 14:18:11.222972 12618 sgd_solver.cpp:105] Iteration 49400, lr = 0.000310688
I1028 14:18:12.713011 12618 solver.cpp:218] Iteration 49600 (134.228 iter/s, 1.49s/200 iters), loss = 0.155855
I1028 14:18:12.713035 12618 solver.cpp:237]     Train net output #0: loss = 0.155855 (* 1 = 0.155855 loss)
I1028 14:18:12.713039 12618 sgd_solver.cpp:105] Iteration 49600, lr = 0.000309606
I1028 14:18:14.205703 12618 solver.cpp:218] Iteration 49800 (133.994 iter/s, 1.49261s/200 iters), loss = 0.111653
I1028 14:18:14.205741 12618 solver.cpp:237]     Train net output #0: loss = 0.111653 (* 1 = 0.111653 loss)
I1028 14:18:14.205745 12618 sgd_solver.cpp:105] Iteration 49800, lr = 0.000308533
I1028 14:18:15.662250 12625 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:18:15.684124 12618 solver.cpp:447] Snapshotting to binary proto file /home/ljf/caffe-master/examples/ljftest_alphabet/caffe_ljftest_train_iter_50000.caffemodel
I1028 14:18:15.692755 12618 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/ljf/caffe-master/examples/ljftest_alphabet/caffe_ljftest_train_iter_50000.solverstate
I1028 14:18:15.700840 12618 solver.cpp:310] Iteration 50000, loss = 0.171766
I1028 14:18:15.700881 12618 solver.cpp:330] Iteration 50000, Testing net (#0)
I1028 14:18:15.723477 12618 solver.cpp:397]     Test net output #0: acc = 0.951
I1028 14:18:15.723538 12618 solver.cpp:397]     Test net output #1: loss = 0.14123 (* 1 = 0.14123 loss)
I1028 14:18:15.723544 12618 solver.cpp:315] Optimization Done.
I1028 14:18:15.723548 12618 caffe.cpp:259] Optimization Done.
